\chapter{Introduction}

\section{Introduction and Motivation}

Gamma-ray spectroscopy is an important part of homeland security and nonproliferation technologies. By analyzing the gamma-ray spectrum of some material, a user can determine the isotopes present and their relative quantities. This technique can be used to differentiate special nuclear materials (SNM) such as weapons grade plutonium from a benign medical or industrial source in a cargo container. Gamma-ray spectroscopy can also be used to measure the enrichment of uranium, an important measurement for nonproliferation and nuclear treaty verification. 

Typically, gamma-ray spectroscopy is performed by a trained operator \cite{burr2009} or a hand-held radioisotope identification device (RIID). Because RIID users are usually not trained to analyze gamma-ray spectra, the U.S. DOE (Department of Energy) employs a team of on-call spectroscopists to resolve alarms created by RIIDs. Despite their importance, reported performance of commercial RIIDs are generally poor \cite{pibida2004,blackadar2003,blackadar2004}. It has been argued that RIID improvements fall into two categories \cite{swoboda2004}: improvements in the detection materials and improvements in the identification algorithms \cite{blackadar2003}. Detection materials can be improved by reducing the cost of producing large detector volumes for advanced detection materials \cite{Gostilo2004,Chen2018} or by finding new room-temperature gamma-ray detection materials with high intrinsic efficiency and resolution comparable to high purity germanium (HPGe) semiconductor detectors \cite{swoboda2004}. While these advanced materials can be used to improve performance, commercial RIIDs typically employ the medium-resolution material sodium iodide (NaI) or high-resolution materials like HPGe and cadmium zinc tellurium (CZT). High-resolution materials do offer better performance, but these materials suffer from several drawbacks. Drawbacks like material cost, requirement for cryogenic temperatures (for HPGe), and difficulty creating large detector volumes. Despite the drop in resolution, the medium-resolution detection material NaI is still standard in the RIID industry due to its ease of use, low cost, large detector volumes, high intrinsic efficiency, high light output, and acceptable resolution for gamma-ray spectroscopy \cite{swoboda2004}. It has been argued that the focus of improving RIIDs should focus on the identification algorithms using this industry standard material \cite{blackadar2003}. Because of the reasons outlined above, the focus of this dissertation is to investigate a novel detection method, machine learning algorithms, as a possible avenue of improving the performance of RIIDs using NaI.

The medium-resolution detector of interest in this work is the Ortec 905-3 2- x 2-in. NaI cylindrical scintillation detector \cite{Hofstadter1948}. Despite it's widespread use, NaI detectors have several issues that complicate automated identification. The first issue is poor resolution compared to other more expensive radiation detection material, such as HPGe and CZT. The lower-resolution makes some photopeaks unresolvable from each other, complicating identification. The second issue is calibration drift due to voltage drift in detectors electronics and temperature changes \cite{knoll,gilmore}. This calibration drift changes the locations and shapes of features in a gamma-ray spectrum. Automatic recalibration can be accomplished through automatically calibrating to a built-in reference source or to a naturally occurring background source. These methods fall short for different reasons. Built-in sources need to be periodically replaced and add an unwanted signal to a spectrum. Calibrating off of a background reference, typically the 1460 keV gamma-ray peak from $^{40}$K, requires the signal-to-noise ratio of that photopeak to be significant. For short integration times common in homeland security measurements this is often be infeasible. 

The third issue is a non-linear energy response. This manifests as a small second order term in their calibration. This complicates. While not specific to NaI detectors, the fourth issue affecting identification algorithms is background radiation from naturally occurring radioactive material (NORM). Background radiation can change both in intensity and composition based on location and weather. This background signal can obscure features in gamma-ray spectra. Despite these drawbacks, our previous works have demonstrated ANNs capable of identifying multiple isotopes in unknown backgrounds with a wide range of calibration settings \cite{kamudaThesis2017,kamuda2017}.


% \section{Radioisotope Identification Device Applications}

% Statistical methods applied to gamma-ray spectroscopy algorithms in nuclear security missions \cite{Min2014}.

% \subsection{Homeland Security}

% Handheld RIIDs are used by boarder protection and law enforcement for porthole and area monitoring \cite{Hodge2007}. An example of area monitoring could be monitoring a high traffic area during a high-profile event. An example of porthole monitoring is monitoring cargo vehicles. RIIDs are typically employed in second screening activities, after a primary count rate alarm is triggered. In order to minimize traffic and ensure cargo containers leave in an economically reasonable time, screening activities are kept on the order of minutes. Another example of porthole monitoring is temporary checkpoints where traffic is slowed but not stopped. Often, the important task for devices employed in vehicle screening is determining if a primary alarm came from NORM, a legitimate industrial source, or SNM.


% \cite{fagan2012}

% GRADER PROGRAM https://www.dhs.gov/guidance-grader-program


% RIIDs also can be used to identify orphaned sources.
% https://www-sciencedirect-com.proxy2.library.illinois.edu/science/article/pii/S0969804302002221

% Pozzi great references https://www-sciencedirect-com.proxy2.library.illinois.edu/science/article/pii/S0168900217300074


% DATASET https://www-sciencedirect-com.proxy2.library.illinois.edu/science/article/pii/S0168900214012741

% \subsection{Nuclear Treaty Verification}

% Talk about Zero knowledge measurements 


\section{Neural Network History}


Artificial neural networks were first theorized in the 1940s as a model of how complex biological systems like groups of neurons learn and remember \cite{Pitts1943, Hebb1949}. These theories hypothesized that learning took place by reinforcing neural connections corresponding to some correct behavior that was reinforced. The first implementation of an ANN came in 1958 in the form of The Perceptron \cite{Rosenblatt1958, Rosenblatt1962}. The Perceptron was a single layer neural network implemented in a two-class image recognition problem. A class is a unique category, like dog and cat or on and off. There is no limit on the number of classes a model can attempt to learn. Another single layer neural network design was ADALINE, created in 1960 \cite{Widrow1960}. While the ADALINE algorithm shares a similar architecture with the perceptron, the learning rule is different. Unfortunately, the single-layer perceptron was proven to not work in cases where classes in the data are not linearly separable \cite{Minsky1969}. This realization led to a decline in neural network research.

While a single layer network could only solve linearly separable problems, in 1969 it was also found that a network with multiple layers could solve problems that are non-linearly separable \cite{Minsky1969}. The perceptron algorithm was limited to a single layer network due to its activation function being a non-differentiable step function. It was soon shown that multiple ADALINE neurons could be stacked on top of each other, creating a MADALINE network \cite{Ridgway1962}. Due to its multilayer structure, MADALINE is able to learn non-linearly separable functions. A MADALINE network was used as an adaptive filter that removes echo from phone lines \cite{Widrow1988}.

Further advances in ANNs came in the form of learning improvements. Not long after the success of ADALINE and MADALINE, it was suggested that the concept of error propagation could be applied to ANNs \cite{Werbos1974, Rumelhart1986}. Additionally, it was shown that error backpropogation applied with a differentiable non-linear activation function was an extremely powerful method to train ANNs \cite{Murtagh1991}. Algorithms based on the backpropogation of error are now the most common method to train ANNs.

Currently, ANNs can solve many diverse problems. ANNs have shown promise in everyday problems such as handwritten zip code recognition \cite{LeCun1989}, image recognition \cite{Krizhevsky2012}, and fingerprint identification \cite{Jeyanthia2015}; as well as more complicated problems such as lung cancer classification based on MRI images \cite{Selvakumari2016}, estimating surface soil moisture from high-resolution aerial images of cropland \cite{Hassan-Esfahani2015}, and stock market forecasting \cite{Rababaah2015}.


\section{Gamma-Ray Spectroscopy for Isotope Identification}

Traditionally, isotope identification is conducted by a trained spectroscopist. Rawool-Sullivan et al. identified a common workflow performed by a group of gamma-ray spectroscopists \cite{Sullivan2010}. This workflow includes discriminating background and source photopeaks, adjusting the calibration using background photopeaks and checking for shielding effects in the low-energy photopeaks. Once photopeaks are identified, the spectroscopist would use their prior knowledge of isotope emissions (or consult a database of these emissions) to match isotopes to the spectrum. The researchers also noted that while  spectroscopists used this book knowledge, they often would use intuition developed from analyzing tens or hundreds of gamma-ray spectrum. The researchers also noted the difficulty in incorporating this subjective analysis into an automated algorithm.
% This is one of the main arguments for using ANNs in automated isotope ID


There are many automated radioisotope identification methods available, but few perform well given a low-resolution gamma-ray spectrum of a mixture of radioisotopes. Common methods include library comparison algorithms, region of interest (ROI) algorithms, principle component analysis (PCA), and template matching.

Library comparison algorithms attempt to match photopeak energies found in a gamma-ray spectrum with those found in a library of known isotope decay energies. Drifts and uncertainties in detector calibration can lead to misidentifying photopeaks, leading to incorrect isotope identifications \cite{burr2009}. To be automated, this method needs an algorithm to extract photopeak centroids despite calibration drift and an unknown background signal. While methods for photopeak extraction exist and are actively researched \cite{mariscotti1967,DELOTTO1977,GARDNER2011}, they face difficulties when a large number of photopeaks overlap in a spectrum \cite{xiong2015}, such as when a mixture of radio-isotopes are measured with a low-resolution detector .

ROI algorithms define regions in a spectrum where target radioisotope photopeaks are expected. Counts in these regions are then compared to a measured or expected background. Significant elevation in counts in a target isotopes ROI's indicates the presence of that isotope. ROI algorithms operate poorly when photopeaks of different radioisotopes overlap \cite{burr2009}. Because of this, large isotope libraries perform poorly using this method. Similarly to the library comparison algorithm, calibration drift may shift photopeaks into neighboring ROIs, leading to incorrect identification. The ROI method has been used to differentiate normally occurring radioactive material (NORM) from special nuclear material (SNM) using plastic scintillators \cite{Ely2006}.

PCA can also be applied to radioisotope identification. The goal of PCA is to reduce the dimensionality of a dataset into uncorrelated variables \cite{Jolliffe2002}. Using a few of these principle components, the data may be represented in a reduced space that contains most of the information present in the original data. The transformed data can then be clustered based on isotope identity. Clustering algorithms may include K-means or Mahalanobis distance \cite{Kanungo2002, Kumari2012}. PCA has been applied to isotope identification using plastic scintillators \cite{Boardman2012} and anomaly detection using both plastic scintillators and NaI detectors \cite{runkle2006b}. Despite the progress of PCA in some isotope identification problems, there has not been significant progress in applying PCA to separating mixtures of isotopes in gamma-ray spectra.

Template matching algorithms find an example in a database of gamma-ray spectra that most closely matches a measured spectrum \cite{burr2009}. The database of spectra can contain multiple detector calibration settings, shielding materials, and source-to-detector distances. Goodness of fit can be measured using a hypothesis test such as chi-squared test, euclidean distance, or Mahalanobis distance. While a sufficient amount of example spectra can be used to identify almost any measured spectrum, the drawback of this method is the time necessary to compare a measured spectrum to the library and the computer memory necessary to store said library. This method also may have difficulty when mixtures of isotopes are considered, although work is being done to correct this \cite{mattingly2010}.

These algorithms largely incorporate book knowledge. By further incorporating the intuition identified by Rawool-Sullivan et al., these algorithms may be improved. By carefully creating a training set of spectra and intelligently applying deep learning architectures, a machine learning approach to automated gamma-ray spectroscopy may be able to marry book knowledge and a trained spectroscopists intuition.


\section{Automated Isotope Identification Using ANNs}

There have been a number of published papers which apply ANNs to automated isotope identification. ANNs have been applied to peak fitting \cite{Abdel-Aal2002}, isotope identification \cite{Abdel-Aal1996, Medhat2012}, and activity estimation \cite{Abdel-Aal1996, Vigneron1996}. 

Peak fitting methods include applying 


Many of these works rely on ROI methods \cite{Pilato1999}, feature extraction \cite{Chen2009}, high-resolution gamma-ray spectra as the input to the ANN \cite{Yoshida2002}, small libraries of isotopes, and assume perfectly calibrated detectors. ANN training methods created for high-resolution gamma-ray spectra may not perform well when trained using low-resolution spectra. Because of the large discrepancy in resolution, the features exploited by a ANN trained on high-resolution spectra would be different than low-resolution spectra. In addition to this, ANN training that relies on ROI methods may not perform well when ROIs overlap significantly with large libraries of isotopes. Feature extraction and ROI methods may also falter when the background radiation field is unknown or the detector's calibration is unreliable.  

% ANNs using feature extraction on 3x3 NaI detector \cite{HE2018}.

\section{Chapter Conclusion}

There are two main questions addressed in this work. The first is question addresses what physics should be incorporated into a synthetic dataset of gamma-ray spectra for different problems in isotope identification and quantification. The second question addresses how different ANNs architectures perform on these datasets. Gamma-ray spectroscopists often use intuition when identifying isotopes in spectra. ANNs mimic this abstract analysis, synthesizing features of a gamma-ray spectrum in non-intuitive ways. Exploiting this intuition may overcome common hurdles encountered by other isotope identification algorithms.

To overcome the issues outlined above, instead of training an ANN using predetermined ROIs or feature extraction, it may be better to train the ANN with an entire gamma-ray spectrum. Due to perceived training issues and computational requirements associated with using the entire spectrum \cite{Pilato1999,Yoshida2002}, this approach has been avoided in previous works. Despite this, it has been shown that training an ANN using the full spectrum is a viable method to identify and quantify isotopes in gamma-ray spectra \cite{kamuda2017,kamudaThesis2017,kamuda2018}. There is also evidence that this method can overcome common  gamma-ray spectroscopy issues like gain shifts due to changes in temperature and identifying isotopes in spectra without clear isotopic features.

The solution outlined in this work is to perform radioisotope identification and quantification simultaneously using an ANN. Skipping automated peak-fitting routines releases the algorithm from the burden of determining proper peak-fitting subroutines for the variety of cases in which a peak may be seen. A photopeak can typically be fit using a Gaussian distribution added to a linear baseline. This baseline changes based on its location in another photopeak's Compton continuum. In spectra where peaks overlap, deconvolution techniques may be needed to resolve constituent peaks. An unknown gain or poorly calibrated detector will shift photopeaks, further complicating a spectrum. Instead of making deterministic rules for each of these cases, a machine learning algorithm can be taught to recognize and handle them automatically.

Traditionally, once photopeaks are found, another algorithm is needed to measure the locations of peak centroids and additional information (peak area, area uncertainty) to identify what isotopes are present in a spectrum. This process adds computation time and again suffers from the need to be modified to handle changes in a spectrum as described above. Also, the algorithm that performs identification based on peak information must be tailored to the peak-fitting routine. This requires unique algorithms to be created for different detector materials and sizes, as they change the shape of the spectrum. Using an ANN with an appropriate training set, these problems can be avoided.

By allowing a machine to learn the important features of a gamma-ray spectrum, the problem of determining the best analysis technique given a spectrum with significant features overlap and unknown calibration is avoided. This method is ideal for low-resolution gamma-ray spectroscopy for mixtures of radioisotopes for a number of reasons. Because this method uses simulated gamma-ray spectra to train the ANN, there is no restriction on the number of isotopes allowed in the library or their identity. This allows the ANN training set to be cheaply generated using mixtures of exotic, dangerous, or short-lived isotopes that are not easily accessible in an academic setting. 

Another benefit of using a training set of simulated spectra is that an ANN may be trained for a specific scenario using a custom isotope library. The isotope library requirements for a border patrol, which may focus on distinguishing possibly shielded medical isotopes and NORM from SNM, are very different from the isotope library needed to perform post-detonation nuclear forensics. Because spectra can be generated with different calibrations, this method can be insensitive to a range of calibration shifts due to temperature change or operator error. This insensitivity would allow isotope identification and quantification to be performed without prior knowledge of the detectors calibration.

Experiments in this work fall into two categories: advanced simulated datasets and advanced machine learning architectures. The first advanced dataset is based on the the American National Standards Institute performance criteria for hand-held instruments for the detection and identification of radionuclides, ANSI N42-34-2006 \cite{ANSI}. This dataset will incorporate the effects of shielding, calibration drift, and unknown background. The second dataset will be based on a zero knowledge measurement for automated uranium enrichment calculations. The performance of models trained on both datasets will be assessed on a series of real and simulated gamma-ray spectra. The machine learning architectures explored will include a dense neural network (DNN), dense autoencoder (DAE), convolutional neural networks (CNNs), and convolutional autoencoder (CAE).