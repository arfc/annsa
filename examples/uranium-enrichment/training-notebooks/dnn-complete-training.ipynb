{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import model, training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from annsa.load_dataset import dataset_to_spectrakeys\n",
    "from annsa.model_classes import build_dnn_model, compile_model\n",
    "from annsa.load_pretrained_network import load_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(os.path.join('dataset_generation',\n",
    "                               'uenrichment_dataset_100000.npy'))\n",
    "training_spectra = np.array(dataset.item()['spectra'], dtype='float64')\n",
    "all_keys = np.array(dataset.item()['keys'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_id = os.path.join('..',\n",
    "                               'source-interdiction',\n",
    "                               'final_training_notebooks',\n",
    "                               'final-models',\n",
    "                               'learningcurve-dnn-full-final-features',\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = load_features(architecture_id)\n",
    "model_features.input_dim = 1024\n",
    "model_features.dropout_rate = model_features.dropout_probability\n",
    "model_features.loss = tf.keras.losses.mean_squared_error\n",
    "model_features.optimizer = tf.keras.optimizers.Adam\n",
    "model_features.output_function = tf.nn.sigmoid\n",
    "model_features.output_size = 1\n",
    "model_features.metrics = ['mse']\n",
    "model_features.learning_rate = model_features.learining_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "patience = 10\n",
    "\n",
    "model_id_save_as = 'dnn-full'\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_mean_squared_error',\n",
    "    patience=patience,\n",
    "    mode='min',\n",
    "    min_delta=0.01,\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_spectra_scaled = model_features.scaler.transform(training_spectra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/200\n",
      "80000/80000 [==============================] - 11s 140us/sample - loss: 3.9937 - mean_squared_error: 0.1343 - val_loss: 0.2061 - val_mean_squared_error: 0.0615\n",
      "Epoch 2/200\n",
      "80000/80000 [==============================] - 11s 132us/sample - loss: 0.1223 - mean_squared_error: 0.0583 - val_loss: 0.0743 - val_mean_squared_error: 0.0487\n",
      "Epoch 3/200\n",
      "80000/80000 [==============================] - 11s 133us/sample - loss: 0.0705 - mean_squared_error: 0.0537 - val_loss: 0.0587 - val_mean_squared_error: 0.0465\n",
      "Epoch 4/200\n",
      "80000/80000 [==============================] - 11s 133us/sample - loss: 0.0626 - mean_squared_error: 0.0521 - val_loss: 0.0569 - val_mean_squared_error: 0.0476\n",
      "Epoch 5/200\n",
      "80000/80000 [==============================] - 11s 133us/sample - loss: 0.0591 - mean_squared_error: 0.0505 - val_loss: 0.0707 - val_mean_squared_error: 0.0627\n",
      "Epoch 6/200\n",
      "80000/80000 [==============================] - 11s 134us/sample - loss: 0.0564 - mean_squared_error: 0.0487 - val_loss: 0.0490 - val_mean_squared_error: 0.0418\n",
      "Epoch 7/200\n",
      "80000/80000 [==============================] - 11s 132us/sample - loss: 0.0552 - mean_squared_error: 0.0480 - val_loss: 0.0511 - val_mean_squared_error: 0.0445\n",
      "Epoch 8/200\n",
      "80000/80000 [==============================] - 11s 132us/sample - loss: 0.0528 - mean_squared_error: 0.0464 - val_loss: 0.0480 - val_mean_squared_error: 0.0414\n",
      "Epoch 9/200\n",
      "80000/80000 [==============================] - 11s 132us/sample - loss: 0.0513 - mean_squared_error: 0.0451 - val_loss: 0.0535 - val_mean_squared_error: 0.0472\n",
      "Epoch 10/200\n",
      "80000/80000 [==============================] - 11s 132us/sample - loss: 0.0512 - mean_squared_error: 0.0451 - val_loss: 0.0450 - val_mean_squared_error: 0.0390\n",
      "Epoch 11/200\n",
      "80000/80000 [==============================] - 11s 133us/sample - loss: 0.0491 - mean_squared_error: 0.0434 - val_loss: 0.0545 - val_mean_squared_error: 0.0488\n",
      "Epoch 12/200\n",
      "80000/80000 [==============================] - 11s 134us/sample - loss: 0.0491 - mean_squared_error: 0.0435 - val_loss: 0.0434 - val_mean_squared_error: 0.0379\n",
      "Epoch 13/200\n",
      "80000/80000 [==============================] - 11s 135us/sample - loss: 0.0484 - mean_squared_error: 0.0430 - val_loss: 0.0519 - val_mean_squared_error: 0.0467\n",
      "Epoch 14/200\n",
      "80000/80000 [==============================] - 11s 136us/sample - loss: 0.0480 - mean_squared_error: 0.0427 - val_loss: 0.0436 - val_mean_squared_error: 0.0388\n",
      "Epoch 15/200\n",
      "80000/80000 [==============================] - 11s 134us/sample - loss: 0.0469 - mean_squared_error: 0.0418 - val_loss: 0.0435 - val_mean_squared_error: 0.0384\n",
      "Epoch 16/200\n",
      "80000/80000 [==============================] - 11s 135us/sample - loss: 0.0465 - mean_squared_error: 0.0416 - val_loss: 0.0400 - val_mean_squared_error: 0.0345\n",
      "Epoch 17/200\n",
      "80000/80000 [==============================] - 11s 135us/sample - loss: 0.0468 - mean_squared_error: 0.0418 - val_loss: 0.0491 - val_mean_squared_error: 0.0440\n",
      "Epoch 18/200\n",
      "80000/80000 [==============================] - 11s 132us/sample - loss: 0.0455 - mean_squared_error: 0.0406 - val_loss: 0.0388 - val_mean_squared_error: 0.0339\n",
      "Epoch 19/200\n",
      "80000/80000 [==============================] - 11s 133us/sample - loss: 0.0453 - mean_squared_error: 0.0404 - val_loss: 0.0416 - val_mean_squared_error: 0.0367\n",
      "Epoch 20/200\n",
      "80000/80000 [==============================] - 11s 135us/sample - loss: 0.0461 - mean_squared_error: 0.0412 - val_loss: 0.0412 - val_mean_squared_error: 0.0364\n",
      "Epoch 21/200\n",
      "80000/80000 [==============================] - 11s 135us/sample - loss: 0.0463 - mean_squared_error: 0.0414 - val_loss: 0.0411 - val_mean_squared_error: 0.0363\n",
      "Epoch 22/200\n",
      "80000/80000 [==============================] - 11s 142us/sample - loss: 0.0462 - mean_squared_error: 0.0412 - val_loss: 0.0384 - val_mean_squared_error: 0.0336\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/200\n",
      "80000/80000 [==============================] - 12s 148us/sample - loss: 3.7765 - mean_squared_error: 0.1349 - val_loss: 0.2033 - val_mean_squared_error: 0.0592\n",
      "Epoch 2/200\n",
      "80000/80000 [==============================] - 11s 136us/sample - loss: 0.1220 - mean_squared_error: 0.0571 - val_loss: 0.0735 - val_mean_squared_error: 0.0482\n",
      "Epoch 3/200\n",
      "80000/80000 [==============================] - 11s 136us/sample - loss: 0.0688 - mean_squared_error: 0.0527 - val_loss: 0.0652 - val_mean_squared_error: 0.0535\n",
      "Epoch 4/200\n",
      "80000/80000 [==============================] - 11s 134us/sample - loss: 0.0607 - mean_squared_error: 0.0510 - val_loss: 0.0566 - val_mean_squared_error: 0.0470\n",
      "Epoch 5/200\n",
      "80000/80000 [==============================] - 11s 134us/sample - loss: 0.0567 - mean_squared_error: 0.0485 - val_loss: 0.0584 - val_mean_squared_error: 0.0501\n",
      "Epoch 6/200\n",
      "80000/80000 [==============================] - 11s 134us/sample - loss: 0.0552 - mean_squared_error: 0.0477 - val_loss: 0.0481 - val_mean_squared_error: 0.0411\n",
      "Epoch 7/200\n",
      "80000/80000 [==============================] - 11s 132us/sample - loss: 0.0532 - mean_squared_error: 0.0462 - val_loss: 0.0437 - val_mean_squared_error: 0.0372\n",
      "Epoch 8/200\n",
      "80000/80000 [==============================] - 11s 134us/sample - loss: 0.0506 - mean_squared_error: 0.0442 - val_loss: 0.0426 - val_mean_squared_error: 0.0367\n",
      "Epoch 9/200\n",
      "80000/80000 [==============================] - 11s 133us/sample - loss: 0.0508 - mean_squared_error: 0.0446 - val_loss: 0.0431 - val_mean_squared_error: 0.0374\n",
      "Epoch 10/200\n",
      "80000/80000 [==============================] - 10s 130us/sample - loss: 0.0491 - mean_squared_error: 0.0432 - val_loss: 0.0435 - val_mean_squared_error: 0.0382\n",
      "Epoch 11/200\n",
      "80000/80000 [==============================] - 10s 129us/sample - loss: 0.0476 - mean_squared_error: 0.0421 - val_loss: 0.0427 - val_mean_squared_error: 0.0372\n",
      "Epoch 12/200\n",
      "80000/80000 [==============================] - 10s 128us/sample - loss: 0.0474 - mean_squared_error: 0.0419 - val_loss: 0.0479 - val_mean_squared_error: 0.0424\n",
      "Epoch 13/200\n",
      "80000/80000 [==============================] - 10s 130us/sample - loss: 0.0477 - mean_squared_error: 0.0423 - val_loss: 0.0412 - val_mean_squared_error: 0.0359\n",
      "Epoch 14/200\n",
      "80000/80000 [==============================] - 10s 129us/sample - loss: 0.0462 - mean_squared_error: 0.0409 - val_loss: 0.0390 - val_mean_squared_error: 0.0341\n",
      "Epoch 15/200\n",
      "80000/80000 [==============================] - 10s 129us/sample - loss: 0.0464 - mean_squared_error: 0.0411 - val_loss: 0.0403 - val_mean_squared_error: 0.0351\n",
      "Epoch 16/200\n",
      "80000/80000 [==============================] - 10s 129us/sample - loss: 0.0461 - mean_squared_error: 0.0410 - val_loss: 0.0406 - val_mean_squared_error: 0.0358\n",
      "Epoch 17/200\n",
      "80000/80000 [==============================] - 11s 139us/sample - loss: 0.0471 - mean_squared_error: 0.0420 - val_loss: 0.0379 - val_mean_squared_error: 0.0329\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/200\n",
      "80000/80000 [==============================] - 11s 142us/sample - loss: 3.8121 - mean_squared_error: 0.1225 - val_loss: 0.2129 - val_mean_squared_error: 0.0612\n",
      "Epoch 2/200\n",
      "80000/80000 [==============================] - 10s 129us/sample - loss: 0.1262 - mean_squared_error: 0.0570 - val_loss: 0.0866 - val_mean_squared_error: 0.0582\n",
      "Epoch 3/200\n",
      "80000/80000 [==============================] - 10s 129us/sample - loss: 0.0710 - mean_squared_error: 0.0527 - val_loss: 0.0660 - val_mean_squared_error: 0.0529\n",
      "Epoch 4/200\n",
      "80000/80000 [==============================] - 10s 129us/sample - loss: 0.0616 - mean_squared_error: 0.0507 - val_loss: 0.0542 - val_mean_squared_error: 0.0445\n",
      "Epoch 5/200\n",
      "80000/80000 [==============================] - 10s 127us/sample - loss: 0.0579 - mean_squared_error: 0.0493 - val_loss: 0.0520 - val_mean_squared_error: 0.0445\n",
      "Epoch 6/200\n",
      "80000/80000 [==============================] - 10s 127us/sample - loss: 0.0563 - mean_squared_error: 0.0489 - val_loss: 0.0567 - val_mean_squared_error: 0.0500\n",
      "Epoch 7/200\n",
      "80000/80000 [==============================] - 10s 127us/sample - loss: 0.0540 - mean_squared_error: 0.0473 - val_loss: 0.0481 - val_mean_squared_error: 0.0420\n",
      "Epoch 8/200\n",
      "80000/80000 [==============================] - 10s 127us/sample - loss: 0.0528 - mean_squared_error: 0.0466 - val_loss: 0.0540 - val_mean_squared_error: 0.0481\n",
      "Epoch 9/200\n",
      "80000/80000 [==============================] - 10s 123us/sample - loss: 0.0520 - mean_squared_error: 0.0461 - val_loss: 0.0471 - val_mean_squared_error: 0.0415\n",
      "Epoch 10/200\n",
      "80000/80000 [==============================] - 10s 125us/sample - loss: 0.0515 - mean_squared_error: 0.0455 - val_loss: 0.0452 - val_mean_squared_error: 0.0395\n",
      "Epoch 11/200\n",
      "80000/80000 [==============================] - 10s 123us/sample - loss: 0.0502 - mean_squared_error: 0.0445 - val_loss: 0.0433 - val_mean_squared_error: 0.0377\n",
      "Epoch 12/200\n",
      "80000/80000 [==============================] - 10s 124us/sample - loss: 0.0498 - mean_squared_error: 0.0443 - val_loss: 0.0481 - val_mean_squared_error: 0.0422\n",
      "Epoch 13/200\n",
      "80000/80000 [==============================] - 10s 124us/sample - loss: 0.0484 - mean_squared_error: 0.0428 - val_loss: 0.0493 - val_mean_squared_error: 0.0440\n",
      "Epoch 14/200\n",
      "80000/80000 [==============================] - 11s 134us/sample - loss: 0.0473 - mean_squared_error: 0.0419 - val_loss: 0.0487 - val_mean_squared_error: 0.0436\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/200\n",
      "80000/80000 [==============================] - 11s 134us/sample - loss: 3.7226 - mean_squared_error: 0.1354 - val_loss: 0.2008 - val_mean_squared_error: 0.0674\n",
      "Epoch 2/200\n",
      "80000/80000 [==============================] - 10s 122us/sample - loss: 0.1184 - mean_squared_error: 0.0567 - val_loss: 0.0720 - val_mean_squared_error: 0.0470\n",
      "Epoch 3/200\n",
      "80000/80000 [==============================] - 10s 122us/sample - loss: 0.0668 - mean_squared_error: 0.0514 - val_loss: 0.0581 - val_mean_squared_error: 0.0477\n",
      "Epoch 4/200\n",
      "80000/80000 [==============================] - 10s 122us/sample - loss: 0.0598 - mean_squared_error: 0.0504 - val_loss: 0.0551 - val_mean_squared_error: 0.0470\n",
      "Epoch 5/200\n",
      "80000/80000 [==============================] - 10s 122us/sample - loss: 0.0568 - mean_squared_error: 0.0488 - val_loss: 0.0722 - val_mean_squared_error: 0.0649\n",
      "Epoch 6/200\n",
      "80000/80000 [==============================] - 10s 122us/sample - loss: 0.0545 - mean_squared_error: 0.0475 - val_loss: 0.0462 - val_mean_squared_error: 0.0398\n",
      "Epoch 7/200\n",
      "80000/80000 [==============================] - 10s 122us/sample - loss: 0.0532 - mean_squared_error: 0.0468 - val_loss: 0.0512 - val_mean_squared_error: 0.0442\n",
      "Epoch 8/200\n",
      "80000/80000 [==============================] - 10s 122us/sample - loss: 0.0517 - mean_squared_error: 0.0454 - val_loss: 0.0453 - val_mean_squared_error: 0.0390\n",
      "Epoch 9/200\n",
      "80000/80000 [==============================] - 10s 121us/sample - loss: 0.0505 - mean_squared_error: 0.0445 - val_loss: 0.0431 - val_mean_squared_error: 0.0373\n",
      "Epoch 10/200\n",
      "80000/80000 [==============================] - 9s 119us/sample - loss: 0.0495 - mean_squared_error: 0.0437 - val_loss: 0.0453 - val_mean_squared_error: 0.0392\n",
      "Epoch 11/200\n",
      "80000/80000 [==============================] - 10s 119us/sample - loss: 0.0481 - mean_squared_error: 0.0424 - val_loss: 0.0420 - val_mean_squared_error: 0.0361\n",
      "Epoch 12/200\n",
      "80000/80000 [==============================] - 10s 120us/sample - loss: 0.0496 - mean_squared_error: 0.0438 - val_loss: 0.0436 - val_mean_squared_error: 0.0381\n",
      "Epoch 13/200\n",
      "80000/80000 [==============================] - 10s 120us/sample - loss: 0.0481 - mean_squared_error: 0.0427 - val_loss: 0.0470 - val_mean_squared_error: 0.0416\n",
      "Epoch 14/200\n",
      "80000/80000 [==============================] - 10s 120us/sample - loss: 0.0475 - mean_squared_error: 0.0423 - val_loss: 0.0439 - val_mean_squared_error: 0.0387\n",
      "Epoch 15/200\n",
      "80000/80000 [==============================] - 10s 120us/sample - loss: 0.0478 - mean_squared_error: 0.0425 - val_loss: 0.0465 - val_mean_squared_error: 0.0406\n",
      "Epoch 16/200\n",
      "80000/80000 [==============================] - 10s 120us/sample - loss: 0.0473 - mean_squared_error: 0.0421 - val_loss: 0.0408 - val_mean_squared_error: 0.0357\n",
      "Epoch 17/200\n",
      "80000/80000 [==============================] - 10s 120us/sample - loss: 0.0462 - mean_squared_error: 0.0412 - val_loss: 0.0405 - val_mean_squared_error: 0.0356\n",
      "Epoch 18/200\n",
      "80000/80000 [==============================] - 10s 120us/sample - loss: 0.0472 - mean_squared_error: 0.0422 - val_loss: 0.0441 - val_mean_squared_error: 0.0388\n",
      "Epoch 19/200\n",
      "80000/80000 [==============================] - 10s 120us/sample - loss: 0.0455 - mean_squared_error: 0.0405 - val_loss: 0.0382 - val_mean_squared_error: 0.0335\n",
      "Epoch 20/200\n",
      "80000/80000 [==============================] - 10s 120us/sample - loss: 0.0453 - mean_squared_error: 0.0404 - val_loss: 0.0482 - val_mean_squared_error: 0.0434\n",
      "Epoch 21/200\n",
      "80000/80000 [==============================] - 10s 130us/sample - loss: 0.0462 - mean_squared_error: 0.0412 - val_loss: 0.0572 - val_mean_squared_error: 0.0521\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/200\n",
      "80000/80000 [==============================] - 11s 132us/sample - loss: 3.9536 - mean_squared_error: 0.1493 - val_loss: 0.2176 - val_mean_squared_error: 0.0656\n",
      "Epoch 2/200\n",
      "80000/80000 [==============================] - 10s 121us/sample - loss: 0.1235 - mean_squared_error: 0.0583 - val_loss: 0.0831 - val_mean_squared_error: 0.0599\n",
      "Epoch 3/200\n",
      "80000/80000 [==============================] - 10s 119us/sample - loss: 0.0681 - mean_squared_error: 0.0537 - val_loss: 0.0604 - val_mean_squared_error: 0.0494\n",
      "Epoch 4/200\n",
      "80000/80000 [==============================] - 9s 117us/sample - loss: 0.0595 - mean_squared_error: 0.0504 - val_loss: 0.0546 - val_mean_squared_error: 0.0469\n",
      "Epoch 5/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0556 - mean_squared_error: 0.0479 - val_loss: 0.0598 - val_mean_squared_error: 0.0518\n",
      "Epoch 6/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0543 - mean_squared_error: 0.0472 - val_loss: 0.0550 - val_mean_squared_error: 0.0477\n",
      "Epoch 7/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0539 - mean_squared_error: 0.0470 - val_loss: 0.0634 - val_mean_squared_error: 0.0568\n",
      "Epoch 8/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0532 - mean_squared_error: 0.0466 - val_loss: 0.0485 - val_mean_squared_error: 0.0423\n",
      "Epoch 9/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0499 - mean_squared_error: 0.0441 - val_loss: 0.0652 - val_mean_squared_error: 0.0596\n",
      "Epoch 10/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0496 - mean_squared_error: 0.0441 - val_loss: 0.0456 - val_mean_squared_error: 0.0403\n",
      "Epoch 11/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0487 - mean_squared_error: 0.0434 - val_loss: 0.0431 - val_mean_squared_error: 0.0380\n",
      "Epoch 12/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0494 - mean_squared_error: 0.0441 - val_loss: 0.0450 - val_mean_squared_error: 0.0401\n",
      "Epoch 13/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0485 - mean_squared_error: 0.0436 - val_loss: 0.0411 - val_mean_squared_error: 0.0362\n",
      "Epoch 14/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0486 - mean_squared_error: 0.0438 - val_loss: 0.0474 - val_mean_squared_error: 0.0426\n",
      "Epoch 15/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0491 - mean_squared_error: 0.0443 - val_loss: 0.0450 - val_mean_squared_error: 0.0399\n",
      "Epoch 16/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0482 - mean_squared_error: 0.0435 - val_loss: 0.0471 - val_mean_squared_error: 0.0422\n",
      "Epoch 17/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0489 - mean_squared_error: 0.0442 - val_loss: 0.0504 - val_mean_squared_error: 0.0458\n",
      "Epoch 18/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0493 - mean_squared_error: 0.0447 - val_loss: 0.0454 - val_mean_squared_error: 0.0408\n",
      "Epoch 19/200\n",
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0476 - mean_squared_error: 0.0431 - val_loss: 0.0416 - val_mean_squared_error: 0.0372\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000/80000 [==============================] - 9s 116us/sample - loss: 0.0483 - mean_squared_error: 0.0438 - val_loss: 0.0422 - val_mean_squared_error: 0.0375\n",
      "Epoch 21/200\n",
      "80000/80000 [==============================] - 10s 126us/sample - loss: 0.0484 - mean_squared_error: 0.0439 - val_loss: 0.0437 - val_mean_squared_error: 0.0392\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "k = 0\n",
    "for train_index, validation_index in kf.split(training_spectra_scaled):\n",
    "    model = compile_model(\n",
    "        build_dnn_model,\n",
    "        model_features)\n",
    "\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger(\n",
    "        os.path.join('final-models-keras/',\n",
    "        model_id_save_as+'_fold' + str(k) + '.log')\n",
    "\n",
    "    output = model.fit(\n",
    "        x=training_spectra_scaled[train_index],\n",
    "        y=all_keys[train_index],\n",
    "        epochs=num_epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(training_spectra_scaled[validation_index],\n",
    "                         all_keys[validation_index]),\n",
    "        shuffle=True,\n",
    "        callbacks=[earlystop_callback, csv_logger],\n",
    "    )\n",
    "    model.save(\n",
    "        os.path.join('final-models-keras',\n",
    "                     model_id_save_as + '_fold' + str(k) + '.hdf5')\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36_update)",
   "language": "python",
   "name": "conda_tensorflow_p36_update"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
