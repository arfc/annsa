{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/Notebooks/annsa/\")\n",
    "\n",
    "import tensorflow.contrib.eager as tfe\n",
    "from sklearn import datasets, preprocessing, model_selection\n",
    "\n",
    "import annsa as an\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.init_ops import glorot_uniform_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class simple_nn(tf.keras.Model):\n",
    "    def __init__(self, model_features):\n",
    "        super(simple_nn, self).__init__()\n",
    "        \"\"\" Define here the layers used during the forward-pass \n",
    "            of the neural network.\n",
    "        \"\"\"\n",
    "        l2_regularization_scale=model_features.l2_regularization_scale\n",
    "        dropout_probability=model_features.dropout_probability\n",
    "        nodes_layer_1=model_features.nodes_layer_1\n",
    "        nodes_layer_2=model_features.nodes_layer_2      \n",
    "        # define l2 regularization\n",
    "        self.regularizer = tf.keras.regularizers.l2(l=l2_regularization_scale)        \n",
    "        # Hidden layer.\n",
    "        self.dense_layer1 = tf.layers.Dense(nodes_layer_1, \n",
    "                                            activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.truncated_normal_initializer(stddev = 1/np.sqrt(1024)),\n",
    "                                            #kernel_initializer=glorot_uniform_initializer(),\n",
    "                                            kernel_regularizer=self.regularizer)\n",
    "        self.drop1 = tf.layers.Dropout(dropout_probability)\n",
    "        self.dense_layer2 = tf.layers.Dense(nodes_layer_2,\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            kernel_initializer=tf.truncated_normal_initializer(stddev = 1/np.sqrt(nodes_layer_1)),\n",
    "                                            #kernel_initializer=glorot_uniform_initializer(),\n",
    "                                            kernel_regularizer=self.regularizer)\n",
    "        self.drop2 = tf.layers.Dropout(dropout_probability)\n",
    "        # Output layer. No activation.\n",
    "        self.output_layer = tf.layers.Dense(32, activation=None)\n",
    "        \n",
    "    def predict_logits(self, input_data, training=True):\n",
    "        \"\"\" Runs a forward-pass through the network. Only outputs logits for loss function. \n",
    "            This is because tf.nn.softmax_cross_entropy_with_logits calculates softmax internally.   \n",
    "            Note, dropout training is true here.\n",
    "            Args:\n",
    "                input_data: 2D tensor of shape (n_samples, n_features).   \n",
    "            Returns:\n",
    "                logits: unnormalized predictions.\n",
    "        \"\"\"\n",
    "        # Reshape input data\n",
    "        x=tf.reshape(input_data,[-1,1,1024])\n",
    "        x=self.dense_layer1(x)\n",
    "        x=self.drop1(x,training)\n",
    "        x=self.dense_layer2(x)\n",
    "        x=self.drop2(x,training)\n",
    "        logits=self.output_layer(x)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def predict(self, input_data, training=False):\n",
    "        \"\"\" Runs a forward-pass through the network and uses softmax output. Dropout training is off, this is \n",
    "            not used for gradient calculations in loss function.\n",
    "            Args:\n",
    "                input_data: 2D tensor of shape (n_samples, n_features).   \n",
    "            Returns:\n",
    "                logits: unnormalized predictions.\n",
    "        \"\"\"\n",
    "        # Reshape input data\n",
    "        x = tf.reshape(input_data,[-1,1,1024])\n",
    "        x = self.dense_layer1(x)\n",
    "        x = self.drop1(x,training)\n",
    "        x = self.dense_layer2(x)\n",
    "        x = self.drop2(x,training)\n",
    "        x = self.output_layer(x)\n",
    "        outputs = tf.nn.softmax(x)\n",
    "        return outputs\n",
    "    \n",
    "    def loss_fn(self, input_data, target, training=True):\n",
    "        \"\"\" Defines the loss function used during \n",
    "            training.         \n",
    "        \"\"\"\n",
    "        logits = self.predict_logits(input_data, training)\n",
    "        cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=logits))\n",
    "        l2_weights = [self.weights[i] for i in range(len(self.weights)) if i%2==0]\n",
    "        l2_loss = tf.contrib.layers.apply_regularization(self.regularizer, l2_weights)\n",
    "        loss = cross_entropy_loss+l2_loss\n",
    "        return loss\n",
    "    \n",
    "    def grads_fn(self, input_data, target):\n",
    "        \"\"\" Dynamically computes the gradients of the loss value\n",
    "            with respect to the parameters of the model, in each\n",
    "            forward pass.\n",
    "        \"\"\"\n",
    "        with tfe.GradientTape() as tape:\n",
    "            loss = self.loss_fn(input_data, target) \n",
    "        return tape.gradient(loss, self.variables)\n",
    "    \n",
    "    def fit(self, input_data, target, optimizer, num_epochs=500, verbose=50):\n",
    "        \"\"\" Function to train the model, using the selected optimizer and\n",
    "            for the desired number of epochs.\n",
    "        \"\"\"\n",
    "        for i in range(num_epochs):\n",
    "            grads = self.grads_fn(input_data, target)\n",
    "            optimizer.apply_gradients(zip(grads, self.variables))\n",
    "            if (i==0) | ((i+1)%verbose==0):\n",
    "                print('Loss at epoch %d: %f' %(i+1, self.loss_fn(input_data, target, training=False).numpy()))\n",
    "                \n",
    "    \n",
    "    def fit_batch(self, train_dataset,test_dataset, optimizer, num_epochs=50, verbose=50):\n",
    "        \"\"\" Function to train the model, using the selected optimizer and\n",
    "            for the desired number of epochs.\n",
    "        \"\"\"\n",
    "        all_loss_train=[]\n",
    "        all_loss_test=[0]\n",
    "        for i in range(num_epochs):\n",
    "            for (input_data, target) in tfe.Iterator(train_dataset.shuffle(1e5).batch(512)):\n",
    "                grads = self.grads_fn(input_data, target)\n",
    "                optimizer.apply_gradients(zip(grads, self.variables))\n",
    "                all_loss_train.append(self.loss_fn(input_data, target, training=False).numpy())\n",
    "                all_loss_test.append(self.loss_fn(test_dataset[0],test_dataset[1], training=False).numpy())\n",
    "            if (i==0) | ((i+1)%verbose==0):\n",
    "                print('Loss at epoch %d: %3.2f %3.2f' %(i+1, np.average(all_loss_train[-10:]), np.average(all_loss_test[-10:])))\n",
    "        return all_loss_train, all_loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class model_features(object):\n",
    "    \n",
    "    def __init__(self,learining_rate,\n",
    "                      l2_regularization_scale,\n",
    "                      dropout_probability,\n",
    "                      nodes_layer_1,\n",
    "                      nodes_layer_2\n",
    "                ):\n",
    "        self.learining_rate=learining_rate\n",
    "        self.l2_regularization_scale=l2_regularization_scale\n",
    "        self.dropout_probability=dropout_probability\n",
    "        self.nodes_layer_1=nodes_layer_1\n",
    "        self.nodes_layer_2=nodes_layer_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data = np.load('/home/ubuntu/Notebooks/GADRAS_ANN_work/Project_SORMA18/Dataset_Details/spectrum_data_1-simplex_1E6.npy')[:-10000]\n",
    "training_keys = np.load('/home/ubuntu/Notebooks/GADRAS_ANN_work/Project_SORMA18/Dataset_Details/key_data_1-simplex_1E6.npy')[:-10000]\n",
    "\n",
    "training_data = an.log_normalize(training_data)\n",
    "training_keys = an.normalize_data(training_keys)\n",
    "\n",
    "X_tensor = tf.constant(training_data)\n",
    "y_tensor = tf.constant(training_keys)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_data = np.load('/home/ubuntu/Notebooks/GADRAS_ANN_work/Project_SORMA18/Dataset_Details/spectrum_data_1-simplex_1E6.npy')[-1000:]\n",
    "testing_keys = np.load('/home/ubuntu/Notebooks/GADRAS_ANN_work/Project_SORMA18/Dataset_Details/key_data_1-simplex_1E6.npy')[-1000:]\n",
    "\n",
    "testing_data = an.log_normalize(testing_data)\n",
    "testing_keys = an.normalize_data(testing_keys)\n",
    "\n",
    "X_tensor = tf.constant(testing_data)\n",
    "y_tensor = tf.constant(testing_keys)\n",
    "\n",
    "test_dataset = (testing_data, testing_keys)\n",
    "#test_dataset = tf.data.Dataset.from_tensor_slices((X_tensor, y_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define an optimizer, model, and train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_model_features = model_features(learining_rate=4.5e-3,\n",
    "                                    l2_regularization_scale=1.09e-3,\n",
    "                                    dropout_probability=1.0-0.96,\n",
    "                                    nodes_layer_1=449,\n",
    "                                    nodes_layer_2=205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 1.67 1.67\n",
      "Loss at epoch 2: 1.44 1.46\n",
      "Loss at epoch 3: 1.39 1.41\n",
      "Loss at epoch 4: 1.39 1.41\n",
      "Loss at epoch 5: 1.37 1.39\n",
      "Loss at epoch 6: 1.34 1.36\n",
      "Loss at epoch 7: 1.33 1.35\n",
      "Loss at epoch 8: 1.33 1.34\n",
      "Loss at epoch 9: 1.34 1.36\n",
      "Loss at epoch 10: 1.33 1.34\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(new_model_features.learining_rate)\n",
    "model = simple_nn(new_model_features)\n",
    "all_loss_train, all_loss_test = model.fit_batch(train_dataset,test_dataset, optimizer, num_epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc35c1800d0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+n8+AddLkg/4/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc35c180110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_loss_train[10:])\n",
    "plt.plot(all_loss_test[10:])\n",
    "#plt.xlim([0,500])\n",
    "#plt.ylim([2.9,3.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Ba133', 0.8499593661113368)\n",
      "('Back_Th', 0.11905729378301504)\n",
      "('Back_K', 0.01574563185696871)\n",
      "('Back_U', 0.015237708248679399)\n",
      "('U235', 0.0)\n",
      "\n",
      "\n",
      "('Ba133', 0.8939623790696212)\n",
      "('Back_Th', 0.03925428874613645)\n",
      "('Back_U', 0.03395918333178101)\n",
      "('Back_K', 0.017143611190704938)\n",
      "('I131', 0.010330148635405682)\n"
     ]
    }
   ],
   "source": [
    "index = 100\n",
    "\n",
    "logits_test = model.predict(training_data[index])\n",
    "\n",
    "an.results2(training_keys[index],5)\n",
    "print '\\n'\n",
    "an.results2(logits_test.numpy()[0][0],5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
