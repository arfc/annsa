{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "model_id = 'DNN-hpsearch-easy'\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from annsa.template_sampling import *\n",
    "from annsa.load_pretrained_network import save_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperparameter_models import make_dense_model as make_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.eager as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import model, training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annsa.model_classes import (dnn_model_features,\n",
    "                                 DNN,\n",
    "                                 save_model,\n",
    "                                 train_earlystop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('../dataset_generation/hyperparametersearch_dataset_100_easy.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spectra = np.float64(np.add(dataset.item()['sources'], dataset.item()['backgrounds']))\n",
    "all_keys = dataset.item()['keys']\n",
    "\n",
    "mlb=LabelBinarizer()\n",
    "\n",
    "all_keys_binarized = mlb.fit_transform(all_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_hyperparameters_to_search = 256\n",
    "earlystop_errors_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=5)\n",
    "testing_errors = []\n",
    "all_kf_errors = []\n",
    "\n",
    "for network_id in range(number_hyperparameters_to_search):\n",
    "    print(network_id)\n",
    "    model, model_features = make_model(all_keys_binarized)\n",
    "    filename = os.path.join('hyperparameter-search-results',\n",
    "                            model_id + '-' +str(hyperparameter_index))\n",
    "    save_features(model_features, filename)\n",
    "    \n",
    "    k_folds_errors = []\n",
    "    for train_index, test_index in skf.split(all_spectra, all_keys):\n",
    "        # reset model on each iteration\n",
    "        model = DNN(model_features)\n",
    "        optimizer = tf.train.AdamOptimizer(model_features.learining_rate)\n",
    "\n",
    "        costfunction_errors_tmp, earlystop_errors_tmp = train_earlystop(\n",
    "                training_data=all_spectra[train_index],\n",
    "                training_keys=all_keys_binarized[train_index],\n",
    "                testing_data=all_spectra[test_index],\n",
    "                testing_keys=all_keys_binarized[test_index],\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                num_epochs=200,\n",
    "                obj_cost=model.cross_entropy,\n",
    "                earlystop_cost_fn=model.f1_error,\n",
    "                earlystop_patience=10,\n",
    "                not_learning_patience=10,\n",
    "                not_learning_threshold=0.9,\n",
    "                verbose=True,\n",
    "                fit_batch_verbose=10,\n",
    "                data_augmentation=model.default_data_augmentation)\n",
    "        k_folds_errors.append(earlystop_errors_tmp)\n",
    "        all_kf_errors.append(earlystop_errors_tmp)\n",
    "\n",
    "    testing_errors.append(np.average(k_folds_errors))\n",
    "    np.save('./final-models/final_test_errors_'+model_id, testing_errors)\n",
    "    np.save('./final-models/final_kf_errors_'+model_id, all_kf_errors)\n",
    "    network_id += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
