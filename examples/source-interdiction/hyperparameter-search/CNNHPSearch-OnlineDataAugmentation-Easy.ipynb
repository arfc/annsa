{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "\n",
    "from annsa.template_sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.eager as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import model, training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annsa.model_classes import (cnn1d_model_features,\n",
    "                                 CNN1D,\n",
    "                                 generate_random_cnn1d_architecture,\n",
    "                                 save_model,\n",
    "                                 train_earlystop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_dataset = pd.read_csv('../../source-interdiction/training_testing_data/background_template_dataset.csv')\n",
    "source_dataset = pd.read_csv('../../source-interdiction/training_testing_data/shielded_templates_200kev_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sourcedist: [50.0, 112.5, 175.0, 237.5, 300.0]\n",
      "sourceheight: [50.0, 75.0, 100.0, 125.0, 150.0]\n",
      "alum shieldingdensity: [1.82, 4.18, 7.49, 13.16]\n",
      "iron shieldingdensity: [1.53, 3.5, 6.28, 11.02]\n",
      "lead shieldingdensity: [0.22, 0.51, 0.92, 1.61]\n",
      "fwhm: [6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0]\n"
     ]
    }
   ],
   "source": [
    "print('sourcedist: ' + str(sorted(set(source_dataset['sourcedist']))))\n",
    "print('sourceheight: ' + str(sorted(set(source_dataset['sourceheight']))))\n",
    "print('alum shieldingdensity: ' + str(sorted(set(source_dataset[source_dataset['shielding']=='alum']['shieldingdensity']))))\n",
    "print('iron shieldingdensity: ' + str(sorted(set(source_dataset[source_dataset['shielding']=='iron']['shieldingdensity']))))\n",
    "print('lead shieldingdensity: ' + str(sorted(set(source_dataset[source_dataset['shielding']=='lead']['shieldingdensity']))))\n",
    "print('fwhm: ' + str(sorted(set(source_dataset['fwhm']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dataset = source_dataset[source_dataset['fwhm']==7.5]\n",
    "source_dataset = source_dataset[source_dataset['sourcedist']==175.0]\n",
    "source_dataset = source_dataset[source_dataset['sourceheight']==100.0]\n",
    "\n",
    "# remove 80% shielding\n",
    "source_dataset = source_dataset[source_dataset['shieldingdensity']!=13.16]\n",
    "source_dataset = source_dataset[source_dataset['shieldingdensity']!=11.02]\n",
    "source_dataset = source_dataset[source_dataset['shieldingdensity']!=1.61]\n",
    "\n",
    "# remove 60% shielding\n",
    "source_dataset = source_dataset[source_dataset['shieldingdensity']!=7.49]\n",
    "source_dataset = source_dataset[source_dataset['shieldingdensity']!=6.28]\n",
    "source_dataset = source_dataset[source_dataset['shieldingdensity']!=0.92]\n",
    "\n",
    "# remove 40% shielding\n",
    "source_dataset = source_dataset[source_dataset['shieldingdensity']!=4.18]\n",
    "source_dataset = source_dataset[source_dataset['shieldingdensity']!=3.5]\n",
    "source_dataset = source_dataset[source_dataset['shieldingdensity']!=0.51]\n",
    "\n",
    "# remove 20% shielding\n",
    "source_dataset = source_dataset[source_dataset['shieldingdensity']!=1.82]\n",
    "source_dataset = source_dataset[source_dataset['shieldingdensity']!=1.53]\n",
    "source_dataset = source_dataset[source_dataset['shieldingdensity']!=0.22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove empty spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indicies dropped: []\n"
     ]
    }
   ],
   "source": [
    "zero_count_indicies = np.argwhere(np.sum(source_dataset.values[:,6:],axis=1) == 0).flatten()\n",
    "\n",
    "print('indicies dropped: ' +str(zero_count_indicies))\n",
    "\n",
    "source_dataset.drop(source_dataset.index[zero_count_indicies], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add empty spectra for background "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_spectra = []\n",
    "for fwhm in set(source_dataset['fwhm']):\n",
    "    num_examples = source_dataset[(source_dataset['fwhm']==fwhm) &\n",
    "                                  (source_dataset['isotope']==source_dataset['isotope'].iloc()[0])].shape[0]\n",
    "    for k in range(num_examples):\n",
    "        blank_spectra_tmp = [0]*1200\n",
    "        blank_spectra_tmp[5] = fwhm\n",
    "        blank_spectra_tmp[0] = 'background'\n",
    "        blank_spectra_tmp[3] = 'background'\n",
    "        blank_spectra.append(blank_spectra_tmp)\n",
    "\n",
    "source_dataset = source_dataset.append(pd.DataFrame(blank_spectra,\n",
    "                                                    columns=source_dataset.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset from spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_dataset = source_dataset.values[:,5:].astype('float64')\n",
    "all_keys = source_dataset['isotope'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define online data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integration_time():\n",
    "    return np.random.uniform(60,600)\n",
    "\n",
    "def background_cps():\n",
    "    return np.random.poisson(200)\n",
    "\n",
    "def signal_to_background():\n",
    "    return np.random.uniform(0.5,2)\n",
    "\n",
    "def calibration():\n",
    "    return [np.random.uniform(0,10),\n",
    "            np.random.uniform(2500/3000,3500/3000),\n",
    "            0]\n",
    "\n",
    "online_data_augmentation = online_data_augmentation_vanilla(background_dataset,\n",
    "                                background_cps,\n",
    "                                integration_time,\n",
    "                                signal_to_background,\n",
    "                                calibration,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = np.load('../dataset_generation/testing_dataset_200keV_1000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_spectra = np.random.poisson(np.add(testing_dataset.item()['sources'], testing_dataset.item()['backgrounds']))\n",
    "testing_keys = testing_dataset.item()['keys']\n",
    "\n",
    "mlb=LabelBinarizer()\n",
    "\n",
    "all_keys_binarized = mlb.fit_transform(all_keys.reshape([all_keys.shape[0],1]))\n",
    "testing_keys_binarized = mlb.transform(testing_keys)\n",
    "training_keys_binarized = mlb.transform(all_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_hyperparameters_to_search = 256\n",
    "earlystop_errors_test = []\n",
    "model_id='CNN-onlinedataaugeasy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    '''\n",
    "    Makes a random model given some parameters.\n",
    "\n",
    "    '''\n",
    "    cnn_filters_choices = ((4, 8),\n",
    "                       (8, 16),\n",
    "                       (16, 32),\n",
    "                       (4,),\n",
    "                       (8,),\n",
    "                       (16,),\n",
    "                       (32,),\n",
    "                       (4, 8, 16),\n",
    "                       (8, 16, 32),\n",
    "                      )\n",
    "\n",
    "    cnn_kernel_choices = ((2,), (4,), (8,), (16,))\n",
    "    pool_size_choices = ((2,), (4,), (8,), (16,))\n",
    "\n",
    "    \n",
    "    model_features = generate_random_cnn1d_architecture(\n",
    "        cnn_filters_choices= cnn_filters_choices,\n",
    "        cnn_kernel_choices=cnn_kernel_choices,\n",
    "        pool_size_choices=pool_size_choices,\n",
    "    )\n",
    "    model_features.trainable = True\n",
    "    model_features.learining_rate = 10**np.random.uniform(-4,-1)\n",
    "    model_features.batch_size = 2**np.random.randint(4,6)\n",
    "    model_features.output_size = training_keys_binarized.shape[1]\n",
    "    model_features.scaler = choice([make_pipeline(FunctionTransformer(np.log1p, validate=True)),\n",
    "                                    make_pipeline(FunctionTransformer(np.sqrt, validate=True))])\n",
    "    model_features.activation_function = choice([tf.nn.relu,tf.nn.tanh,tf.nn.sigmoid])\n",
    "    model_features.output_function = None\n",
    "    model_features.Pooling = tf.layers.MaxPooling1D\n",
    "    model_features.l2_regularization_scale = 10**np.random.uniform(-3,0)\n",
    "    model_features.dropout_probability = np.random.uniform(0,1)\n",
    "    model_features.pool_strides = ((2,2,2))\n",
    "    number_layers = choice([1, 2, 3])\n",
    "    dense_nodes = 2**np.random.randint(4,8,number_layers)\n",
    "    dense_nodes = np.sort(dense_nodes)\n",
    "    dense_nodes = np.flipud(dense_nodes)\n",
    "    \n",
    "    model_features.dense_nodes = dense_nodes\n",
    "\n",
    "    model = CNN1D(model_features)\n",
    "\n",
    "    return model, model_features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: CostFunc loss: 0.00 6.10, EarlyStop loss: 0.00 0.97\n",
      "Epoch 2: CostFunc loss: 0.00 5.78, EarlyStop loss: 0.00 0.97\n",
      "Epoch 3: CostFunc loss: 0.00 5.68, EarlyStop loss: 0.00 0.97\n",
      "Epoch 4: CostFunc loss: 0.00 5.43, EarlyStop loss: 0.00 0.97\n",
      "Epoch 5: CostFunc loss: 0.00 5.38, EarlyStop loss: 0.00 0.97\n",
      "Epoch 6: CostFunc loss: 0.00 5.34, EarlyStop loss: 0.00 0.97\n",
      "Epoch 7: CostFunc loss: 0.00 5.22, EarlyStop loss: 0.00 0.97\n",
      "Test error at early stop: Objectives fctn: 5.68 Early stopfctn: 5.68\n"
     ]
    }
   ],
   "source": [
    "testing_errors = []\n",
    "\n",
    "for network_id in range(number_hyperparameters_to_search):\n",
    "    # reset model on each iteration\n",
    "    model, model_features = make_model()\n",
    "    optimizer = tf.train.AdamOptimizer(model_features.learining_rate)\n",
    "    \n",
    "    costfunction_errors_tmp, earlystop_errors_tmp = train_earlystop(\n",
    "            training_data=spectra_dataset,\n",
    "            training_keys=training_keys_binarized,\n",
    "            testing_data=testing_spectra,\n",
    "            testing_keys=testing_keys_binarized,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            num_epochs=100,\n",
    "            obj_cost=model.cross_entropy,\n",
    "            earlystop_cost_fn=model.f1_error,\n",
    "            earlystop_patience=5,\n",
    "            verbose=True,\n",
    "            fit_batch_verbose=1,\n",
    "            data_augmentation=online_data_augmentation)\n",
    "    testing_errors.append(earlystop_errors_tmp)\n",
    "\n",
    "    # np.save('./final-models/final_test_errors_'+model_id, training_errors)\n",
    "    # model.save_weights('./final-models/'+model_id+'_checkpoint_'+str(network_id))\n",
    "    network_id += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
