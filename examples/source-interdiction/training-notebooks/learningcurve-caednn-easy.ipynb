{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_device_id = str(7)\n",
    "model_id_save_as = 'learningcurve-caednn-easy-final'\n",
    "architecture_id = '../hyperparameter_search/hyperparameter-search-results/CNN-kfoldseasy-final-1-reluupdate_33'\n",
    "model_class_id = 'CNN1D'\n",
    "testing_dataset_id = '../../source-interdiction/dataset_generation/validation_dataset_200keV_log10time_100.npy'\n",
    "training_dataset_id = '../../source-interdiction/dataset_generation/training_dataset_200keV_log10time_10000.npy'\n",
    "difficulty_setting = 'easy'\n",
    "\n",
    "train_sizes = [50, 100, 500, 1000, 5000, 10000, 15000, 20000,]\n",
    "earlystop_patience = 10\n",
    "num_epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_device_id\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(5)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import model, training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from annsa.model_classes import build_cnn_model, compile_model, f1\n",
    "from annsa.load_dataset import load_easy, load_full, dataset_to_spectrakeys\n",
    "from annsa.load_pretrained_network import load_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = np.load(training_dataset_id)\n",
    "training_spectra, training_keys = dataset_to_spectrakeys(training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = np.load(testing_dataset_id)\n",
    "testing_spectra, testing_keys = dataset_to_spectrakeys(testing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = load_features(architecture_id)\n",
    "model_features.output_function = tf.nn.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features.cnn_kernels = model_features.cnn_kernel\n",
    "model_features.pool_sizes = model_features.pool_size\n",
    "model_features.loss = tf.keras.losses.categorical_crossentropy\n",
    "model_features.optimizer = tf.keras.optimizers.Adam\n",
    "model_features.metrics = [f1]\n",
    "model_features.dropout_rate = model_features.dropout_probability\n",
    "model_features.output_function = tf.nn.softmax\n",
    "model_features.input_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "cae_model = load_model('./final-models-keras/caepretrain-easy-final.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_spectra_scaled = model_features.scaler.transform(training_spectra)\n",
    "testing_spectra_scaled = model_features.scaler.transform(testing_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_f1',\n",
    "    patience=earlystop_patience,\n",
    "    mode='max',\n",
    "    min_delta=0.01,\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running through training size 50\n",
      "Running through fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 2s 39ms/sample - loss: 4.8103 - f1: 0.0000e+00 - val_loss: 4.5658 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.4379 - f1: 0.0000e+00 - val_loss: 4.3522 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.1333 - f1: 0.0000e+00 - val_loss: 4.1507 - val_f1: 0.0064\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8760 - f1: 0.0000e+00 - val_loss: 3.9441 - val_f1: 0.0256\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.5871 - f1: 0.0588 - val_loss: 3.7293 - val_f1: 0.0731\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.2734 - f1: 0.1857 - val_loss: 3.5255 - val_f1: 0.0978\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.0673 - f1: 0.2477 - val_loss: 3.3538 - val_f1: 0.1119\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.8271 - f1: 0.2929 - val_loss: 3.1987 - val_f1: 0.1453\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.6228 - f1: 0.2795 - val_loss: 3.0574 - val_f1: 0.1675\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.4554 - f1: 0.2526 - val_loss: 2.9426 - val_f1: 0.2035\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.3308 - f1: 0.4174 - val_loss: 2.8404 - val_f1: 0.2362\n",
      "Epoch 12/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.1523 - f1: 0.4369 - val_loss: 2.7411 - val_f1: 0.2696\n",
      "Epoch 13/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.0415 - f1: 0.4317 - val_loss: 2.6552 - val_f1: 0.2948\n",
      "Epoch 14/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.9480 - f1: 0.5128 - val_loss: 2.5841 - val_f1: 0.3116\n",
      "Epoch 15/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.8080 - f1: 0.6410 - val_loss: 2.5257 - val_f1: 0.3291\n",
      "Epoch 16/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.7502 - f1: 0.6763 - val_loss: 2.4776 - val_f1: 0.3436\n",
      "Epoch 17/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.6268 - f1: 0.7262 - val_loss: 2.4291 - val_f1: 0.3595\n",
      "Epoch 18/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.5480 - f1: 0.7393 - val_loss: 2.3865 - val_f1: 0.3813\n",
      "Epoch 19/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.4875 - f1: 0.7297 - val_loss: 2.3418 - val_f1: 0.3895\n",
      "Epoch 20/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3928 - f1: 0.6786 - val_loss: 2.2959 - val_f1: 0.4024\n",
      "Epoch 21/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3496 - f1: 0.7600 - val_loss: 2.2526 - val_f1: 0.4165\n",
      "Epoch 22/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.2799 - f1: 0.7919 - val_loss: 2.2252 - val_f1: 0.4247\n",
      "Epoch 23/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.2258 - f1: 0.7975 - val_loss: 2.1980 - val_f1: 0.4280\n",
      "Epoch 24/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1757 - f1: 0.8286 - val_loss: 2.1571 - val_f1: 0.4302\n",
      "Epoch 25/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1074 - f1: 0.9092 - val_loss: 2.1377 - val_f1: 0.4354\n",
      "Epoch 26/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1153 - f1: 0.8375 - val_loss: 2.1115 - val_f1: 0.4550\n",
      "Epoch 27/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0477 - f1: 0.8831 - val_loss: 2.0779 - val_f1: 0.4789\n",
      "Epoch 28/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0129 - f1: 0.8860 - val_loss: 2.0546 - val_f1: 0.4994\n",
      "Epoch 29/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9813 - f1: 0.9524 - val_loss: 2.0374 - val_f1: 0.5100\n",
      "Epoch 30/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9552 - f1: 0.9373 - val_loss: 2.0067 - val_f1: 0.5253\n",
      "Epoch 31/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9216 - f1: 0.9300 - val_loss: 1.9813 - val_f1: 0.5341\n",
      "Epoch 32/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8803 - f1: 0.9611 - val_loss: 1.9687 - val_f1: 0.5421\n",
      "Epoch 33/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8623 - f1: 0.9921 - val_loss: 1.9516 - val_f1: 0.5523\n",
      "Epoch 34/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8382 - f1: 0.9778 - val_loss: 1.9283 - val_f1: 0.5565\n",
      "Epoch 35/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.8093 - f1: 0.9696 - val_loss: 1.9153 - val_f1: 0.5577\n",
      "Epoch 36/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.8021 - f1: 0.9667 - val_loss: 1.9094 - val_f1: 0.5626\n",
      "Epoch 37/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7771 - f1: 0.9921 - val_loss: 1.8960 - val_f1: 0.5739\n",
      "Epoch 38/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7525 - f1: 0.9857 - val_loss: 1.8778 - val_f1: 0.5767\n",
      "Epoch 39/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7341 - f1: 0.9921 - val_loss: 1.8612 - val_f1: 0.5777\n",
      "Epoch 40/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7161 - f1: 1.0000 - val_loss: 1.8533 - val_f1: 0.5815\n",
      "Epoch 41/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7144 - f1: 0.9857 - val_loss: 1.8489 - val_f1: 0.5907\n",
      "Epoch 42/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6866 - f1: 1.0000 - val_loss: 1.8499 - val_f1: 0.5851\n",
      "Epoch 43/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6850 - f1: 0.9839 - val_loss: 1.8196 - val_f1: 0.5948\n",
      "Epoch 44/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6587 - f1: 1.0000 - val_loss: 1.8026 - val_f1: 0.5980\n",
      "Epoch 45/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6497 - f1: 0.9921 - val_loss: 1.8025 - val_f1: 0.6009\n",
      "Epoch 46/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6385 - f1: 1.0000 - val_loss: 1.8031 - val_f1: 0.6011\n",
      "Epoch 47/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6160 - f1: 1.0000 - val_loss: 1.8171 - val_f1: 0.5895\n",
      "Epoch 48/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6099 - f1: 1.0000 - val_loss: 1.8009 - val_f1: 0.5954\n",
      "Epoch 49/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6034 - f1: 1.0000 - val_loss: 1.7789 - val_f1: 0.6057\n",
      "Epoch 50/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5924 - f1: 1.0000 - val_loss: 1.7679 - val_f1: 0.6094\n",
      "Epoch 51/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5740 - f1: 1.0000 - val_loss: 1.7616 - val_f1: 0.6048\n",
      "Epoch 52/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5688 - f1: 1.0000 - val_loss: 1.7461 - val_f1: 0.6104\n",
      "Epoch 53/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5525 - f1: 1.0000 - val_loss: 1.7324 - val_f1: 0.6157\n",
      "Epoch 54/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5493 - f1: 1.0000 - val_loss: 1.7299 - val_f1: 0.6173\n",
      "Epoch 55/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5378 - f1: 1.0000 - val_loss: 1.7301 - val_f1: 0.6149\n",
      "Epoch 56/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5252 - f1: 1.0000 - val_loss: 1.7364 - val_f1: 0.6082\n",
      "Epoch 57/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5201 - f1: 1.0000 - val_loss: 1.7305 - val_f1: 0.6108\n",
      "Epoch 58/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5163 - f1: 1.0000 - val_loss: 1.7102 - val_f1: 0.6215\n",
      "Epoch 59/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5052 - f1: 1.0000 - val_loss: 1.7057 - val_f1: 0.6227\n",
      "Epoch 60/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4904 - f1: 1.0000 - val_loss: 1.6993 - val_f1: 0.6239\n",
      "Epoch 61/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4883 - f1: 1.0000 - val_loss: 1.7032 - val_f1: 0.6172\n",
      "Epoch 62/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4898 - f1: 1.0000 - val_loss: 1.6936 - val_f1: 0.6152\n",
      "Epoch 63/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4763 - f1: 1.0000 - val_loss: 1.6727 - val_f1: 0.6229\n",
      "Running through fold 1\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 19ms/sample - loss: 4.8213 - f1: 0.0000e+00 - val_loss: 4.5858 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.4572 - f1: 0.0000e+00 - val_loss: 4.3540 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.1421 - f1: 0.0000e+00 - val_loss: 4.1250 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.8290 - f1: 0.0000e+00 - val_loss: 3.9021 - val_f1: 0.0013\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.5127 - f1: 0.0526 - val_loss: 3.6789 - val_f1: 0.0092\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.2401 - f1: 0.0829 - val_loss: 3.4719 - val_f1: 0.0148\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.9575 - f1: 0.0588 - val_loss: 3.2868 - val_f1: 0.0416\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.7579 - f1: 0.1111 - val_loss: 3.1267 - val_f1: 0.0937\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.5427 - f1: 0.3008 - val_loss: 2.9963 - val_f1: 0.1476\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.3297 - f1: 0.4013 - val_loss: 2.8850 - val_f1: 0.1684\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.1519 - f1: 0.4695 - val_loss: 2.7997 - val_f1: 0.1899\n",
      "Epoch 12/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.0463 - f1: 0.5458 - val_loss: 2.7243 - val_f1: 0.2088\n",
      "Epoch 13/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.9214 - f1: 0.5528 - val_loss: 2.6508 - val_f1: 0.2385\n",
      "Epoch 14/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.7833 - f1: 0.5643 - val_loss: 2.5917 - val_f1: 0.2771\n",
      "Epoch 15/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.6762 - f1: 0.6225 - val_loss: 2.5419 - val_f1: 0.3206\n",
      "Epoch 16/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.6131 - f1: 0.7262 - val_loss: 2.4899 - val_f1: 0.3413\n",
      "Epoch 17/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.4937 - f1: 0.7469 - val_loss: 2.4351 - val_f1: 0.3696\n",
      "Epoch 18/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.4542 - f1: 0.7919 - val_loss: 2.3927 - val_f1: 0.4077\n",
      "Epoch 19/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3624 - f1: 0.8040 - val_loss: 2.3516 - val_f1: 0.4272\n",
      "Epoch 20/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3171 - f1: 0.8276 - val_loss: 2.3124 - val_f1: 0.4491\n",
      "Epoch 21/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.2741 - f1: 0.8508 - val_loss: 2.2768 - val_f1: 0.4560\n",
      "Epoch 22/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1883 - f1: 0.8754 - val_loss: 2.2450 - val_f1: 0.4742\n",
      "Epoch 23/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1467 - f1: 0.9286 - val_loss: 2.2126 - val_f1: 0.4912\n",
      "Epoch 24/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.0748 - f1: 0.9282 - val_loss: 2.1953 - val_f1: 0.5057\n",
      "Epoch 25/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.0399 - f1: 0.9129 - val_loss: 2.1741 - val_f1: 0.5090\n",
      "Epoch 26/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.9950 - f1: 0.9282 - val_loss: 2.1457 - val_f1: 0.5208\n",
      "Epoch 27/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9765 - f1: 0.9212 - val_loss: 2.1156 - val_f1: 0.5224\n",
      "Epoch 28/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9291 - f1: 0.9373 - val_loss: 2.0842 - val_f1: 0.5287\n",
      "Epoch 29/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9062 - f1: 0.9611 - val_loss: 2.0579 - val_f1: 0.5325\n",
      "Epoch 30/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8719 - f1: 0.9460 - val_loss: 2.0416 - val_f1: 0.5383\n",
      "Epoch 31/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8546 - f1: 0.9696 - val_loss: 2.0258 - val_f1: 0.5457\n",
      "Epoch 32/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8354 - f1: 0.9627 - val_loss: 2.0122 - val_f1: 0.5505\n",
      "Epoch 33/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8304 - f1: 0.9696 - val_loss: 1.9974 - val_f1: 0.5532\n",
      "Epoch 34/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7940 - f1: 0.9778 - val_loss: 1.9812 - val_f1: 0.5556\n",
      "Epoch 35/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7670 - f1: 0.9839 - val_loss: 1.9621 - val_f1: 0.5591\n",
      "Epoch 36/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7394 - f1: 0.9778 - val_loss: 1.9447 - val_f1: 0.5615\n",
      "Epoch 37/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7242 - f1: 0.9778 - val_loss: 1.9352 - val_f1: 0.5617\n",
      "Epoch 38/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7039 - f1: 0.9857 - val_loss: 1.9223 - val_f1: 0.5649\n",
      "Epoch 39/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6958 - f1: 0.9839 - val_loss: 1.9087 - val_f1: 0.5703\n",
      "Epoch 40/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6719 - f1: 1.0000 - val_loss: 1.9000 - val_f1: 0.5692\n",
      "Epoch 41/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6579 - f1: 0.9857 - val_loss: 1.8942 - val_f1: 0.5717\n",
      "Epoch 42/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6407 - f1: 1.0000 - val_loss: 1.8887 - val_f1: 0.5718\n",
      "Epoch 43/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6273 - f1: 1.0000 - val_loss: 1.8828 - val_f1: 0.5749\n",
      "Epoch 44/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6186 - f1: 0.9778 - val_loss: 1.8788 - val_f1: 0.5755\n",
      "Epoch 45/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6070 - f1: 0.9921 - val_loss: 1.8672 - val_f1: 0.5815\n",
      "Epoch 46/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5977 - f1: 1.0000 - val_loss: 1.8542 - val_f1: 0.5834\n",
      "Epoch 47/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5835 - f1: 0.9921 - val_loss: 1.8414 - val_f1: 0.5857\n",
      "Epoch 48/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5857 - f1: 0.9921 - val_loss: 1.8299 - val_f1: 0.5838\n",
      "Epoch 49/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5671 - f1: 1.0000 - val_loss: 1.8232 - val_f1: 0.5849\n",
      "Epoch 50/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5563 - f1: 1.0000 - val_loss: 1.8199 - val_f1: 0.5876\n",
      "Epoch 51/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5354 - f1: 1.0000 - val_loss: 1.8181 - val_f1: 0.5884\n",
      "Epoch 52/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5307 - f1: 1.0000 - val_loss: 1.8129 - val_f1: 0.5958\n",
      "Epoch 53/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5240 - f1: 1.0000 - val_loss: 1.7999 - val_f1: 0.5966\n",
      "Epoch 54/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5224 - f1: 1.0000 - val_loss: 1.7848 - val_f1: 0.5942\n",
      "Epoch 55/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5139 - f1: 1.0000 - val_loss: 1.7799 - val_f1: 0.5923\n",
      "Epoch 56/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5151 - f1: 1.0000 - val_loss: 1.7748 - val_f1: 0.5942\n",
      "Epoch 57/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4982 - f1: 1.0000 - val_loss: 1.7737 - val_f1: 0.5925\n",
      "Epoch 58/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4865 - f1: 1.0000 - val_loss: 1.7704 - val_f1: 0.5925\n",
      "Epoch 59/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4911 - f1: 1.0000 - val_loss: 1.7688 - val_f1: 0.5958\n",
      "Epoch 60/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4750 - f1: 1.0000 - val_loss: 1.7680 - val_f1: 0.6002\n",
      "Epoch 61/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4731 - f1: 1.0000 - val_loss: 1.7704 - val_f1: 0.5987\n",
      "Epoch 62/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4568 - f1: 1.0000 - val_loss: 1.7687 - val_f1: 0.5978\n",
      "Running through fold 2\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 20ms/sample - loss: 4.8138 - f1: 0.0000e+00 - val_loss: 4.5884 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.4388 - f1: 0.0000e+00 - val_loss: 4.3665 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.1244 - f1: 0.0000e+00 - val_loss: 4.1526 - val_f1: 0.0013\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.8616 - f1: 0.0526 - val_loss: 3.9465 - val_f1: 0.0411\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.5634 - f1: 0.1383 - val_loss: 3.7524 - val_f1: 0.0818\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.3184 - f1: 0.2111 - val_loss: 3.5698 - val_f1: 0.1185\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.1322 - f1: 0.2540 - val_loss: 3.4014 - val_f1: 0.1534\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.8719 - f1: 0.3000 - val_loss: 3.2315 - val_f1: 0.1684\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.6778 - f1: 0.3170 - val_loss: 3.0810 - val_f1: 0.1733\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.4924 - f1: 0.3000 - val_loss: 2.9520 - val_f1: 0.1741\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.3293 - f1: 0.2907 - val_loss: 2.8405 - val_f1: 0.1795\n",
      "Epoch 12/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.1553 - f1: 0.3381 - val_loss: 2.7449 - val_f1: 0.1831\n",
      "Epoch 13/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.0679 - f1: 0.4013 - val_loss: 2.6602 - val_f1: 0.2078\n",
      "Epoch 14/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.9101 - f1: 0.4901 - val_loss: 2.5850 - val_f1: 0.2594\n",
      "Epoch 15/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.8314 - f1: 0.5966 - val_loss: 2.5196 - val_f1: 0.2953\n",
      "Epoch 16/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.7070 - f1: 0.6727 - val_loss: 2.4637 - val_f1: 0.3168\n",
      "Epoch 17/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.6881 - f1: 0.6682 - val_loss: 2.4051 - val_f1: 0.3315\n",
      "Epoch 18/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.5678 - f1: 0.6763 - val_loss: 2.3614 - val_f1: 0.3565\n",
      "Epoch 19/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.4771 - f1: 0.7725 - val_loss: 2.3294 - val_f1: 0.3815\n",
      "Epoch 20/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.4207 - f1: 0.7534 - val_loss: 2.2978 - val_f1: 0.4088\n",
      "Epoch 21/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3458 - f1: 0.8040 - val_loss: 2.2582 - val_f1: 0.4274\n",
      "Epoch 22/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.2960 - f1: 0.8268 - val_loss: 2.2249 - val_f1: 0.4503\n",
      "Epoch 23/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.2235 - f1: 0.8449 - val_loss: 2.1857 - val_f1: 0.4683\n",
      "Epoch 24/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.1764 - f1: 0.8483 - val_loss: 2.1594 - val_f1: 0.4820\n",
      "Epoch 25/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.1140 - f1: 0.8931 - val_loss: 2.1404 - val_f1: 0.4921\n",
      "Epoch 26/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0810 - f1: 0.9243 - val_loss: 2.1198 - val_f1: 0.5041\n",
      "Epoch 27/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0520 - f1: 0.8948 - val_loss: 2.1114 - val_f1: 0.5070\n",
      "Epoch 28/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9986 - f1: 0.9092 - val_loss: 2.1055 - val_f1: 0.5111\n",
      "Epoch 29/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9614 - f1: 0.9243 - val_loss: 2.0838 - val_f1: 0.5255\n",
      "Epoch 30/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9307 - f1: 0.9524 - val_loss: 2.0586 - val_f1: 0.5347\n",
      "Epoch 31/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8861 - f1: 0.9627 - val_loss: 2.0322 - val_f1: 0.5455\n",
      "Epoch 32/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8699 - f1: 0.9524 - val_loss: 2.0045 - val_f1: 0.5507\n",
      "Epoch 33/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8651 - f1: 0.9460 - val_loss: 1.9914 - val_f1: 0.5572\n",
      "Epoch 34/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8310 - f1: 0.9754 - val_loss: 1.9907 - val_f1: 0.5592\n",
      "Epoch 35/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7911 - f1: 0.9921 - val_loss: 1.9839 - val_f1: 0.5573\n",
      "Epoch 36/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7807 - f1: 0.9706 - val_loss: 1.9726 - val_f1: 0.5629\n",
      "Epoch 37/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7676 - f1: 0.9921 - val_loss: 1.9532 - val_f1: 0.5681\n",
      "Epoch 38/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7399 - f1: 1.0000 - val_loss: 1.9324 - val_f1: 0.5729\n",
      "Epoch 39/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7147 - f1: 0.9857 - val_loss: 1.9109 - val_f1: 0.5814\n",
      "Epoch 40/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7107 - f1: 1.0000 - val_loss: 1.8988 - val_f1: 0.5845\n",
      "Epoch 41/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6984 - f1: 0.9857 - val_loss: 1.8960 - val_f1: 0.5836\n",
      "Epoch 42/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6680 - f1: 1.0000 - val_loss: 1.8952 - val_f1: 0.5863\n",
      "Epoch 43/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6632 - f1: 1.0000 - val_loss: 1.8904 - val_f1: 0.5870\n",
      "Epoch 44/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6495 - f1: 0.9921 - val_loss: 1.8867 - val_f1: 0.5887\n",
      "Epoch 45/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6356 - f1: 1.0000 - val_loss: 1.8754 - val_f1: 0.5919\n",
      "Epoch 46/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6273 - f1: 1.0000 - val_loss: 1.8543 - val_f1: 0.5932\n",
      "Epoch 47/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6075 - f1: 1.0000 - val_loss: 1.8334 - val_f1: 0.5927\n",
      "Epoch 48/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6024 - f1: 1.0000 - val_loss: 1.8283 - val_f1: 0.5940\n",
      "Epoch 49/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5971 - f1: 1.0000 - val_loss: 1.8324 - val_f1: 0.5937\n",
      "Epoch 50/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5697 - f1: 1.0000 - val_loss: 1.8246 - val_f1: 0.5970\n",
      "Epoch 51/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5667 - f1: 1.0000 - val_loss: 1.8163 - val_f1: 0.5968\n",
      "Epoch 52/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5622 - f1: 1.0000 - val_loss: 1.8040 - val_f1: 0.5993\n",
      "Epoch 53/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5471 - f1: 1.0000 - val_loss: 1.7928 - val_f1: 0.5987\n",
      "Epoch 54/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5427 - f1: 1.0000 - val_loss: 1.7842 - val_f1: 0.5969\n",
      "Epoch 55/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5361 - f1: 1.0000 - val_loss: 1.7747 - val_f1: 0.5999\n",
      "Running through fold 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 21ms/sample - loss: 4.7925 - f1: 0.0000e+00 - val_loss: 4.5595 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.4037 - f1: 0.0000e+00 - val_loss: 4.3325 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.0831 - f1: 0.0000e+00 - val_loss: 4.1081 - val_f1: 6.4475e-04\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.7713 - f1: 0.0829 - val_loss: 3.8949 - val_f1: 0.0279\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.4735 - f1: 0.1818 - val_loss: 3.7064 - val_f1: 0.0544\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.2392 - f1: 0.1732 - val_loss: 3.5368 - val_f1: 0.0778\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.9753 - f1: 0.2477 - val_loss: 3.3783 - val_f1: 0.1159\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.7862 - f1: 0.2762 - val_loss: 3.2396 - val_f1: 0.1390\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.5875 - f1: 0.3357 - val_loss: 3.1094 - val_f1: 0.1490\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.4330 - f1: 0.2540 - val_loss: 2.9957 - val_f1: 0.1527\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.2708 - f1: 0.3223 - val_loss: 2.8960 - val_f1: 0.1635\n",
      "Epoch 12/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.1467 - f1: 0.3818 - val_loss: 2.8107 - val_f1: 0.2086\n",
      "Epoch 13/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.0079 - f1: 0.4707 - val_loss: 2.7383 - val_f1: 0.2625\n",
      "Epoch 14/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.8840 - f1: 0.5689 - val_loss: 2.6696 - val_f1: 0.2956\n",
      "Epoch 15/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.8106 - f1: 0.6222 - val_loss: 2.6082 - val_f1: 0.3225\n",
      "Epoch 16/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.7071 - f1: 0.6763 - val_loss: 2.5437 - val_f1: 0.3595\n",
      "Epoch 17/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.6378 - f1: 0.6410 - val_loss: 2.4868 - val_f1: 0.3909\n",
      "Epoch 18/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.5536 - f1: 0.7059 - val_loss: 2.4465 - val_f1: 0.4201\n",
      "Epoch 19/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.4747 - f1: 0.7515 - val_loss: 2.4152 - val_f1: 0.4317\n",
      "Epoch 20/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.4162 - f1: 0.8040 - val_loss: 2.3803 - val_f1: 0.4440\n",
      "Epoch 21/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3242 - f1: 0.7919 - val_loss: 2.3605 - val_f1: 0.4592\n",
      "Epoch 22/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.2628 - f1: 0.8079 - val_loss: 2.3417 - val_f1: 0.4686\n",
      "Epoch 23/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.2326 - f1: 0.7867 - val_loss: 2.3187 - val_f1: 0.4745\n",
      "Epoch 24/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1936 - f1: 0.8286 - val_loss: 2.2991 - val_f1: 0.4779\n",
      "Epoch 25/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1307 - f1: 0.8676 - val_loss: 2.2788 - val_f1: 0.4806\n",
      "Epoch 26/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0816 - f1: 0.8951 - val_loss: 2.2544 - val_f1: 0.4966\n",
      "Epoch 27/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0475 - f1: 0.9189 - val_loss: 2.2392 - val_f1: 0.5250\n",
      "Epoch 28/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0383 - f1: 0.8858 - val_loss: 2.2287 - val_f1: 0.5362\n",
      "Epoch 29/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9760 - f1: 0.9212 - val_loss: 2.2129 - val_f1: 0.5386\n",
      "Epoch 30/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9586 - f1: 0.9300 - val_loss: 2.2047 - val_f1: 0.5347\n",
      "Epoch 31/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9014 - f1: 0.9839 - val_loss: 2.2029 - val_f1: 0.5359\n",
      "Epoch 32/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8698 - f1: 0.9706 - val_loss: 2.2017 - val_f1: 0.5550\n",
      "Epoch 33/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8553 - f1: 0.9778 - val_loss: 2.2063 - val_f1: 0.5612\n",
      "Epoch 34/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8356 - f1: 0.9839 - val_loss: 2.1963 - val_f1: 0.5610\n",
      "Epoch 35/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7942 - f1: 0.9921 - val_loss: 2.1755 - val_f1: 0.5584\n",
      "Epoch 36/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7910 - f1: 0.9778 - val_loss: 2.1601 - val_f1: 0.5513\n",
      "Epoch 37/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7698 - f1: 0.9921 - val_loss: 2.1413 - val_f1: 0.5576\n",
      "Epoch 38/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7382 - f1: 1.0000 - val_loss: 2.1282 - val_f1: 0.5634\n",
      "Epoch 39/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7134 - f1: 1.0000 - val_loss: 2.1267 - val_f1: 0.5682\n",
      "Epoch 40/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6993 - f1: 1.0000 - val_loss: 2.1257 - val_f1: 0.5722\n",
      "Epoch 41/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6823 - f1: 1.0000 - val_loss: 2.1103 - val_f1: 0.5702\n",
      "Epoch 42/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6671 - f1: 1.0000 - val_loss: 2.0954 - val_f1: 0.5681\n",
      "Epoch 43/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6518 - f1: 1.0000 - val_loss: 2.0846 - val_f1: 0.5707\n",
      "Epoch 44/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6462 - f1: 1.0000 - val_loss: 2.0736 - val_f1: 0.5751\n",
      "Epoch 45/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.6259 - f1: 1.0000 - val_loss: 2.0710 - val_f1: 0.5785\n",
      "Epoch 46/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.6137 - f1: 1.0000 - val_loss: 2.0670 - val_f1: 0.5786\n",
      "Epoch 47/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6098 - f1: 1.0000 - val_loss: 2.0587 - val_f1: 0.5804\n",
      "Epoch 48/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5930 - f1: 1.0000 - val_loss: 2.0494 - val_f1: 0.5817\n",
      "Epoch 49/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5830 - f1: 1.0000 - val_loss: 2.0423 - val_f1: 0.5826\n",
      "Epoch 50/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5693 - f1: 1.0000 - val_loss: 2.0366 - val_f1: 0.5844\n",
      "Epoch 51/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5530 - f1: 1.0000 - val_loss: 2.0279 - val_f1: 0.5814\n",
      "Epoch 52/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5572 - f1: 1.0000 - val_loss: 2.0190 - val_f1: 0.5820\n",
      "Epoch 53/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5369 - f1: 1.0000 - val_loss: 2.0102 - val_f1: 0.5832\n",
      "Epoch 54/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5296 - f1: 1.0000 - val_loss: 2.0064 - val_f1: 0.5809\n",
      "Epoch 55/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5192 - f1: 1.0000 - val_loss: 1.9999 - val_f1: 0.5797\n",
      "Running through fold 4\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 22ms/sample - loss: 4.8340 - f1: 0.0000e+00 - val_loss: 4.6084 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.4903 - f1: 0.0000e+00 - val_loss: 4.4096 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.2187 - f1: 0.0000e+00 - val_loss: 4.2118 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.9525 - f1: 0.0000e+00 - val_loss: 4.0142 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.6616 - f1: 0.0000e+00 - val_loss: 3.8127 - val_f1: 0.0025\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.3770 - f1: 0.0000e+00 - val_loss: 3.6192 - val_f1: 0.0398\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.1353 - f1: 0.1115 - val_loss: 3.4470 - val_f1: 0.0758\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.8867 - f1: 0.2111 - val_loss: 3.3022 - val_f1: 0.1030\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.6811 - f1: 0.2780 - val_loss: 3.1591 - val_f1: 0.1251\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.5026 - f1: 0.4079 - val_loss: 3.0391 - val_f1: 0.1702\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.3349 - f1: 0.4174 - val_loss: 2.9352 - val_f1: 0.2132\n",
      "Epoch 12/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.1800 - f1: 0.4174 - val_loss: 2.8336 - val_f1: 0.2347\n",
      "Epoch 13/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.0600 - f1: 0.4995 - val_loss: 2.7479 - val_f1: 0.2474\n",
      "Epoch 14/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.8802 - f1: 0.5804 - val_loss: 2.6693 - val_f1: 0.2661\n",
      "Epoch 15/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.7841 - f1: 0.6400 - val_loss: 2.6013 - val_f1: 0.3096\n",
      "Epoch 16/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.6924 - f1: 0.6933 - val_loss: 2.5369 - val_f1: 0.3422\n",
      "Epoch 17/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.5938 - f1: 0.7393 - val_loss: 2.4797 - val_f1: 0.3775\n",
      "Epoch 18/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.5225 - f1: 0.7844 - val_loss: 2.4271 - val_f1: 0.4062\n",
      "Epoch 19/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.4412 - f1: 0.7867 - val_loss: 2.3785 - val_f1: 0.4303\n",
      "Epoch 20/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3702 - f1: 0.8508 - val_loss: 2.3310 - val_f1: 0.4559\n",
      "Epoch 21/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3213 - f1: 0.8668 - val_loss: 2.2858 - val_f1: 0.4703\n",
      "Epoch 22/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.2558 - f1: 0.8286 - val_loss: 2.2483 - val_f1: 0.4817\n",
      "Epoch 23/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1989 - f1: 0.8668 - val_loss: 2.2165 - val_f1: 0.4936\n",
      "Epoch 24/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1375 - f1: 0.8661 - val_loss: 2.1936 - val_f1: 0.4981\n",
      "Epoch 25/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1265 - f1: 0.8831 - val_loss: 2.1708 - val_f1: 0.5115\n",
      "Epoch 26/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0655 - f1: 0.8858 - val_loss: 2.1454 - val_f1: 0.5153\n",
      "Epoch 27/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0209 - f1: 0.8676 - val_loss: 2.1216 - val_f1: 0.5230\n",
      "Epoch 28/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9922 - f1: 0.9340 - val_loss: 2.0959 - val_f1: 0.5273\n",
      "Epoch 29/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9512 - f1: 0.9460 - val_loss: 2.0711 - val_f1: 0.5367\n",
      "Epoch 30/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9075 - f1: 0.9114 - val_loss: 2.0500 - val_f1: 0.5456\n",
      "Epoch 31/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8906 - f1: 0.9460 - val_loss: 2.0342 - val_f1: 0.5499\n",
      "Epoch 32/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8480 - f1: 0.9545 - val_loss: 2.0239 - val_f1: 0.5584\n",
      "Epoch 33/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8402 - f1: 0.9460 - val_loss: 2.0182 - val_f1: 0.5694\n",
      "Epoch 34/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8080 - f1: 0.9696 - val_loss: 2.0099 - val_f1: 0.5732\n",
      "Epoch 35/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7823 - f1: 0.9839 - val_loss: 1.9995 - val_f1: 0.5703\n",
      "Epoch 36/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7709 - f1: 0.9778 - val_loss: 1.9790 - val_f1: 0.5734\n",
      "Epoch 37/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7408 - f1: 0.9921 - val_loss: 1.9510 - val_f1: 0.5792\n",
      "Epoch 38/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7304 - f1: 0.9778 - val_loss: 1.9380 - val_f1: 0.5869\n",
      "Epoch 39/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7043 - f1: 0.9857 - val_loss: 1.9215 - val_f1: 0.5981\n",
      "Epoch 40/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7003 - f1: 0.9921 - val_loss: 1.9071 - val_f1: 0.5993\n",
      "Epoch 41/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6833 - f1: 1.0000 - val_loss: 1.8957 - val_f1: 0.6014\n",
      "Epoch 42/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6557 - f1: 1.0000 - val_loss: 1.8907 - val_f1: 0.6053\n",
      "Epoch 43/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6434 - f1: 1.0000 - val_loss: 1.8873 - val_f1: 0.6094\n",
      "Epoch 44/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6264 - f1: 1.0000 - val_loss: 1.8832 - val_f1: 0.6090\n",
      "Epoch 45/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6223 - f1: 1.0000 - val_loss: 1.8755 - val_f1: 0.6171\n",
      "Epoch 46/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6016 - f1: 1.0000 - val_loss: 1.8659 - val_f1: 0.6185\n",
      "Epoch 47/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6017 - f1: 1.0000 - val_loss: 1.8512 - val_f1: 0.6181\n",
      "Epoch 48/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5939 - f1: 1.0000 - val_loss: 1.8394 - val_f1: 0.6210\n",
      "Epoch 49/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5819 - f1: 1.0000 - val_loss: 1.8305 - val_f1: 0.6226\n",
      "Epoch 50/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5576 - f1: 1.0000 - val_loss: 1.8241 - val_f1: 0.6245\n",
      "Epoch 51/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5508 - f1: 1.0000 - val_loss: 1.8170 - val_f1: 0.6303\n",
      "Epoch 52/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5505 - f1: 1.0000 - val_loss: 1.8124 - val_f1: 0.6278\n",
      "Epoch 53/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5325 - f1: 1.0000 - val_loss: 1.8026 - val_f1: 0.6225\n",
      "Epoch 54/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5296 - f1: 1.0000 - val_loss: 1.7867 - val_f1: 0.6301\n",
      "Epoch 55/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5178 - f1: 1.0000 - val_loss: 1.7692 - val_f1: 0.6336\n",
      "Epoch 56/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5035 - f1: 1.0000 - val_loss: 1.7581 - val_f1: 0.6382\n",
      "Epoch 57/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5014 - f1: 1.0000 - val_loss: 1.7582 - val_f1: 0.6370\n",
      "Epoch 58/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4988 - f1: 1.0000 - val_loss: 1.7662 - val_f1: 0.6343\n",
      "Epoch 59/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4852 - f1: 1.0000 - val_loss: 1.7759 - val_f1: 0.6295\n",
      "Epoch 60/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4796 - f1: 1.0000 - val_loss: 1.7829 - val_f1: 0.6160\n",
      "Epoch 61/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4683 - f1: 1.0000 - val_loss: 1.7762 - val_f1: 0.6187\n",
      "Epoch 62/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4680 - f1: 1.0000 - val_loss: 1.7507 - val_f1: 0.6327\n",
      "Epoch 63/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4565 - f1: 1.0000 - val_loss: 1.7337 - val_f1: 0.6371\n",
      "Epoch 64/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4579 - f1: 1.0000 - val_loss: 1.7282 - val_f1: 0.6350\n",
      "Epoch 65/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.4425 - f1: 1.0000 - val_loss: 1.7296 - val_f1: 0.6349\n",
      "\n",
      "\n",
      "Running through training size 100\n",
      "Running through fold 0\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 1s 12ms/sample - loss: 4.7674 - f1: 0.0000e+00 - val_loss: 4.3981 - val_f1: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.2731 - f1: 0.0000e+00 - val_loss: 4.0816 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.9054 - f1: 0.0152 - val_loss: 3.7998 - val_f1: 0.0398\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.5418 - f1: 0.0597 - val_loss: 3.4684 - val_f1: 0.0839\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.1961 - f1: 0.2264 - val_loss: 3.1909 - val_f1: 0.0940\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.8881 - f1: 0.1874 - val_loss: 2.9509 - val_f1: 0.1209\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.5794 - f1: 0.3079 - val_loss: 2.7501 - val_f1: 0.1490\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.3709 - f1: 0.1901 - val_loss: 2.6020 - val_f1: 0.2082\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.1830 - f1: 0.3573 - val_loss: 2.4755 - val_f1: 0.2988\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.0240 - f1: 0.5373 - val_loss: 2.3447 - val_f1: 0.3317\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.8907 - f1: 0.6143 - val_loss: 2.2349 - val_f1: 0.3671\n",
      "Epoch 12/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.7541 - f1: 0.5286 - val_loss: 2.1267 - val_f1: 0.4135\n",
      "Epoch 13/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6263 - f1: 0.6684 - val_loss: 2.0575 - val_f1: 0.4396\n",
      "Epoch 14/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.5496 - f1: 0.5775 - val_loss: 1.9811 - val_f1: 0.4684\n",
      "Epoch 15/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4430 - f1: 0.7279 - val_loss: 1.9464 - val_f1: 0.5026\n",
      "Epoch 16/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3721 - f1: 0.7678 - val_loss: 1.8926 - val_f1: 0.5217\n",
      "Epoch 17/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3271 - f1: 0.7136 - val_loss: 1.8281 - val_f1: 0.5385\n",
      "Epoch 18/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2203 - f1: 0.5935 - val_loss: 1.8024 - val_f1: 0.5588\n",
      "Epoch 19/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2125 - f1: 0.8239 - val_loss: 1.8049 - val_f1: 0.5758\n",
      "Epoch 20/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1515 - f1: 0.8135 - val_loss: 1.7674 - val_f1: 0.5800\n",
      "Epoch 21/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1001 - f1: 0.8294 - val_loss: 1.7030 - val_f1: 0.6150\n",
      "Epoch 22/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0550 - f1: 0.9174 - val_loss: 1.7056 - val_f1: 0.6316\n",
      "Epoch 23/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0706 - f1: 0.9074 - val_loss: 1.6908 - val_f1: 0.6319\n",
      "Epoch 24/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0029 - f1: 0.9103 - val_loss: 1.6659 - val_f1: 0.6449\n",
      "Epoch 25/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9550 - f1: 0.9487 - val_loss: 1.6281 - val_f1: 0.6667\n",
      "Epoch 26/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9027 - f1: 0.9575 - val_loss: 1.5941 - val_f1: 0.6662\n",
      "Epoch 27/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8954 - f1: 0.9672 - val_loss: 1.5535 - val_f1: 0.6871\n",
      "Epoch 28/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8421 - f1: 0.9397 - val_loss: 1.5256 - val_f1: 0.6925\n",
      "Epoch 29/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8132 - f1: 0.9007 - val_loss: 1.5146 - val_f1: 0.6918\n",
      "Epoch 30/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8002 - f1: 0.9880 - val_loss: 1.5086 - val_f1: 0.6941\n",
      "Epoch 31/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7849 - f1: 0.9921 - val_loss: 1.4821 - val_f1: 0.7035\n",
      "Epoch 32/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7521 - f1: 0.9921 - val_loss: 1.4719 - val_f1: 0.6985\n",
      "Epoch 33/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7394 - f1: 0.9960 - val_loss: 1.4729 - val_f1: 0.6993\n",
      "Epoch 34/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7163 - f1: 0.9960 - val_loss: 1.4984 - val_f1: 0.6939\n",
      "Epoch 35/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7073 - f1: 0.9921 - val_loss: 1.4891 - val_f1: 0.6960\n",
      "Epoch 36/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7038 - f1: 0.9800 - val_loss: 1.4548 - val_f1: 0.7023\n",
      "Epoch 37/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6690 - f1: 1.0000 - val_loss: 1.4292 - val_f1: 0.7133\n",
      "Epoch 38/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6647 - f1: 0.9960 - val_loss: 1.4200 - val_f1: 0.7140\n",
      "Epoch 39/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6491 - f1: 0.9921 - val_loss: 1.4141 - val_f1: 0.7123\n",
      "Epoch 40/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6262 - f1: 1.0000 - val_loss: 1.4126 - val_f1: 0.7060\n",
      "Epoch 41/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6107 - f1: 1.0000 - val_loss: 1.3794 - val_f1: 0.7157\n",
      "Epoch 42/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5953 - f1: 1.0000 - val_loss: 1.3598 - val_f1: 0.7167\n",
      "Epoch 43/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5855 - f1: 1.0000 - val_loss: 1.3402 - val_f1: 0.7196\n",
      "Epoch 44/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5671 - f1: 1.0000 - val_loss: 1.3181 - val_f1: 0.7232\n",
      "Epoch 45/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5657 - f1: 1.0000 - val_loss: 1.3201 - val_f1: 0.7203\n",
      "Epoch 46/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5643 - f1: 1.0000 - val_loss: 1.3742 - val_f1: 0.7030\n",
      "Epoch 47/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5608 - f1: 1.0000 - val_loss: 1.3148 - val_f1: 0.7283\n",
      "Epoch 48/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5327 - f1: 1.0000 - val_loss: 1.3009 - val_f1: 0.7224\n",
      "Epoch 49/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5237 - f1: 1.0000 - val_loss: 1.2796 - val_f1: 0.7278\n",
      "Epoch 50/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5117 - f1: 1.0000 - val_loss: 1.2720 - val_f1: 0.7279\n",
      "Epoch 51/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5016 - f1: 1.0000 - val_loss: 1.2688 - val_f1: 0.7275\n",
      "Epoch 52/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4972 - f1: 1.0000 - val_loss: 1.2500 - val_f1: 0.7297\n",
      "Epoch 53/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4817 - f1: 1.0000 - val_loss: 1.2532 - val_f1: 0.7234\n",
      "Epoch 54/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4849 - f1: 1.0000 - val_loss: 1.2531 - val_f1: 0.7239\n",
      "Epoch 55/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4824 - f1: 1.0000 - val_loss: 1.3082 - val_f1: 0.7017\n",
      "Epoch 56/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4785 - f1: 1.0000 - val_loss: 1.2691 - val_f1: 0.7205\n",
      "Epoch 57/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4636 - f1: 1.0000 - val_loss: 1.2799 - val_f1: 0.7230\n",
      "Running through fold 1\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 1s 12ms/sample - loss: 4.7484 - f1: 0.0000e+00 - val_loss: 4.3510 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.2220 - f1: 0.0000e+00 - val_loss: 3.9790 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7690 - f1: 0.0000e+00 - val_loss: 3.6129 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.3729 - f1: 0.0000e+00 - val_loss: 3.3008 - val_f1: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.0344 - f1: 0.0303 - val_loss: 3.0177 - val_f1: 0.0729\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.7131 - f1: 0.1001 - val_loss: 2.7839 - val_f1: 0.1247\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.4682 - f1: 0.2533 - val_loss: 2.6161 - val_f1: 0.2125\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.2678 - f1: 0.3656 - val_loss: 2.4739 - val_f1: 0.2841\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.0986 - f1: 0.3245 - val_loss: 2.3578 - val_f1: 0.3268\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.9464 - f1: 0.4261 - val_loss: 2.2491 - val_f1: 0.3852\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.8060 - f1: 0.5453 - val_loss: 2.1421 - val_f1: 0.4057\n",
      "Epoch 12/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6672 - f1: 0.6333 - val_loss: 2.0976 - val_f1: 0.4273\n",
      "Epoch 13/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6384 - f1: 0.4911 - val_loss: 2.0313 - val_f1: 0.4658\n",
      "Epoch 14/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.5621 - f1: 0.6803 - val_loss: 1.9898 - val_f1: 0.5126\n",
      "Epoch 15/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.5172 - f1: 0.6416 - val_loss: 1.9082 - val_f1: 0.5649\n",
      "Epoch 16/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3829 - f1: 0.6097 - val_loss: 1.8548 - val_f1: 0.5826\n",
      "Epoch 17/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3092 - f1: 0.7424 - val_loss: 1.8262 - val_f1: 0.5862\n",
      "Epoch 18/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2889 - f1: 0.7665 - val_loss: 1.7930 - val_f1: 0.5875\n",
      "Epoch 19/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2438 - f1: 0.8185 - val_loss: 1.7607 - val_f1: 0.5966\n",
      "Epoch 20/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2179 - f1: 0.7277 - val_loss: 1.7211 - val_f1: 0.6148\n",
      "Epoch 21/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1475 - f1: 0.8177 - val_loss: 1.6972 - val_f1: 0.6290\n",
      "Epoch 22/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1036 - f1: 0.9180 - val_loss: 1.6606 - val_f1: 0.6490\n",
      "Epoch 23/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0638 - f1: 0.7763 - val_loss: 1.6243 - val_f1: 0.6697\n",
      "Epoch 24/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0482 - f1: 0.8779 - val_loss: 1.5929 - val_f1: 0.6762\n",
      "Epoch 25/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9856 - f1: 0.8869 - val_loss: 1.5741 - val_f1: 0.6736\n",
      "Epoch 26/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9496 - f1: 0.9013 - val_loss: 1.5524 - val_f1: 0.6815\n",
      "Epoch 27/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9234 - f1: 0.9535 - val_loss: 1.5360 - val_f1: 0.6853\n",
      "Epoch 28/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9017 - f1: 0.9411 - val_loss: 1.5037 - val_f1: 0.6897\n",
      "Epoch 29/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8752 - f1: 0.9415 - val_loss: 1.4684 - val_f1: 0.7032\n",
      "Epoch 30/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8371 - f1: 0.9621 - val_loss: 1.4447 - val_f1: 0.7109\n",
      "Epoch 31/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8085 - f1: 0.9671 - val_loss: 1.4368 - val_f1: 0.7116\n",
      "Epoch 32/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7890 - f1: 0.9668 - val_loss: 1.4395 - val_f1: 0.7118\n",
      "Epoch 33/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7893 - f1: 0.9676 - val_loss: 1.4434 - val_f1: 0.7106\n",
      "Epoch 34/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7783 - f1: 0.9553 - val_loss: 1.4215 - val_f1: 0.7135\n",
      "Epoch 35/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7549 - f1: 0.9679 - val_loss: 1.4247 - val_f1: 0.7140\n",
      "Epoch 36/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7470 - f1: 0.9629 - val_loss: 1.4141 - val_f1: 0.7150\n",
      "Epoch 37/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7258 - f1: 0.9718 - val_loss: 1.4140 - val_f1: 0.7048\n",
      "Epoch 38/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7237 - f1: 0.9402 - val_loss: 1.3829 - val_f1: 0.7140\n",
      "Epoch 39/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7116 - f1: 0.9676 - val_loss: 1.3840 - val_f1: 0.7144\n",
      "Epoch 40/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7010 - f1: 0.9675 - val_loss: 1.3770 - val_f1: 0.7152\n",
      "Epoch 41/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6858 - f1: 0.9758 - val_loss: 1.3644 - val_f1: 0.7209\n",
      "Epoch 42/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6773 - f1: 0.9798 - val_loss: 1.3598 - val_f1: 0.7196\n",
      "Epoch 43/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6545 - f1: 0.9714 - val_loss: 1.3638 - val_f1: 0.7161\n",
      "Epoch 44/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6281 - f1: 0.9881 - val_loss: 1.3523 - val_f1: 0.7140\n",
      "Running through fold 2\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 1s 13ms/sample - loss: 4.7619 - f1: 0.0000e+00 - val_loss: 4.3751 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.1940 - f1: 0.0000e+00 - val_loss: 3.9473 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7324 - f1: 0.0000e+00 - val_loss: 3.5868 - val_f1: 0.0173\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.3305 - f1: 0.0446 - val_loss: 3.2485 - val_f1: 0.1199\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.9880 - f1: 0.1390 - val_loss: 3.0051 - val_f1: 0.1657\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.7203 - f1: 0.3202 - val_loss: 2.7953 - val_f1: 0.2373\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.4852 - f1: 0.3563 - val_loss: 2.6435 - val_f1: 0.2691\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.3216 - f1: 0.2964 - val_loss: 2.5044 - val_f1: 0.3098\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.1726 - f1: 0.4540 - val_loss: 2.3718 - val_f1: 0.3223\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.9977 - f1: 0.5583 - val_loss: 2.2625 - val_f1: 0.3626\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.9066 - f1: 0.4966 - val_loss: 2.1828 - val_f1: 0.3923\n",
      "Epoch 12/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.7880 - f1: 0.5245 - val_loss: 2.1078 - val_f1: 0.4294\n",
      "Epoch 13/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6928 - f1: 0.6057 - val_loss: 2.0182 - val_f1: 0.4692\n",
      "Epoch 14/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.5908 - f1: 0.7194 - val_loss: 1.9525 - val_f1: 0.4982\n",
      "Epoch 15/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4959 - f1: 0.6988 - val_loss: 1.8941 - val_f1: 0.5294\n",
      "Epoch 16/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4275 - f1: 0.7643 - val_loss: 1.8296 - val_f1: 0.5622\n",
      "Epoch 17/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3623 - f1: 0.7847 - val_loss: 1.7984 - val_f1: 0.5801\n",
      "Epoch 18/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2994 - f1: 0.8211 - val_loss: 1.7477 - val_f1: 0.6014\n",
      "Epoch 19/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2332 - f1: 0.7146 - val_loss: 1.6928 - val_f1: 0.6096\n",
      "Epoch 20/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1737 - f1: 0.7828 - val_loss: 1.6640 - val_f1: 0.6392\n",
      "Epoch 21/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1319 - f1: 0.8519 - val_loss: 1.6199 - val_f1: 0.6548\n",
      "Epoch 22/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0857 - f1: 0.8939 - val_loss: 1.5987 - val_f1: 0.6618\n",
      "Epoch 23/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0487 - f1: 0.8991 - val_loss: 1.6012 - val_f1: 0.6586\n",
      "Epoch 24/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0363 - f1: 0.8902 - val_loss: 1.5650 - val_f1: 0.6635\n",
      "Epoch 25/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9875 - f1: 0.9124 - val_loss: 1.5181 - val_f1: 0.6815\n",
      "Epoch 26/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9376 - f1: 0.9049 - val_loss: 1.5006 - val_f1: 0.6966\n",
      "Epoch 27/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8997 - f1: 0.8606 - val_loss: 1.5110 - val_f1: 0.6870\n",
      "Epoch 28/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8714 - f1: 0.9410 - val_loss: 1.4786 - val_f1: 0.6879\n",
      "Epoch 29/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8749 - f1: 0.9268 - val_loss: 1.4516 - val_f1: 0.7000\n",
      "Epoch 30/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8520 - f1: 0.9453 - val_loss: 1.4423 - val_f1: 0.6982\n",
      "Epoch 31/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8093 - f1: 0.9549 - val_loss: 1.4556 - val_f1: 0.6958\n",
      "Epoch 32/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7895 - f1: 0.9185 - val_loss: 1.4535 - val_f1: 0.6957\n",
      "Epoch 33/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7602 - f1: 0.9585 - val_loss: 1.4125 - val_f1: 0.7044\n",
      "Epoch 34/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7506 - f1: 0.9184 - val_loss: 1.3897 - val_f1: 0.7137\n",
      "Epoch 35/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7331 - f1: 0.9359 - val_loss: 1.3946 - val_f1: 0.7068\n",
      "Epoch 36/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7286 - f1: 0.9315 - val_loss: 1.4048 - val_f1: 0.7011\n",
      "Epoch 37/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7159 - f1: 0.9626 - val_loss: 1.4160 - val_f1: 0.6888\n",
      "Epoch 38/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7095 - f1: 0.9669 - val_loss: 1.4146 - val_f1: 0.6965\n",
      "Epoch 39/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6945 - f1: 0.9591 - val_loss: 1.3883 - val_f1: 0.6998\n",
      "Epoch 40/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6784 - f1: 0.9718 - val_loss: 1.3751 - val_f1: 0.6969\n",
      "Epoch 41/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6474 - f1: 0.9840 - val_loss: 1.3508 - val_f1: 0.7074\n",
      "Epoch 42/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6285 - f1: 0.9880 - val_loss: 1.3218 - val_f1: 0.7147\n",
      "Epoch 43/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6236 - f1: 0.9837 - val_loss: 1.3080 - val_f1: 0.7197\n",
      "Epoch 44/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6246 - f1: 0.9840 - val_loss: 1.3140 - val_f1: 0.7209\n",
      "Running through fold 3\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 1s 14ms/sample - loss: 4.7661 - f1: 0.0000e+00 - val_loss: 4.3573 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.1622 - f1: 0.0000e+00 - val_loss: 3.9705 - val_f1: 0.0149\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7322 - f1: 0.0294 - val_loss: 3.6240 - val_f1: 0.0364\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.3366 - f1: 0.2017 - val_loss: 3.3198 - val_f1: 0.1185\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.9797 - f1: 0.2907 - val_loss: 3.0480 - val_f1: 0.1814\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.7256 - f1: 0.3694 - val_loss: 2.8605 - val_f1: 0.2182\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.4697 - f1: 0.3579 - val_loss: 2.6615 - val_f1: 0.2322\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.2606 - f1: 0.3687 - val_loss: 2.4964 - val_f1: 0.2490\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.1198 - f1: 0.4843 - val_loss: 2.3797 - val_f1: 0.2985\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.9516 - f1: 0.3887 - val_loss: 2.2371 - val_f1: 0.3683\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.7983 - f1: 0.6346 - val_loss: 2.1598 - val_f1: 0.4004\n",
      "Epoch 12/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6925 - f1: 0.5812 - val_loss: 2.0799 - val_f1: 0.4385\n",
      "Epoch 13/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6206 - f1: 0.7491 - val_loss: 2.0138 - val_f1: 0.4752\n",
      "Epoch 14/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.5038 - f1: 0.7157 - val_loss: 1.9956 - val_f1: 0.4791\n",
      "Epoch 15/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4626 - f1: 0.7572 - val_loss: 1.9947 - val_f1: 0.4757\n",
      "Epoch 16/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4326 - f1: 0.6516 - val_loss: 1.9273 - val_f1: 0.5073\n",
      "Epoch 17/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3267 - f1: 0.7786 - val_loss: 1.8429 - val_f1: 0.5472\n",
      "Epoch 18/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2697 - f1: 0.6998 - val_loss: 1.8009 - val_f1: 0.5729\n",
      "Epoch 19/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2259 - f1: 0.8381 - val_loss: 1.7633 - val_f1: 0.5803\n",
      "Epoch 20/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1802 - f1: 0.8477 - val_loss: 1.7201 - val_f1: 0.5961\n",
      "Epoch 21/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1196 - f1: 0.7916 - val_loss: 1.6938 - val_f1: 0.6078\n",
      "Epoch 22/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1031 - f1: 0.8121 - val_loss: 1.6802 - val_f1: 0.6161\n",
      "Epoch 23/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0717 - f1: 0.8819 - val_loss: 1.6519 - val_f1: 0.6320\n",
      "Epoch 24/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0117 - f1: 0.9022 - val_loss: 1.6291 - val_f1: 0.6327\n",
      "Epoch 25/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9811 - f1: 0.8826 - val_loss: 1.6010 - val_f1: 0.6341\n",
      "Epoch 26/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9377 - f1: 0.9087 - val_loss: 1.5912 - val_f1: 0.6297\n",
      "Epoch 27/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9151 - f1: 0.9035 - val_loss: 1.5704 - val_f1: 0.6458\n",
      "Epoch 28/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8811 - f1: 0.8530 - val_loss: 1.5402 - val_f1: 0.6554\n",
      "Epoch 29/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8463 - f1: 0.9490 - val_loss: 1.5243 - val_f1: 0.6649\n",
      "Epoch 30/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8440 - f1: 0.9587 - val_loss: 1.4951 - val_f1: 0.6808\n",
      "Epoch 31/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7962 - f1: 0.9626 - val_loss: 1.4736 - val_f1: 0.6924\n",
      "Epoch 32/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7748 - f1: 0.9710 - val_loss: 1.4605 - val_f1: 0.6952\n",
      "Epoch 33/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7547 - f1: 0.9361 - val_loss: 1.4552 - val_f1: 0.6952\n",
      "Epoch 34/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7641 - f1: 0.9275 - val_loss: 1.4516 - val_f1: 0.6906\n",
      "Epoch 35/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7232 - f1: 0.9753 - val_loss: 1.4258 - val_f1: 0.6901\n",
      "Epoch 36/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7329 - f1: 0.9315 - val_loss: 1.4336 - val_f1: 0.6958\n",
      "Epoch 37/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7231 - f1: 0.9709 - val_loss: 1.4312 - val_f1: 0.7058\n",
      "Epoch 38/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6864 - f1: 0.9798 - val_loss: 1.4167 - val_f1: 0.7063\n",
      "Epoch 39/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6602 - f1: 0.9798 - val_loss: 1.4057 - val_f1: 0.7065\n",
      "Epoch 40/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6342 - f1: 0.9921 - val_loss: 1.3685 - val_f1: 0.7140\n",
      "Epoch 41/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6210 - f1: 0.9921 - val_loss: 1.3581 - val_f1: 0.7189\n",
      "Epoch 42/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6073 - f1: 0.9922 - val_loss: 1.3589 - val_f1: 0.7135\n",
      "Epoch 43/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6041 - f1: 0.9881 - val_loss: 1.3489 - val_f1: 0.7154\n",
      "Epoch 44/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5894 - f1: 0.9960 - val_loss: 1.3498 - val_f1: 0.7124\n",
      "Epoch 45/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5820 - f1: 0.9921 - val_loss: 1.3292 - val_f1: 0.7200\n",
      "Epoch 46/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5640 - f1: 1.0000 - val_loss: 1.2963 - val_f1: 0.7284\n",
      "Epoch 47/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5581 - f1: 0.9960 - val_loss: 1.3038 - val_f1: 0.7259\n",
      "Epoch 48/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5450 - f1: 0.9960 - val_loss: 1.3198 - val_f1: 0.7222\n",
      "Epoch 49/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5408 - f1: 0.9960 - val_loss: 1.2991 - val_f1: 0.7339\n",
      "Epoch 50/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5212 - f1: 1.0000 - val_loss: 1.2939 - val_f1: 0.7281\n",
      "Epoch 51/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5174 - f1: 1.0000 - val_loss: 1.2539 - val_f1: 0.7399\n",
      "Epoch 52/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5039 - f1: 1.0000 - val_loss: 1.2465 - val_f1: 0.7462\n",
      "Epoch 53/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5014 - f1: 0.9960 - val_loss: 1.2515 - val_f1: 0.7380\n",
      "Epoch 54/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5108 - f1: 0.9922 - val_loss: 1.2507 - val_f1: 0.7379\n",
      "Epoch 55/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4876 - f1: 0.9960 - val_loss: 1.2923 - val_f1: 0.7272\n",
      "Epoch 56/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4948 - f1: 0.9921 - val_loss: 1.2898 - val_f1: 0.7221\n",
      "Epoch 57/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4822 - f1: 1.0000 - val_loss: 1.2680 - val_f1: 0.7343\n",
      "Epoch 58/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4754 - f1: 0.9922 - val_loss: 1.3430 - val_f1: 0.7125\n",
      "Epoch 59/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4984 - f1: 0.9763 - val_loss: 1.2728 - val_f1: 0.7320\n",
      "Epoch 60/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4530 - f1: 1.0000 - val_loss: 1.2684 - val_f1: 0.7273\n",
      "Epoch 61/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4668 - f1: 0.9960 - val_loss: 1.2605 - val_f1: 0.7286\n",
      "Epoch 62/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.4577 - f1: 1.0000 - val_loss: 1.3380 - val_f1: 0.7050\n",
      "Running through fold 4\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 1s 14ms/sample - loss: 4.7824 - f1: 0.0000e+00 - val_loss: 4.3913 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.2490 - f1: 0.0000e+00 - val_loss: 4.0151 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8114 - f1: 0.0000e+00 - val_loss: 3.6316 - val_f1: 0.0184\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.3781 - f1: 0.0303 - val_loss: 3.2964 - val_f1: 0.0908\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.0095 - f1: 0.1405 - val_loss: 3.0128 - val_f1: 0.1741\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.7029 - f1: 0.2551 - val_loss: 2.7696 - val_f1: 0.2218\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.4470 - f1: 0.3653 - val_loss: 2.6104 - val_f1: 0.2573\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.2933 - f1: 0.3700 - val_loss: 2.4638 - val_f1: 0.3036\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.1032 - f1: 0.4955 - val_loss: 2.3587 - val_f1: 0.3755\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.9735 - f1: 0.3691 - val_loss: 2.2605 - val_f1: 0.3967\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.8581 - f1: 0.6457 - val_loss: 2.1587 - val_f1: 0.4313\n",
      "Epoch 12/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.7376 - f1: 0.5411 - val_loss: 2.0695 - val_f1: 0.4657\n",
      "Epoch 13/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6553 - f1: 0.4917 - val_loss: 1.9959 - val_f1: 0.4992\n",
      "Epoch 14/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.5444 - f1: 0.5981 - val_loss: 1.9441 - val_f1: 0.5081\n",
      "Epoch 15/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4825 - f1: 0.6919 - val_loss: 1.9075 - val_f1: 0.5373\n",
      "Epoch 16/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4635 - f1: 0.7020 - val_loss: 1.8506 - val_f1: 0.5538\n",
      "Epoch 17/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3665 - f1: 0.7140 - val_loss: 1.7837 - val_f1: 0.5774\n",
      "Epoch 18/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2792 - f1: 0.8259 - val_loss: 1.7513 - val_f1: 0.5958\n",
      "Epoch 19/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2553 - f1: 0.7308 - val_loss: 1.7135 - val_f1: 0.5940\n",
      "Epoch 20/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2049 - f1: 0.8057 - val_loss: 1.6632 - val_f1: 0.6075\n",
      "Epoch 21/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1360 - f1: 0.8460 - val_loss: 1.6266 - val_f1: 0.6254\n",
      "Epoch 22/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1044 - f1: 0.8570 - val_loss: 1.6134 - val_f1: 0.6292\n",
      "Epoch 23/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0808 - f1: 0.8627 - val_loss: 1.6006 - val_f1: 0.6279\n",
      "Epoch 24/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0367 - f1: 0.8923 - val_loss: 1.5702 - val_f1: 0.6508\n",
      "Epoch 25/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0002 - f1: 0.8672 - val_loss: 1.5236 - val_f1: 0.6741\n",
      "Epoch 26/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9542 - f1: 0.9176 - val_loss: 1.5052 - val_f1: 0.6775\n",
      "Epoch 27/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9212 - f1: 0.9092 - val_loss: 1.4689 - val_f1: 0.6847\n",
      "Epoch 28/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9008 - f1: 0.8635 - val_loss: 1.4582 - val_f1: 0.6899\n",
      "Epoch 29/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9055 - f1: 0.9403 - val_loss: 1.4535 - val_f1: 0.7011\n",
      "Epoch 30/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8596 - f1: 0.9138 - val_loss: 1.4288 - val_f1: 0.7101\n",
      "Epoch 31/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8432 - f1: 0.9141 - val_loss: 1.4162 - val_f1: 0.7205\n",
      "Epoch 32/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8128 - f1: 0.9546 - val_loss: 1.4010 - val_f1: 0.7213\n",
      "Epoch 33/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7840 - f1: 0.9758 - val_loss: 1.3944 - val_f1: 0.7204\n",
      "Epoch 34/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7638 - f1: 0.9757 - val_loss: 1.3920 - val_f1: 0.7228\n",
      "Epoch 35/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7443 - f1: 0.9710 - val_loss: 1.3666 - val_f1: 0.7301\n",
      "Epoch 36/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7322 - f1: 0.9798 - val_loss: 1.3344 - val_f1: 0.7380\n",
      "Epoch 37/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7115 - f1: 0.9880 - val_loss: 1.3156 - val_f1: 0.7410\n",
      "Epoch 38/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7005 - f1: 0.9523 - val_loss: 1.3232 - val_f1: 0.7365\n",
      "Epoch 39/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6957 - f1: 0.9562 - val_loss: 1.3215 - val_f1: 0.7344\n",
      "Epoch 40/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6803 - f1: 0.9798 - val_loss: 1.3534 - val_f1: 0.7436\n",
      "Epoch 41/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7176 - f1: 0.9630 - val_loss: 1.3456 - val_f1: 0.7417\n",
      "Epoch 42/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6841 - f1: 0.9843 - val_loss: 1.3444 - val_f1: 0.7276\n",
      "Epoch 43/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6673 - f1: 0.9841 - val_loss: 1.3232 - val_f1: 0.7366\n",
      "Epoch 44/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6392 - f1: 0.9880 - val_loss: 1.2944 - val_f1: 0.7423\n",
      "Epoch 45/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6105 - f1: 0.9921 - val_loss: 1.2774 - val_f1: 0.7429\n",
      "Epoch 46/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6038 - f1: 1.0000 - val_loss: 1.2637 - val_f1: 0.7485\n",
      "Epoch 47/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5909 - f1: 0.9960 - val_loss: 1.2456 - val_f1: 0.7592\n",
      "Epoch 48/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5917 - f1: 0.9881 - val_loss: 1.2665 - val_f1: 0.7586\n",
      "Epoch 49/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6007 - f1: 0.9803 - val_loss: 1.2379 - val_f1: 0.7671\n",
      "Epoch 50/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5642 - f1: 1.0000 - val_loss: 1.2169 - val_f1: 0.7648\n",
      "Epoch 51/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5609 - f1: 0.9922 - val_loss: 1.2316 - val_f1: 0.7571\n",
      "Epoch 52/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5587 - f1: 0.9922 - val_loss: 1.2611 - val_f1: 0.7477\n",
      "Epoch 53/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5504 - f1: 0.9960 - val_loss: 1.2543 - val_f1: 0.7529\n",
      "Epoch 54/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5342 - f1: 1.0000 - val_loss: 1.2306 - val_f1: 0.7657\n",
      "Epoch 55/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5225 - f1: 1.0000 - val_loss: 1.2285 - val_f1: 0.7631\n",
      "Epoch 56/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5130 - f1: 1.0000 - val_loss: 1.2073 - val_f1: 0.7630\n",
      "Epoch 57/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5024 - f1: 1.0000 - val_loss: 1.1905 - val_f1: 0.7657\n",
      "\n",
      "\n",
      "Running through training size 500\n",
      "Running through fold 0\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 4.0858 - f1: 0.0171 - val_loss: 3.1327 - val_f1: 0.1128\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 790us/sample - loss: 2.6530 - f1: 0.2509 - val_loss: 2.2315 - val_f1: 0.3842\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 791us/sample - loss: 1.9456 - f1: 0.4463 - val_loss: 1.7372 - val_f1: 0.5665\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 789us/sample - loss: 1.5308 - f1: 0.6733 - val_loss: 1.4371 - val_f1: 0.7143\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 788us/sample - loss: 1.2592 - f1: 0.7765 - val_loss: 1.2462 - val_f1: 0.7618\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 786us/sample - loss: 1.0795 - f1: 0.8231 - val_loss: 1.1069 - val_f1: 0.8103\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 790us/sample - loss: 0.9697 - f1: 0.8621 - val_loss: 1.0333 - val_f1: 0.8243\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 789us/sample - loss: 0.8735 - f1: 0.8966 - val_loss: 0.9413 - val_f1: 0.8576\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 783us/sample - loss: 0.8083 - f1: 0.9080 - val_loss: 0.8795 - val_f1: 0.8654\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 785us/sample - loss: 0.7465 - f1: 0.9239 - val_loss: 0.8263 - val_f1: 0.8799\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 0s 785us/sample - loss: 0.6961 - f1: 0.9240 - val_loss: 0.8002 - val_f1: 0.8770\n",
      "Epoch 12/2000\n",
      "500/500 [==============================] - 0s 783us/sample - loss: 0.6486 - f1: 0.9294 - val_loss: 0.7664 - val_f1: 0.8834\n",
      "Epoch 13/2000\n",
      "500/500 [==============================] - 0s 784us/sample - loss: 0.6139 - f1: 0.9416 - val_loss: 0.7444 - val_f1: 0.8868\n",
      "Epoch 14/2000\n",
      "500/500 [==============================] - 0s 779us/sample - loss: 0.6079 - f1: 0.9275 - val_loss: 0.7516 - val_f1: 0.8714\n",
      "Epoch 15/2000\n",
      "500/500 [==============================] - 0s 784us/sample - loss: 0.6161 - f1: 0.9270 - val_loss: 0.7394 - val_f1: 0.8743\n",
      "Epoch 16/2000\n",
      "500/500 [==============================] - 0s 787us/sample - loss: 0.5817 - f1: 0.9392 - val_loss: 0.6930 - val_f1: 0.8847\n",
      "Epoch 17/2000\n",
      "500/500 [==============================] - 0s 792us/sample - loss: 0.5470 - f1: 0.9414 - val_loss: 0.6527 - val_f1: 0.8917\n",
      "Epoch 18/2000\n",
      "500/500 [==============================] - 0s 783us/sample - loss: 0.5073 - f1: 0.9515 - val_loss: 0.6328 - val_f1: 0.8907\n",
      "Epoch 19/2000\n",
      "500/500 [==============================] - 0s 782us/sample - loss: 0.4807 - f1: 0.9461 - val_loss: 0.6162 - val_f1: 0.8866\n",
      "Epoch 20/2000\n",
      "500/500 [==============================] - 0s 780us/sample - loss: 0.4618 - f1: 0.9504 - val_loss: 0.6165 - val_f1: 0.8905\n",
      "Epoch 21/2000\n",
      "500/500 [==============================] - 0s 787us/sample - loss: 0.4436 - f1: 0.9574 - val_loss: 0.5818 - val_f1: 0.8962\n",
      "Epoch 22/2000\n",
      "500/500 [==============================] - 0s 786us/sample - loss: 0.4297 - f1: 0.9526 - val_loss: 0.5599 - val_f1: 0.8964\n",
      "Epoch 23/2000\n",
      "500/500 [==============================] - 0s 785us/sample - loss: 0.4271 - f1: 0.9473 - val_loss: 0.5932 - val_f1: 0.8859\n",
      "Epoch 24/2000\n",
      "500/500 [==============================] - 0s 798us/sample - loss: 0.4141 - f1: 0.9524 - val_loss: 0.5405 - val_f1: 0.9040\n",
      "Epoch 25/2000\n",
      "500/500 [==============================] - 0s 799us/sample - loss: 0.4120 - f1: 0.9514 - val_loss: 0.5846 - val_f1: 0.8806\n",
      "Epoch 26/2000\n",
      "500/500 [==============================] - 0s 786us/sample - loss: 0.4080 - f1: 0.9552 - val_loss: 0.5548 - val_f1: 0.8945\n",
      "Epoch 27/2000\n",
      "500/500 [==============================] - 0s 790us/sample - loss: 0.4023 - f1: 0.9595 - val_loss: 0.5714 - val_f1: 0.8860\n",
      "Epoch 28/2000\n",
      "500/500 [==============================] - 0s 790us/sample - loss: 0.3775 - f1: 0.9633 - val_loss: 0.5283 - val_f1: 0.8980\n",
      "Epoch 29/2000\n",
      "500/500 [==============================] - 0s 798us/sample - loss: 0.3598 - f1: 0.9606 - val_loss: 0.5354 - val_f1: 0.8955\n",
      "Epoch 30/2000\n",
      "500/500 [==============================] - 0s 797us/sample - loss: 0.3481 - f1: 0.9686 - val_loss: 0.5273 - val_f1: 0.8901\n",
      "Epoch 31/2000\n",
      "500/500 [==============================] - 0s 793us/sample - loss: 0.3468 - f1: 0.9661 - val_loss: 0.5512 - val_f1: 0.8830\n",
      "Epoch 32/2000\n",
      "500/500 [==============================] - 0s 798us/sample - loss: 0.3472 - f1: 0.9657 - val_loss: 0.5638 - val_f1: 0.8847\n",
      "Epoch 33/2000\n",
      "500/500 [==============================] - 0s 792us/sample - loss: 0.3457 - f1: 0.9692 - val_loss: 0.5511 - val_f1: 0.8851\n",
      "Epoch 34/2000\n",
      "500/500 [==============================] - 0s 794us/sample - loss: 0.3416 - f1: 0.9670 - val_loss: 0.5197 - val_f1: 0.8977\n",
      "Running through fold 1\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 4.0873 - f1: 0.0133 - val_loss: 3.1085 - val_f1: 0.1018\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 804us/sample - loss: 2.6345 - f1: 0.2449 - val_loss: 2.1399 - val_f1: 0.3937\n",
      "Epoch 3/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 810us/sample - loss: 1.8944 - f1: 0.4792 - val_loss: 1.6556 - val_f1: 0.5929\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 803us/sample - loss: 1.4998 - f1: 0.6825 - val_loss: 1.3994 - val_f1: 0.7340\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 804us/sample - loss: 1.3090 - f1: 0.7294 - val_loss: 1.2433 - val_f1: 0.7733\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 806us/sample - loss: 1.1250 - f1: 0.8199 - val_loss: 1.1320 - val_f1: 0.8077\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 808us/sample - loss: 1.0076 - f1: 0.8460 - val_loss: 1.0151 - val_f1: 0.8401\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 802us/sample - loss: 0.9069 - f1: 0.8823 - val_loss: 0.9332 - val_f1: 0.8560\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 803us/sample - loss: 0.8420 - f1: 0.8939 - val_loss: 0.8677 - val_f1: 0.8736\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 799us/sample - loss: 0.7740 - f1: 0.8986 - val_loss: 0.8446 - val_f1: 0.8792\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 0s 798us/sample - loss: 0.7258 - f1: 0.9202 - val_loss: 0.7968 - val_f1: 0.8771\n",
      "Epoch 12/2000\n",
      "500/500 [==============================] - 0s 805us/sample - loss: 0.7064 - f1: 0.9202 - val_loss: 0.7574 - val_f1: 0.8912\n",
      "Epoch 13/2000\n",
      "500/500 [==============================] - 0s 798us/sample - loss: 0.6404 - f1: 0.9318 - val_loss: 0.7265 - val_f1: 0.8857\n",
      "Epoch 14/2000\n",
      "500/500 [==============================] - 0s 798us/sample - loss: 0.6141 - f1: 0.9251 - val_loss: 0.6964 - val_f1: 0.8924\n",
      "Epoch 15/2000\n",
      "500/500 [==============================] - 0s 803us/sample - loss: 0.5785 - f1: 0.9361 - val_loss: 0.6733 - val_f1: 0.8936\n",
      "Epoch 16/2000\n",
      "500/500 [==============================] - 0s 803us/sample - loss: 0.5495 - f1: 0.9462 - val_loss: 0.6571 - val_f1: 0.8984\n",
      "Epoch 17/2000\n",
      "500/500 [==============================] - 0s 798us/sample - loss: 0.5224 - f1: 0.9527 - val_loss: 0.6315 - val_f1: 0.8995\n",
      "Epoch 18/2000\n",
      "500/500 [==============================] - 0s 796us/sample - loss: 0.5086 - f1: 0.9565 - val_loss: 0.6516 - val_f1: 0.8811\n",
      "Epoch 19/2000\n",
      "500/500 [==============================] - 0s 800us/sample - loss: 0.5012 - f1: 0.9547 - val_loss: 0.6152 - val_f1: 0.9024\n",
      "Epoch 20/2000\n",
      "500/500 [==============================] - 0s 801us/sample - loss: 0.4900 - f1: 0.9570 - val_loss: 0.5923 - val_f1: 0.9051\n",
      "Epoch 21/2000\n",
      "500/500 [==============================] - 0s 800us/sample - loss: 0.4447 - f1: 0.9661 - val_loss: 0.5848 - val_f1: 0.8992\n",
      "Epoch 22/2000\n",
      "500/500 [==============================] - 0s 796us/sample - loss: 0.4359 - f1: 0.9572 - val_loss: 0.5568 - val_f1: 0.9113\n",
      "Epoch 23/2000\n",
      "500/500 [==============================] - 0s 799us/sample - loss: 0.4182 - f1: 0.9714 - val_loss: 0.5348 - val_f1: 0.9083\n",
      "Epoch 24/2000\n",
      "500/500 [==============================] - 0s 802us/sample - loss: 0.3997 - f1: 0.9739 - val_loss: 0.5594 - val_f1: 0.8965\n",
      "Epoch 25/2000\n",
      "500/500 [==============================] - 0s 797us/sample - loss: 0.4093 - f1: 0.9664 - val_loss: 0.5697 - val_f1: 0.8920\n",
      "Epoch 26/2000\n",
      "500/500 [==============================] - 0s 801us/sample - loss: 0.4000 - f1: 0.9653 - val_loss: 0.5254 - val_f1: 0.9089\n",
      "Epoch 27/2000\n",
      "500/500 [==============================] - 0s 801us/sample - loss: 0.3790 - f1: 0.9694 - val_loss: 0.5381 - val_f1: 0.9041\n",
      "Epoch 28/2000\n",
      "500/500 [==============================] - 0s 803us/sample - loss: 0.3816 - f1: 0.9673 - val_loss: 0.5319 - val_f1: 0.9070\n",
      "Epoch 29/2000\n",
      "500/500 [==============================] - 0s 804us/sample - loss: 0.3588 - f1: 0.9815 - val_loss: 0.5245 - val_f1: 0.9043\n",
      "Running through fold 2\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 4.1041 - f1: 0.0097 - val_loss: 3.1736 - val_f1: 0.0831\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 808us/sample - loss: 2.7158 - f1: 0.1810 - val_loss: 2.2041 - val_f1: 0.3016\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 805us/sample - loss: 1.9718 - f1: 0.4169 - val_loss: 1.7194 - val_f1: 0.5598\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 1.5694 - f1: 0.6637 - val_loss: 1.4221 - val_f1: 0.7195\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 810us/sample - loss: 1.3129 - f1: 0.7462 - val_loss: 1.2468 - val_f1: 0.7613\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 809us/sample - loss: 1.1676 - f1: 0.7970 - val_loss: 1.1183 - val_f1: 0.8027\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 803us/sample - loss: 1.0454 - f1: 0.8299 - val_loss: 1.0391 - val_f1: 0.8400\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 806us/sample - loss: 0.9641 - f1: 0.8575 - val_loss: 0.9525 - val_f1: 0.8430\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 805us/sample - loss: 0.8776 - f1: 0.8735 - val_loss: 0.8763 - val_f1: 0.8665\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 805us/sample - loss: 0.8129 - f1: 0.8841 - val_loss: 0.8234 - val_f1: 0.8712\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 0s 804us/sample - loss: 0.7681 - f1: 0.8953 - val_loss: 0.7950 - val_f1: 0.8781\n",
      "Epoch 12/2000\n",
      "500/500 [==============================] - 0s 804us/sample - loss: 0.7348 - f1: 0.8949 - val_loss: 0.7690 - val_f1: 0.8797\n",
      "Epoch 13/2000\n",
      "500/500 [==============================] - 0s 805us/sample - loss: 0.7014 - f1: 0.9101 - val_loss: 0.7292 - val_f1: 0.8867\n",
      "Epoch 14/2000\n",
      "500/500 [==============================] - 0s 805us/sample - loss: 0.6524 - f1: 0.9295 - val_loss: 0.6979 - val_f1: 0.8959\n",
      "Epoch 15/2000\n",
      "500/500 [==============================] - 0s 805us/sample - loss: 0.6167 - f1: 0.9251 - val_loss: 0.6809 - val_f1: 0.8957\n",
      "Epoch 16/2000\n",
      "500/500 [==============================] - 0s 802us/sample - loss: 0.5852 - f1: 0.9333 - val_loss: 0.6528 - val_f1: 0.8989\n",
      "Epoch 17/2000\n",
      "500/500 [==============================] - 0s 797us/sample - loss: 0.5555 - f1: 0.9327 - val_loss: 0.6127 - val_f1: 0.9072\n",
      "Epoch 18/2000\n",
      "500/500 [==============================] - 0s 795us/sample - loss: 0.5468 - f1: 0.9366 - val_loss: 0.6147 - val_f1: 0.9002\n",
      "Epoch 19/2000\n",
      "500/500 [==============================] - 0s 796us/sample - loss: 0.5350 - f1: 0.9502 - val_loss: 0.5970 - val_f1: 0.9041\n",
      "Epoch 20/2000\n",
      "500/500 [==============================] - 0s 792us/sample - loss: 0.5172 - f1: 0.9387 - val_loss: 0.5777 - val_f1: 0.9070\n",
      "Epoch 21/2000\n",
      "500/500 [==============================] - 0s 797us/sample - loss: 0.5121 - f1: 0.9328 - val_loss: 0.5918 - val_f1: 0.8900\n",
      "Epoch 22/2000\n",
      "500/500 [==============================] - 0s 794us/sample - loss: 0.4866 - f1: 0.9349 - val_loss: 0.5528 - val_f1: 0.9107\n",
      "Epoch 23/2000\n",
      "500/500 [==============================] - 0s 796us/sample - loss: 0.4625 - f1: 0.9480 - val_loss: 0.5743 - val_f1: 0.8966\n",
      "Epoch 24/2000\n",
      "500/500 [==============================] - 0s 793us/sample - loss: 0.4533 - f1: 0.9485 - val_loss: 0.5322 - val_f1: 0.9133\n",
      "Epoch 25/2000\n",
      "500/500 [==============================] - 0s 793us/sample - loss: 0.4218 - f1: 0.9618 - val_loss: 0.5076 - val_f1: 0.9150\n",
      "Epoch 26/2000\n",
      "500/500 [==============================] - 0s 803us/sample - loss: 0.4124 - f1: 0.9550 - val_loss: 0.5031 - val_f1: 0.9183\n",
      "Epoch 27/2000\n",
      "500/500 [==============================] - 0s 853us/sample - loss: 0.4246 - f1: 0.9609 - val_loss: 0.5349 - val_f1: 0.9082\n",
      "Epoch 28/2000\n",
      "500/500 [==============================] - 0s 798us/sample - loss: 0.4223 - f1: 0.9507 - val_loss: 0.5461 - val_f1: 0.8991\n",
      "Epoch 29/2000\n",
      "500/500 [==============================] - 0s 789us/sample - loss: 0.3890 - f1: 0.9677 - val_loss: 0.5020 - val_f1: 0.9144\n",
      "Epoch 30/2000\n",
      "500/500 [==============================] - 0s 795us/sample - loss: 0.3760 - f1: 0.9679 - val_loss: 0.4971 - val_f1: 0.9112\n",
      "Epoch 31/2000\n",
      "500/500 [==============================] - 0s 793us/sample - loss: 0.3652 - f1: 0.9624 - val_loss: 0.4689 - val_f1: 0.9200\n",
      "Epoch 32/2000\n",
      "500/500 [==============================] - 0s 793us/sample - loss: 0.3434 - f1: 0.9792 - val_loss: 0.4651 - val_f1: 0.9162\n",
      "Epoch 33/2000\n",
      "500/500 [==============================] - 0s 791us/sample - loss: 0.3538 - f1: 0.9762 - val_loss: 0.5581 - val_f1: 0.8914\n",
      "Epoch 34/2000\n",
      "500/500 [==============================] - 0s 792us/sample - loss: 0.4026 - f1: 0.9589 - val_loss: 0.5532 - val_f1: 0.8985\n",
      "Epoch 35/2000\n",
      "500/500 [==============================] - 0s 799us/sample - loss: 0.4142 - f1: 0.9579 - val_loss: 0.5450 - val_f1: 0.8988\n",
      "Epoch 36/2000\n",
      "500/500 [==============================] - 0s 798us/sample - loss: 0.3905 - f1: 0.9732 - val_loss: 0.5192 - val_f1: 0.9118\n",
      "Running through fold 3\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 4.0318 - f1: 0.0038 - val_loss: 3.0534 - val_f1: 0.1100\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 807us/sample - loss: 2.5830 - f1: 0.2838 - val_loss: 2.1357 - val_f1: 0.3466\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 813us/sample - loss: 1.8735 - f1: 0.4927 - val_loss: 1.6707 - val_f1: 0.6253\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 806us/sample - loss: 1.5236 - f1: 0.6976 - val_loss: 1.4373 - val_f1: 0.7055\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 1.2810 - f1: 0.7696 - val_loss: 1.2458 - val_f1: 0.7534\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 1.1424 - f1: 0.7944 - val_loss: 1.1210 - val_f1: 0.7903\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 813us/sample - loss: 1.0163 - f1: 0.8224 - val_loss: 1.0204 - val_f1: 0.8263\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 821us/sample - loss: 0.9177 - f1: 0.8519 - val_loss: 0.9448 - val_f1: 0.8380\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 817us/sample - loss: 0.8475 - f1: 0.8663 - val_loss: 0.8918 - val_f1: 0.8507\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 819us/sample - loss: 0.7955 - f1: 0.8854 - val_loss: 0.8289 - val_f1: 0.8671\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 0s 810us/sample - loss: 0.7611 - f1: 0.8882 - val_loss: 0.8127 - val_f1: 0.8632\n",
      "Epoch 12/2000\n",
      "500/500 [==============================] - 0s 813us/sample - loss: 0.7126 - f1: 0.8892 - val_loss: 0.7612 - val_f1: 0.8875\n",
      "Epoch 13/2000\n",
      "500/500 [==============================] - 0s 814us/sample - loss: 0.6644 - f1: 0.9204 - val_loss: 0.7194 - val_f1: 0.8830\n",
      "Epoch 14/2000\n",
      "500/500 [==============================] - 0s 808us/sample - loss: 0.6442 - f1: 0.9071 - val_loss: 0.7055 - val_f1: 0.8865\n",
      "Epoch 15/2000\n",
      "500/500 [==============================] - 0s 819us/sample - loss: 0.6075 - f1: 0.9326 - val_loss: 0.6936 - val_f1: 0.8796\n",
      "Epoch 16/2000\n",
      "500/500 [==============================] - 0s 815us/sample - loss: 0.6058 - f1: 0.9186 - val_loss: 0.6660 - val_f1: 0.8905\n",
      "Epoch 17/2000\n",
      "500/500 [==============================] - 0s 809us/sample - loss: 0.5748 - f1: 0.9151 - val_loss: 0.6420 - val_f1: 0.8952\n",
      "Epoch 18/2000\n",
      "500/500 [==============================] - 0s 803us/sample - loss: 0.5502 - f1: 0.9309 - val_loss: 0.6321 - val_f1: 0.8959\n",
      "Epoch 19/2000\n",
      "500/500 [==============================] - 0s 816us/sample - loss: 0.5195 - f1: 0.9360 - val_loss: 0.6378 - val_f1: 0.8818\n",
      "Epoch 20/2000\n",
      "500/500 [==============================] - 0s 817us/sample - loss: 0.4970 - f1: 0.9409 - val_loss: 0.5795 - val_f1: 0.9030\n",
      "Epoch 21/2000\n",
      "500/500 [==============================] - 0s 811us/sample - loss: 0.4727 - f1: 0.9465 - val_loss: 0.5694 - val_f1: 0.9061\n",
      "Epoch 22/2000\n",
      "500/500 [==============================] - 0s 810us/sample - loss: 0.4628 - f1: 0.9523 - val_loss: 0.5620 - val_f1: 0.9029\n",
      "Epoch 23/2000\n",
      "500/500 [==============================] - 0s 813us/sample - loss: 0.4482 - f1: 0.9605 - val_loss: 0.5612 - val_f1: 0.8996\n",
      "Epoch 24/2000\n",
      "500/500 [==============================] - 0s 809us/sample - loss: 0.4752 - f1: 0.9423 - val_loss: 0.6233 - val_f1: 0.8904\n",
      "Epoch 25/2000\n",
      "500/500 [==============================] - 0s 814us/sample - loss: 0.5204 - f1: 0.9153 - val_loss: 0.6735 - val_f1: 0.8685\n",
      "Epoch 26/2000\n",
      "500/500 [==============================] - 0s 811us/sample - loss: 0.5010 - f1: 0.9398 - val_loss: 0.6078 - val_f1: 0.8964\n",
      "Epoch 27/2000\n",
      "500/500 [==============================] - 0s 809us/sample - loss: 0.4523 - f1: 0.9448 - val_loss: 0.5536 - val_f1: 0.9011\n",
      "Epoch 28/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 0.4228 - f1: 0.9511 - val_loss: 0.5241 - val_f1: 0.9046\n",
      "Epoch 29/2000\n",
      "500/500 [==============================] - 0s 815us/sample - loss: 0.3956 - f1: 0.9585 - val_loss: 0.5454 - val_f1: 0.8945\n",
      "Epoch 30/2000\n",
      "500/500 [==============================] - 0s 819us/sample - loss: 0.3846 - f1: 0.9566 - val_loss: 0.5038 - val_f1: 0.9017\n",
      "Running through fold 4\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 4.0181 - f1: 0.0284 - val_loss: 2.9889 - val_f1: 0.1771\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 2.5528 - f1: 0.3043 - val_loss: 2.1268 - val_f1: 0.3813\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 822us/sample - loss: 1.9050 - f1: 0.4782 - val_loss: 1.6829 - val_f1: 0.6336\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 822us/sample - loss: 1.5148 - f1: 0.6801 - val_loss: 1.4510 - val_f1: 0.7120\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 816us/sample - loss: 1.2909 - f1: 0.7449 - val_loss: 1.2449 - val_f1: 0.7660\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 820us/sample - loss: 1.1269 - f1: 0.8156 - val_loss: 1.1380 - val_f1: 0.7969\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 822us/sample - loss: 1.0073 - f1: 0.8451 - val_loss: 1.0287 - val_f1: 0.8183\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 814us/sample - loss: 0.9065 - f1: 0.8688 - val_loss: 0.9635 - val_f1: 0.8484\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 831us/sample - loss: 0.8244 - f1: 0.8952 - val_loss: 0.8897 - val_f1: 0.8629\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 0.7617 - f1: 0.9019 - val_loss: 0.8312 - val_f1: 0.8691\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 0s 816us/sample - loss: 0.7346 - f1: 0.9016 - val_loss: 0.7984 - val_f1: 0.8748\n",
      "Epoch 12/2000\n",
      "500/500 [==============================] - 0s 815us/sample - loss: 0.6754 - f1: 0.9245 - val_loss: 0.7744 - val_f1: 0.8703\n",
      "Epoch 13/2000\n",
      "500/500 [==============================] - 0s 817us/sample - loss: 0.6482 - f1: 0.9152 - val_loss: 0.7558 - val_f1: 0.8738\n",
      "Epoch 14/2000\n",
      "500/500 [==============================] - 0s 810us/sample - loss: 0.6192 - f1: 0.9269 - val_loss: 0.7528 - val_f1: 0.8750\n",
      "Epoch 15/2000\n",
      "500/500 [==============================] - 0s 815us/sample - loss: 0.5895 - f1: 0.9380 - val_loss: 0.7125 - val_f1: 0.8845\n",
      "Epoch 16/2000\n",
      "500/500 [==============================] - 0s 814us/sample - loss: 0.5564 - f1: 0.9503 - val_loss: 0.6999 - val_f1: 0.8807\n",
      "Epoch 17/2000\n",
      "500/500 [==============================] - 0s 817us/sample - loss: 0.5267 - f1: 0.9472 - val_loss: 0.6397 - val_f1: 0.8935\n",
      "Epoch 18/2000\n",
      "500/500 [==============================] - 0s 810us/sample - loss: 0.5057 - f1: 0.9514 - val_loss: 0.6301 - val_f1: 0.8902\n",
      "Epoch 19/2000\n",
      "500/500 [==============================] - 0s 818us/sample - loss: 0.4874 - f1: 0.9568 - val_loss: 0.6020 - val_f1: 0.8953\n",
      "Epoch 20/2000\n",
      "500/500 [==============================] - 0s 820us/sample - loss: 0.4660 - f1: 0.9562 - val_loss: 0.6269 - val_f1: 0.8840\n",
      "Epoch 21/2000\n",
      "500/500 [==============================] - 0s 819us/sample - loss: 0.4845 - f1: 0.9402 - val_loss: 0.6519 - val_f1: 0.8749\n",
      "Epoch 22/2000\n",
      "500/500 [==============================] - 0s 820us/sample - loss: 0.4672 - f1: 0.9538 - val_loss: 0.5974 - val_f1: 0.8933\n",
      "Epoch 23/2000\n",
      "500/500 [==============================] - 0s 824us/sample - loss: 0.4337 - f1: 0.9578 - val_loss: 0.5818 - val_f1: 0.8952\n",
      "Epoch 24/2000\n",
      "500/500 [==============================] - 0s 824us/sample - loss: 0.4139 - f1: 0.9671 - val_loss: 0.5609 - val_f1: 0.8958\n",
      "Epoch 25/2000\n",
      "500/500 [==============================] - 0s 814us/sample - loss: 0.4010 - f1: 0.9721 - val_loss: 0.5360 - val_f1: 0.9005\n",
      "Epoch 26/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 811us/sample - loss: 0.3921 - f1: 0.9590 - val_loss: 0.5535 - val_f1: 0.8912\n",
      "Epoch 27/2000\n",
      "500/500 [==============================] - 0s 823us/sample - loss: 0.3839 - f1: 0.9722 - val_loss: 0.5379 - val_f1: 0.8996\n",
      "\n",
      "\n",
      "Running through training size 1000\n",
      "Running through fold 0\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 3.4095 - f1: 0.1271 - val_loss: 2.1704 - val_f1: 0.3188\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 1.7750 - f1: 0.5711 - val_loss: 1.4192 - val_f1: 0.7081\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 514us/sample - loss: 1.2537 - f1: 0.7511 - val_loss: 1.0964 - val_f1: 0.7958\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 507us/sample - loss: 1.0305 - f1: 0.8313 - val_loss: 0.9709 - val_f1: 0.8263\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 506us/sample - loss: 0.8959 - f1: 0.8617 - val_loss: 0.8367 - val_f1: 0.8727\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 502us/sample - loss: 0.7976 - f1: 0.8752 - val_loss: 0.7765 - val_f1: 0.8750\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 502us/sample - loss: 0.7158 - f1: 0.8958 - val_loss: 0.7410 - val_f1: 0.8868\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 0s 495us/sample - loss: 0.6555 - f1: 0.9049 - val_loss: 0.6462 - val_f1: 0.9022\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 0s 495us/sample - loss: 0.6409 - f1: 0.8967 - val_loss: 0.6461 - val_f1: 0.8986\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 576us/sample - loss: 0.5785 - f1: 0.9163 - val_loss: 0.5797 - val_f1: 0.9097\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 0s 495us/sample - loss: 0.5448 - f1: 0.9200 - val_loss: 0.5634 - val_f1: 0.9007\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 0s 493us/sample - loss: 0.5349 - f1: 0.9161 - val_loss: 0.5783 - val_f1: 0.8900\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 0s 497us/sample - loss: 0.5025 - f1: 0.9365 - val_loss: 0.4948 - val_f1: 0.9207\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 0s 493us/sample - loss: 0.4673 - f1: 0.9353 - val_loss: 0.4930 - val_f1: 0.9233\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 0s 495us/sample - loss: 0.4454 - f1: 0.9363 - val_loss: 0.4602 - val_f1: 0.9343\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 0s 493us/sample - loss: 0.4168 - f1: 0.9468 - val_loss: 0.4276 - val_f1: 0.9349\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 0s 493us/sample - loss: 0.3966 - f1: 0.9517 - val_loss: 0.4385 - val_f1: 0.9363\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 0s 494us/sample - loss: 0.3858 - f1: 0.9498 - val_loss: 0.4513 - val_f1: 0.9175\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 508us/sample - loss: 0.4000 - f1: 0.9419 - val_loss: 0.4203 - val_f1: 0.9335\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 0s 499us/sample - loss: 0.3740 - f1: 0.9529 - val_loss: 0.4545 - val_f1: 0.9203\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 0s 491us/sample - loss: 0.4103 - f1: 0.9489 - val_loss: 0.4376 - val_f1: 0.9302\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 0s 492us/sample - loss: 0.3915 - f1: 0.9458 - val_loss: 0.4064 - val_f1: 0.9350\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 0s 493us/sample - loss: 0.4588 - f1: 0.9361 - val_loss: 0.4661 - val_f1: 0.9292\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 0s 493us/sample - loss: 0.4171 - f1: 0.9469 - val_loss: 0.4412 - val_f1: 0.9238\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 0s 497us/sample - loss: 0.3954 - f1: 0.9442 - val_loss: 0.3915 - val_f1: 0.9433\n",
      "Running through fold 1\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 3.4018 - f1: 0.1121 - val_loss: 2.2175 - val_f1: 0.3048\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 1.7577 - f1: 0.5453 - val_loss: 1.4354 - val_f1: 0.7101\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 1.2513 - f1: 0.7784 - val_loss: 1.1270 - val_f1: 0.7973\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.9982 - f1: 0.8472 - val_loss: 0.9491 - val_f1: 0.8526\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.8453 - f1: 0.8853 - val_loss: 0.8441 - val_f1: 0.8672\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.7639 - f1: 0.8925 - val_loss: 0.7611 - val_f1: 0.8828\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 513us/sample - loss: 0.7222 - f1: 0.8869 - val_loss: 0.7326 - val_f1: 0.8812\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 508us/sample - loss: 0.6676 - f1: 0.9098 - val_loss: 0.7338 - val_f1: 0.8710\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 508us/sample - loss: 0.6269 - f1: 0.9039 - val_loss: 0.6448 - val_f1: 0.8896\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 510us/sample - loss: 0.5525 - f1: 0.9164 - val_loss: 0.5805 - val_f1: 0.9008\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 508us/sample - loss: 0.5082 - f1: 0.9334 - val_loss: 0.5484 - val_f1: 0.9085\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 508us/sample - loss: 0.4917 - f1: 0.9282 - val_loss: 0.5564 - val_f1: 0.8966\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 509us/sample - loss: 0.4662 - f1: 0.9284 - val_loss: 0.5188 - val_f1: 0.9057\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 513us/sample - loss: 0.4727 - f1: 0.9336 - val_loss: 0.5181 - val_f1: 0.9117\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 511us/sample - loss: 0.4518 - f1: 0.9387 - val_loss: 0.4838 - val_f1: 0.9167\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 510us/sample - loss: 0.4355 - f1: 0.9383 - val_loss: 0.4944 - val_f1: 0.9070\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 509us/sample - loss: 0.4087 - f1: 0.9508 - val_loss: 0.4572 - val_f1: 0.9220\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 510us/sample - loss: 0.3646 - f1: 0.9631 - val_loss: 0.4257 - val_f1: 0.9237\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 511us/sample - loss: 0.3769 - f1: 0.9514 - val_loss: 0.4170 - val_f1: 0.9278\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 510us/sample - loss: 0.3682 - f1: 0.9561 - val_loss: 0.4386 - val_f1: 0.9209\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 509us/sample - loss: 0.3644 - f1: 0.9551 - val_loss: 0.4105 - val_f1: 0.9346\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 508us/sample - loss: 0.3202 - f1: 0.9685 - val_loss: 0.4081 - val_f1: 0.9196\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 505us/sample - loss: 0.3452 - f1: 0.9503 - val_loss: 0.4354 - val_f1: 0.9182\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 505us/sample - loss: 0.3655 - f1: 0.9501 - val_loss: 0.4607 - val_f1: 0.9103\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 504us/sample - loss: 0.3621 - f1: 0.9557 - val_loss: 0.4084 - val_f1: 0.9261\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 501us/sample - loss: 0.3526 - f1: 0.9596 - val_loss: 0.4458 - val_f1: 0.9156\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 1s 503us/sample - loss: 0.3358 - f1: 0.9620 - val_loss: 0.4263 - val_f1: 0.9185\n",
      "Epoch 28/2000\n",
      "1000/1000 [==============================] - 1s 504us/sample - loss: 0.3166 - f1: 0.9618 - val_loss: 0.3679 - val_f1: 0.9341\n",
      "Epoch 29/2000\n",
      "1000/1000 [==============================] - 1s 502us/sample - loss: 0.2802 - f1: 0.9702 - val_loss: 0.3769 - val_f1: 0.9224\n",
      "Epoch 30/2000\n",
      "1000/1000 [==============================] - 1s 503us/sample - loss: 0.2671 - f1: 0.9717 - val_loss: 0.3696 - val_f1: 0.9234\n",
      "Epoch 31/2000\n",
      "1000/1000 [==============================] - 1s 503us/sample - loss: 0.3060 - f1: 0.9557 - val_loss: 0.4092 - val_f1: 0.9281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running through fold 2\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 3.3443 - f1: 0.1422 - val_loss: 2.1331 - val_f1: 0.3792\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.7656 - f1: 0.5380 - val_loss: 1.4444 - val_f1: 0.6920\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 1.2608 - f1: 0.7806 - val_loss: 1.1291 - val_f1: 0.8062\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 1.0122 - f1: 0.8579 - val_loss: 0.9486 - val_f1: 0.8578\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.8541 - f1: 0.8955 - val_loss: 0.8329 - val_f1: 0.8846\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.7734 - f1: 0.9017 - val_loss: 0.7441 - val_f1: 0.8987\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.6754 - f1: 0.9250 - val_loss: 0.6994 - val_f1: 0.8955\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.6703 - f1: 0.9050 - val_loss: 0.6990 - val_f1: 0.8854\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.6228 - f1: 0.9182 - val_loss: 0.6418 - val_f1: 0.9002\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.5749 - f1: 0.9245 - val_loss: 0.5948 - val_f1: 0.9067\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.5161 - f1: 0.9406 - val_loss: 0.5421 - val_f1: 0.9116\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.4855 - f1: 0.9400 - val_loss: 0.5381 - val_f1: 0.9038\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.4652 - f1: 0.9406 - val_loss: 0.5158 - val_f1: 0.9090\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.4511 - f1: 0.9416 - val_loss: 0.4832 - val_f1: 0.9198\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 515us/sample - loss: 0.4345 - f1: 0.9443 - val_loss: 0.5255 - val_f1: 0.9030\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 514us/sample - loss: 0.4254 - f1: 0.9483 - val_loss: 0.5062 - val_f1: 0.9058\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.4197 - f1: 0.9409 - val_loss: 0.4556 - val_f1: 0.9201\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 581us/sample - loss: 0.3855 - f1: 0.9518 - val_loss: 0.4405 - val_f1: 0.9246\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 512us/sample - loss: 0.3923 - f1: 0.9398 - val_loss: 0.4332 - val_f1: 0.9228\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 512us/sample - loss: 0.3626 - f1: 0.9587 - val_loss: 0.4251 - val_f1: 0.9175\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 515us/sample - loss: 0.3557 - f1: 0.9532 - val_loss: 0.4558 - val_f1: 0.9141\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 512us/sample - loss: 0.3830 - f1: 0.9494 - val_loss: 0.4282 - val_f1: 0.9265\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 510us/sample - loss: 0.3494 - f1: 0.9570 - val_loss: 0.4457 - val_f1: 0.9217\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.3418 - f1: 0.9605 - val_loss: 0.3939 - val_f1: 0.9266\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 512us/sample - loss: 0.3145 - f1: 0.9598 - val_loss: 0.3661 - val_f1: 0.9334\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 503us/sample - loss: 0.2964 - f1: 0.9659 - val_loss: 0.3650 - val_f1: 0.9316\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 1s 506us/sample - loss: 0.3143 - f1: 0.9628 - val_loss: 0.3723 - val_f1: 0.9321\n",
      "Epoch 28/2000\n",
      "1000/1000 [==============================] - 1s 505us/sample - loss: 0.3042 - f1: 0.9609 - val_loss: 0.3449 - val_f1: 0.9399\n",
      "Epoch 29/2000\n",
      "1000/1000 [==============================] - 1s 502us/sample - loss: 0.2784 - f1: 0.9701 - val_loss: 0.3531 - val_f1: 0.9295\n",
      "Epoch 30/2000\n",
      "1000/1000 [==============================] - 1s 502us/sample - loss: 0.2886 - f1: 0.9611 - val_loss: 0.3452 - val_f1: 0.9363\n",
      "Epoch 31/2000\n",
      "1000/1000 [==============================] - 1s 504us/sample - loss: 0.2837 - f1: 0.9671 - val_loss: 0.3448 - val_f1: 0.9365\n",
      "Epoch 32/2000\n",
      "1000/1000 [==============================] - 1s 503us/sample - loss: 0.3318 - f1: 0.9545 - val_loss: 0.4463 - val_f1: 0.9177\n",
      "Epoch 33/2000\n",
      "1000/1000 [==============================] - 1s 504us/sample - loss: 0.3755 - f1: 0.9458 - val_loss: 0.4093 - val_f1: 0.9349\n",
      "Epoch 34/2000\n",
      "1000/1000 [==============================] - 1s 503us/sample - loss: 0.3204 - f1: 0.9729 - val_loss: 0.3723 - val_f1: 0.9346\n",
      "Epoch 35/2000\n",
      "1000/1000 [==============================] - 1s 504us/sample - loss: 0.2717 - f1: 0.9729 - val_loss: 0.3437 - val_f1: 0.9331\n",
      "Epoch 36/2000\n",
      "1000/1000 [==============================] - 1s 507us/sample - loss: 0.2845 - f1: 0.9620 - val_loss: 0.3673 - val_f1: 0.9244\n",
      "Epoch 37/2000\n",
      "1000/1000 [==============================] - 1s 505us/sample - loss: 0.2778 - f1: 0.9716 - val_loss: 0.3808 - val_f1: 0.9269\n",
      "Epoch 38/2000\n",
      "1000/1000 [==============================] - 1s 507us/sample - loss: 0.2831 - f1: 0.9633 - val_loss: 0.3939 - val_f1: 0.9191\n",
      "Running through fold 3\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 3.3013 - f1: 0.1277 - val_loss: 2.1880 - val_f1: 0.3522\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 1.7739 - f1: 0.5461 - val_loss: 1.4438 - val_f1: 0.6985\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 515us/sample - loss: 1.2672 - f1: 0.7559 - val_loss: 1.1358 - val_f1: 0.7886\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 1.0056 - f1: 0.8301 - val_loss: 0.9774 - val_f1: 0.8436\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.8835 - f1: 0.8685 - val_loss: 0.8576 - val_f1: 0.8664\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.7863 - f1: 0.8871 - val_loss: 0.7992 - val_f1: 0.8728\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 516us/sample - loss: 0.7021 - f1: 0.9143 - val_loss: 0.7100 - val_f1: 0.9000\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 513us/sample - loss: 0.6415 - f1: 0.9156 - val_loss: 0.6632 - val_f1: 0.9023\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 515us/sample - loss: 0.5876 - f1: 0.9137 - val_loss: 0.5959 - val_f1: 0.9151\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 514us/sample - loss: 0.5519 - f1: 0.9254 - val_loss: 0.5859 - val_f1: 0.9062\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.5200 - f1: 0.9301 - val_loss: 0.5539 - val_f1: 0.9136\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 516us/sample - loss: 0.5000 - f1: 0.9296 - val_loss: 0.5555 - val_f1: 0.9097\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 514us/sample - loss: 0.4745 - f1: 0.9460 - val_loss: 0.5044 - val_f1: 0.9209\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 515us/sample - loss: 0.4354 - f1: 0.9498 - val_loss: 0.5010 - val_f1: 0.9202\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.5348 - f1: 0.9196 - val_loss: 0.5740 - val_f1: 0.9115\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.4896 - f1: 0.9333 - val_loss: 0.4903 - val_f1: 0.9335\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 512us/sample - loss: 0.4265 - f1: 0.9492 - val_loss: 0.4648 - val_f1: 0.9276\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 512us/sample - loss: 0.4056 - f1: 0.9399 - val_loss: 0.4778 - val_f1: 0.9127\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.4156 - f1: 0.9365 - val_loss: 0.4469 - val_f1: 0.9270\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.3763 - f1: 0.9478 - val_loss: 0.4277 - val_f1: 0.9317\n",
      "Epoch 21/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 511us/sample - loss: 0.3667 - f1: 0.9517 - val_loss: 0.4167 - val_f1: 0.9352\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 514us/sample - loss: 0.3350 - f1: 0.9673 - val_loss: 0.3829 - val_f1: 0.9403\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 516us/sample - loss: 0.3097 - f1: 0.9721 - val_loss: 0.3789 - val_f1: 0.9350\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 514us/sample - loss: 0.3271 - f1: 0.9597 - val_loss: 0.3998 - val_f1: 0.9252\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 516us/sample - loss: 0.3432 - f1: 0.9552 - val_loss: 0.4024 - val_f1: 0.9331\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.3213 - f1: 0.9652 - val_loss: 0.3771 - val_f1: 0.9336\n",
      "Running through fold 4\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 3.3078 - f1: 0.1284 - val_loss: 2.1502 - val_f1: 0.3513\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 549us/sample - loss: 1.7427 - f1: 0.5560 - val_loss: 1.4023 - val_f1: 0.6887\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.2392 - f1: 0.7656 - val_loss: 1.1037 - val_f1: 0.7976\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.0030 - f1: 0.8457 - val_loss: 0.9276 - val_f1: 0.8566\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 0.8574 - f1: 0.8809 - val_loss: 0.8423 - val_f1: 0.8676\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.7692 - f1: 0.8924 - val_loss: 0.7684 - val_f1: 0.8845\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.7129 - f1: 0.8953 - val_loss: 0.7440 - val_f1: 0.8821\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.6700 - f1: 0.9041 - val_loss: 0.6838 - val_f1: 0.8891\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.6171 - f1: 0.9251 - val_loss: 0.6249 - val_f1: 0.8965\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.5627 - f1: 0.9279 - val_loss: 0.5788 - val_f1: 0.9054\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 521us/sample - loss: 0.5341 - f1: 0.9249 - val_loss: 0.5532 - val_f1: 0.9060\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.4933 - f1: 0.9289 - val_loss: 0.5086 - val_f1: 0.9112\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.4684 - f1: 0.9362 - val_loss: 0.5083 - val_f1: 0.9039\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.4542 - f1: 0.9322 - val_loss: 0.5431 - val_f1: 0.8960\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.4532 - f1: 0.9357 - val_loss: 0.4898 - val_f1: 0.9081\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.4239 - f1: 0.9413 - val_loss: 0.4721 - val_f1: 0.9100\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.4158 - f1: 0.9419 - val_loss: 0.4607 - val_f1: 0.9160\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 587us/sample - loss: 0.4190 - f1: 0.9455 - val_loss: 0.4734 - val_f1: 0.9202\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 521us/sample - loss: 0.4135 - f1: 0.9444 - val_loss: 0.4407 - val_f1: 0.9170\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 521us/sample - loss: 0.4234 - f1: 0.9446 - val_loss: 0.4418 - val_f1: 0.9262\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.4140 - f1: 0.9365 - val_loss: 0.4341 - val_f1: 0.9281\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.4127 - f1: 0.9406 - val_loss: 0.4459 - val_f1: 0.9216\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.3724 - f1: 0.9554 - val_loss: 0.4083 - val_f1: 0.9232\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.3788 - f1: 0.9364 - val_loss: 0.4539 - val_f1: 0.9095\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.3773 - f1: 0.9465 - val_loss: 0.4274 - val_f1: 0.9187\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.3451 - f1: 0.9543 - val_loss: 0.3755 - val_f1: 0.9344\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.3193 - f1: 0.9559 - val_loss: 0.3550 - val_f1: 0.9394\n",
      "Epoch 28/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.3054 - f1: 0.9666 - val_loss: 0.3375 - val_f1: 0.9409\n",
      "Epoch 29/2000\n",
      "1000/1000 [==============================] - 1s 514us/sample - loss: 0.3327 - f1: 0.9467 - val_loss: 0.3850 - val_f1: 0.9328\n",
      "Epoch 30/2000\n",
      "1000/1000 [==============================] - 1s 515us/sample - loss: 0.3252 - f1: 0.9542 - val_loss: 0.3951 - val_f1: 0.9270\n",
      "Epoch 31/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.3042 - f1: 0.9605 - val_loss: 0.3683 - val_f1: 0.9304\n",
      "Epoch 32/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.2822 - f1: 0.9677 - val_loss: 0.3340 - val_f1: 0.9371\n",
      "Epoch 33/2000\n",
      "1000/1000 [==============================] - 1s 515us/sample - loss: 0.2781 - f1: 0.9664 - val_loss: 0.3563 - val_f1: 0.9249\n",
      "Epoch 34/2000\n",
      "1000/1000 [==============================] - 1s 515us/sample - loss: 0.2805 - f1: 0.9669 - val_loss: 0.3904 - val_f1: 0.9201\n",
      "Epoch 35/2000\n",
      "1000/1000 [==============================] - 1s 514us/sample - loss: 0.2903 - f1: 0.9638 - val_loss: 0.3801 - val_f1: 0.9268\n",
      "Epoch 36/2000\n",
      "1000/1000 [==============================] - 1s 516us/sample - loss: 0.2933 - f1: 0.9629 - val_loss: 0.3466 - val_f1: 0.9346\n",
      "Epoch 37/2000\n",
      "1000/1000 [==============================] - 1s 516us/sample - loss: 0.2617 - f1: 0.9709 - val_loss: 0.3331 - val_f1: 0.9385\n",
      "\n",
      "\n",
      "Running through training size 5000\n",
      "Running through fold 0\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 3s 647us/sample - loss: 1.6857 - f1: 0.6115 - val_loss: 0.8532 - val_f1: 0.8754\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 300us/sample - loss: 0.7074 - f1: 0.8898 - val_loss: 0.5694 - val_f1: 0.9199\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.5368 - f1: 0.9117 - val_loss: 0.4768 - val_f1: 0.9158\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 1s 300us/sample - loss: 0.4564 - f1: 0.9243 - val_loss: 0.4236 - val_f1: 0.9235\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 1s 300us/sample - loss: 0.3920 - f1: 0.9366 - val_loss: 0.3759 - val_f1: 0.9408\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.3688 - f1: 0.9402 - val_loss: 0.3745 - val_f1: 0.9308\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.3359 - f1: 0.9451 - val_loss: 0.3136 - val_f1: 0.9487\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.3522 - f1: 0.9398 - val_loss: 0.3395 - val_f1: 0.9436\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.3044 - f1: 0.9505 - val_loss: 0.2898 - val_f1: 0.9487\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 1s 300us/sample - loss: 0.2983 - f1: 0.9504 - val_loss: 0.2848 - val_f1: 0.9567\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.2842 - f1: 0.9539 - val_loss: 0.2573 - val_f1: 0.9574\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.2675 - f1: 0.9571 - val_loss: 0.2918 - val_f1: 0.9475\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.2809 - f1: 0.9547 - val_loss: 0.2443 - val_f1: 0.9582\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.2620 - f1: 0.9569 - val_loss: 0.2820 - val_f1: 0.9542\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.2637 - f1: 0.9594 - val_loss: 0.2437 - val_f1: 0.9606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.2555 - f1: 0.9576 - val_loss: 0.2894 - val_f1: 0.9557\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.2577 - f1: 0.9599 - val_loss: 0.2681 - val_f1: 0.9583\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.2346 - f1: 0.9653 - val_loss: 0.2473 - val_f1: 0.9568\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.2248 - f1: 0.9680 - val_loss: 0.2143 - val_f1: 0.9594\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 1s 300us/sample - loss: 0.2577 - f1: 0.9611 - val_loss: 0.2235 - val_f1: 0.9707\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.2099 - f1: 0.9701 - val_loss: 0.2284 - val_f1: 0.9655\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 1s 297us/sample - loss: 0.2545 - f1: 0.9684 - val_loss: 0.2567 - val_f1: 0.9725\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.2069 - f1: 0.9773 - val_loss: 0.2497 - val_f1: 0.9586\n",
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.1874 - f1: 0.9817 - val_loss: 0.2200 - val_f1: 0.9791\n",
      "Epoch 25/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.2535 - f1: 0.9689 - val_loss: 0.3732 - val_f1: 0.9352\n",
      "Epoch 26/2000\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.2371 - f1: 0.9743 - val_loss: 0.1804 - val_f1: 0.9752\n",
      "Epoch 27/2000\n",
      "5000/5000 [==============================] - 1s 299us/sample - loss: 0.1627 - f1: 0.9844 - val_loss: 0.1558 - val_f1: 0.9841\n",
      "Epoch 28/2000\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.1630 - f1: 0.9866 - val_loss: 0.2060 - val_f1: 0.9826\n",
      "Epoch 29/2000\n",
      "5000/5000 [==============================] - 1s 297us/sample - loss: 0.1810 - f1: 0.9856 - val_loss: 0.1415 - val_f1: 0.9923\n",
      "Epoch 30/2000\n",
      "5000/5000 [==============================] - 1s 298us/sample - loss: 0.1501 - f1: 0.9877 - val_loss: 0.2029 - val_f1: 0.9695\n",
      "Epoch 31/2000\n",
      "5000/5000 [==============================] - 1s 297us/sample - loss: 0.1489 - f1: 0.9882 - val_loss: 0.1850 - val_f1: 0.9779\n",
      "Epoch 32/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.1816 - f1: 0.9870 - val_loss: 0.1784 - val_f1: 0.9891\n",
      "Epoch 33/2000\n",
      "5000/5000 [==============================] - 1s 295us/sample - loss: 0.1415 - f1: 0.9909 - val_loss: 0.1384 - val_f1: 0.9920\n",
      "Epoch 34/2000\n",
      "5000/5000 [==============================] - 1s 295us/sample - loss: 0.1225 - f1: 0.9943 - val_loss: 0.1383 - val_f1: 0.9918\n",
      "Epoch 35/2000\n",
      "5000/5000 [==============================] - 1s 294us/sample - loss: 0.2630 - f1: 0.9725 - val_loss: 0.3116 - val_f1: 0.9682\n",
      "Epoch 36/2000\n",
      "5000/5000 [==============================] - 1s 296us/sample - loss: 0.2929 - f1: 0.9793 - val_loss: 0.1837 - val_f1: 0.9855\n",
      "Epoch 37/2000\n",
      "5000/5000 [==============================] - 1s 297us/sample - loss: 0.1849 - f1: 0.9886 - val_loss: 0.1519 - val_f1: 0.9895\n",
      "Running through fold 1\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 3s 653us/sample - loss: 1.7086 - f1: 0.6181 - val_loss: 0.8531 - val_f1: 0.8867\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.7165 - f1: 0.8863 - val_loss: 0.6081 - val_f1: 0.8898\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.5521 - f1: 0.9056 - val_loss: 0.4660 - val_f1: 0.9221\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.4604 - f1: 0.9200 - val_loss: 0.3898 - val_f1: 0.9322\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.4149 - f1: 0.9282 - val_loss: 0.3867 - val_f1: 0.9356\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.3775 - f1: 0.9355 - val_loss: 0.4044 - val_f1: 0.9276\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.3762 - f1: 0.9362 - val_loss: 0.3622 - val_f1: 0.9236\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.3346 - f1: 0.9420 - val_loss: 0.3352 - val_f1: 0.9413\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.3248 - f1: 0.9413 - val_loss: 0.3846 - val_f1: 0.9353\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.3033 - f1: 0.9506 - val_loss: 0.2743 - val_f1: 0.9554\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.2759 - f1: 0.9524 - val_loss: 0.2900 - val_f1: 0.9432\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.2981 - f1: 0.9496 - val_loss: 0.3295 - val_f1: 0.9352\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.3050 - f1: 0.9460 - val_loss: 0.2998 - val_f1: 0.9437\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 302us/sample - loss: 0.2468 - f1: 0.9574 - val_loss: 0.2941 - val_f1: 0.9361\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 302us/sample - loss: 0.3149 - f1: 0.9464 - val_loss: 0.2636 - val_f1: 0.9554\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.2593 - f1: 0.9567 - val_loss: 0.3075 - val_f1: 0.9423\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.2674 - f1: 0.9574 - val_loss: 0.2698 - val_f1: 0.9542\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.2399 - f1: 0.9612 - val_loss: 0.2032 - val_f1: 0.9641\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.2208 - f1: 0.9616 - val_loss: 0.2838 - val_f1: 0.9586\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 1s 300us/sample - loss: 0.2972 - f1: 0.9576 - val_loss: 0.2205 - val_f1: 0.9592\n",
      "Running through fold 2\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 3s 667us/sample - loss: 1.6978 - f1: 0.6127 - val_loss: 0.8556 - val_f1: 0.8636\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.6887 - f1: 0.8987 - val_loss: 0.5701 - val_f1: 0.9174\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.5031 - f1: 0.9240 - val_loss: 0.4464 - val_f1: 0.9348\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.4260 - f1: 0.9359 - val_loss: 0.3930 - val_f1: 0.9370\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.3922 - f1: 0.9395 - val_loss: 0.3651 - val_f1: 0.9419\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.3586 - f1: 0.9423 - val_loss: 0.3475 - val_f1: 0.9460\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.3501 - f1: 0.9472 - val_loss: 0.3102 - val_f1: 0.9520\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.3323 - f1: 0.9446 - val_loss: 0.3253 - val_f1: 0.9436\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2906 - f1: 0.9540 - val_loss: 0.3161 - val_f1: 0.9423\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.3067 - f1: 0.9548 - val_loss: 0.3111 - val_f1: 0.9366\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.2715 - f1: 0.9553 - val_loss: 0.2912 - val_f1: 0.9530\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.2682 - f1: 0.9597 - val_loss: 0.3046 - val_f1: 0.9407\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2611 - f1: 0.9568 - val_loss: 0.2700 - val_f1: 0.9481\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2604 - f1: 0.9581 - val_loss: 0.3057 - val_f1: 0.9429\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.3058 - f1: 0.9545 - val_loss: 0.3091 - val_f1: 0.9466\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2336 - f1: 0.9661 - val_loss: 0.2970 - val_f1: 0.9514\n",
      "Running through fold 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 3s 692us/sample - loss: 1.7001 - f1: 0.6112 - val_loss: 0.8331 - val_f1: 0.8728\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.7033 - f1: 0.8912 - val_loss: 0.5999 - val_f1: 0.9100\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.5427 - f1: 0.9099 - val_loss: 0.4692 - val_f1: 0.9223\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.4472 - f1: 0.9286 - val_loss: 0.4425 - val_f1: 0.9248\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.4007 - f1: 0.9373 - val_loss: 0.4545 - val_f1: 0.9217\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.3582 - f1: 0.9445 - val_loss: 0.3347 - val_f1: 0.9421\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.3186 - f1: 0.9523 - val_loss: 0.3163 - val_f1: 0.9479\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3266 - f1: 0.9446 - val_loss: 0.4821 - val_f1: 0.9198\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.3320 - f1: 0.9496 - val_loss: 0.2855 - val_f1: 0.9559\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.2825 - f1: 0.9537 - val_loss: 0.2830 - val_f1: 0.9573\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.2789 - f1: 0.9572 - val_loss: 0.2757 - val_f1: 0.9489\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.2616 - f1: 0.9591 - val_loss: 0.2445 - val_f1: 0.9593\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.2583 - f1: 0.9597 - val_loss: 0.3094 - val_f1: 0.9466\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2426 - f1: 0.9631 - val_loss: 0.2555 - val_f1: 0.9630\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.2493 - f1: 0.9630 - val_loss: 0.2190 - val_f1: 0.9669\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.2578 - f1: 0.9591 - val_loss: 0.4452 - val_f1: 0.9275\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.3096 - f1: 0.9608 - val_loss: 0.2015 - val_f1: 0.9711\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.1972 - f1: 0.9721 - val_loss: 0.2370 - val_f1: 0.9598\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2457 - f1: 0.9670 - val_loss: 0.2422 - val_f1: 0.9620\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2190 - f1: 0.9706 - val_loss: 0.1921 - val_f1: 0.9768\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.1802 - f1: 0.9820 - val_loss: 0.2131 - val_f1: 0.9762\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.1944 - f1: 0.9803 - val_loss: 0.1667 - val_f1: 0.9817\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.2156 - f1: 0.9791 - val_loss: 0.2212 - val_f1: 0.9810\n",
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1966 - f1: 0.9832 - val_loss: 0.1711 - val_f1: 0.9911\n",
      "Epoch 25/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1899 - f1: 0.9825 - val_loss: 0.1664 - val_f1: 0.9904\n",
      "Epoch 26/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1662 - f1: 0.9883 - val_loss: 0.1369 - val_f1: 0.9922\n",
      "Epoch 27/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1618 - f1: 0.9870 - val_loss: 0.1889 - val_f1: 0.9821\n",
      "Epoch 28/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.1938 - f1: 0.9845 - val_loss: 0.2050 - val_f1: 0.9890\n",
      "Epoch 29/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1889 - f1: 0.9900 - val_loss: 0.1287 - val_f1: 0.9945\n",
      "Epoch 30/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1202 - f1: 0.9960 - val_loss: 0.1308 - val_f1: 0.9938\n",
      "Epoch 31/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1718 - f1: 0.9882 - val_loss: 0.1869 - val_f1: 0.9901\n",
      "Epoch 32/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2249 - f1: 0.9838 - val_loss: 0.1749 - val_f1: 0.9920\n",
      "Epoch 33/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.1320 - f1: 0.9949 - val_loss: 0.1171 - val_f1: 0.9908\n",
      "Epoch 34/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1553 - f1: 0.9913 - val_loss: 0.1381 - val_f1: 0.9948\n",
      "Epoch 35/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1135 - f1: 0.9962 - val_loss: 0.0956 - val_f1: 0.9972\n",
      "Epoch 36/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.0959 - f1: 0.9974 - val_loss: 0.0989 - val_f1: 0.9960\n",
      "Running through fold 4\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 3s 697us/sample - loss: 1.6912 - f1: 0.6089 - val_loss: 0.8299 - val_f1: 0.8758\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.7041 - f1: 0.8896 - val_loss: 0.5981 - val_f1: 0.9032\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.5450 - f1: 0.9107 - val_loss: 0.4915 - val_f1: 0.9250\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.4451 - f1: 0.9288 - val_loss: 0.4154 - val_f1: 0.9378\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.4043 - f1: 0.9283 - val_loss: 0.4218 - val_f1: 0.9268\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.3492 - f1: 0.9435 - val_loss: 0.3471 - val_f1: 0.9444\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 319us/sample - loss: 0.3568 - f1: 0.9389 - val_loss: 0.3962 - val_f1: 0.9254\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.3201 - f1: 0.9460 - val_loss: 0.3433 - val_f1: 0.9413\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.3038 - f1: 0.9484 - val_loss: 0.2984 - val_f1: 0.9518\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.2963 - f1: 0.9515 - val_loss: 0.3257 - val_f1: 0.9340\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3034 - f1: 0.9475 - val_loss: 0.3377 - val_f1: 0.9493\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.2667 - f1: 0.9584 - val_loss: 0.3265 - val_f1: 0.9359\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.2694 - f1: 0.9530 - val_loss: 0.2988 - val_f1: 0.9461\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.2852 - f1: 0.9538 - val_loss: 0.2827 - val_f1: 0.9624\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.2273 - f1: 0.9642 - val_loss: 0.2511 - val_f1: 0.9541\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.2508 - f1: 0.9588 - val_loss: 0.2698 - val_f1: 0.9641\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.2824 - f1: 0.9559 - val_loss: 0.3140 - val_f1: 0.9378\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.2340 - f1: 0.9672 - val_loss: 0.2255 - val_f1: 0.9643\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.2502 - f1: 0.9634 - val_loss: 0.2859 - val_f1: 0.9626\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.2275 - f1: 0.9686 - val_loss: 0.2249 - val_f1: 0.9587\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.2017 - f1: 0.9713 - val_loss: 0.2032 - val_f1: 0.9635\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.2336 - f1: 0.9693 - val_loss: 0.2732 - val_f1: 0.9600\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.2312 - f1: 0.9739 - val_loss: 0.2326 - val_f1: 0.9664\n",
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.2092 - f1: 0.9815 - val_loss: 0.1868 - val_f1: 0.9689\n",
      "\n",
      "\n",
      "Running through training size 10000\n",
      "Running through fold 0\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 5s 478us/sample - loss: 1.2035 - f1: 0.7493 - val_loss: 0.5700 - val_f1: 0.9082\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.4870 - f1: 0.9194 - val_loss: 0.4251 - val_f1: 0.9246\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.3910 - f1: 0.9351 - val_loss: 0.3716 - val_f1: 0.9474\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 3s 281us/sample - loss: 0.3416 - f1: 0.9441 - val_loss: 0.3154 - val_f1: 0.9438\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 3s 281us/sample - loss: 0.3093 - f1: 0.9480 - val_loss: 0.3320 - val_f1: 0.9488\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.2955 - f1: 0.9555 - val_loss: 0.2715 - val_f1: 0.9617\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.2703 - f1: 0.9584 - val_loss: 0.2406 - val_f1: 0.9567\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.2614 - f1: 0.9635 - val_loss: 0.2060 - val_f1: 0.9699\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.2299 - f1: 0.9694 - val_loss: 0.2623 - val_f1: 0.9525\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.2280 - f1: 0.9752 - val_loss: 0.2182 - val_f1: 0.9815\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 3s 281us/sample - loss: 0.2089 - f1: 0.9781 - val_loss: 0.3282 - val_f1: 0.9477\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 3s 281us/sample - loss: 0.2084 - f1: 0.9819 - val_loss: 0.1997 - val_f1: 0.9825\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.1692 - f1: 0.9875 - val_loss: 0.2436 - val_f1: 0.9715\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.1912 - f1: 0.9848 - val_loss: 0.2133 - val_f1: 0.9843\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.1515 - f1: 0.9927 - val_loss: 0.1663 - val_f1: 0.9908\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.1833 - f1: 0.9883 - val_loss: 0.3456 - val_f1: 0.9647\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 3s 280us/sample - loss: 0.1495 - f1: 0.9945 - val_loss: 0.1220 - val_f1: 0.9965\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 3s 281us/sample - loss: 0.1119 - f1: 0.9963 - val_loss: 0.1748 - val_f1: 0.9871\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 3s 280us/sample - loss: 0.1867 - f1: 0.9893 - val_loss: 0.1727 - val_f1: 0.9894\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 3s 280us/sample - loss: 0.1362 - f1: 0.9952 - val_loss: 0.0927 - val_f1: 0.9988\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 3s 280us/sample - loss: 0.1534 - f1: 0.9924 - val_loss: 0.1850 - val_f1: 0.9967\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.1330 - f1: 0.9936 - val_loss: 0.1180 - val_f1: 0.9973\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.1686 - f1: 0.9919 - val_loss: 0.0922 - val_f1: 1.0000\n",
      "Epoch 24/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.0746 - f1: 0.9992 - val_loss: 0.0770 - val_f1: 0.9970\n",
      "Epoch 25/2000\n",
      "10000/10000 [==============================] - 3s 281us/sample - loss: 0.1247 - f1: 0.9941 - val_loss: 0.1965 - val_f1: 0.9903\n",
      "Epoch 26/2000\n",
      "10000/10000 [==============================] - 3s 281us/sample - loss: 0.1040 - f1: 0.9983 - val_loss: 0.0668 - val_f1: 0.9988\n",
      "Epoch 27/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.1098 - f1: 0.9932 - val_loss: 0.5058 - val_f1: 0.9555\n",
      "Running through fold 1\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 5s 489us/sample - loss: 1.1723 - f1: 0.7496 - val_loss: 0.5737 - val_f1: 0.9075\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.4859 - f1: 0.9187 - val_loss: 0.4400 - val_f1: 0.9245\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.3886 - f1: 0.9358 - val_loss: 0.3447 - val_f1: 0.9398\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.3281 - f1: 0.9455 - val_loss: 0.3315 - val_f1: 0.9516\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.3090 - f1: 0.9513 - val_loss: 0.3070 - val_f1: 0.9485\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.2848 - f1: 0.9529 - val_loss: 0.2924 - val_f1: 0.9529\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.2765 - f1: 0.9575 - val_loss: 0.2888 - val_f1: 0.9585\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.2590 - f1: 0.9602 - val_loss: 0.2333 - val_f1: 0.9592\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.2700 - f1: 0.9588 - val_loss: 0.3225 - val_f1: 0.9420\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.2311 - f1: 0.9679 - val_loss: 0.2296 - val_f1: 0.9607\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.2151 - f1: 0.9715 - val_loss: 0.2936 - val_f1: 0.9556\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.2158 - f1: 0.9762 - val_loss: 0.1971 - val_f1: 0.9858\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.1751 - f1: 0.9846 - val_loss: 0.1671 - val_f1: 0.9790\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.1930 - f1: 0.9842 - val_loss: 0.1589 - val_f1: 0.9935\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.1729 - f1: 0.9874 - val_loss: 0.1851 - val_f1: 0.9942\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.1719 - f1: 0.9899 - val_loss: 0.1174 - val_f1: 0.9945\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.1778 - f1: 0.9896 - val_loss: 0.1257 - val_f1: 0.9962\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 3s 289us/sample - loss: 0.1654 - f1: 0.9914 - val_loss: 0.1234 - val_f1: 0.9972\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 3s 280us/sample - loss: 0.1279 - f1: 0.9943 - val_loss: 0.1223 - val_f1: 0.9952\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 3s 281us/sample - loss: 0.1447 - f1: 0.9938 - val_loss: 0.1227 - val_f1: 0.9930\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.1745 - f1: 0.9897 - val_loss: 0.0982 - val_f1: 0.9997\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 3s 280us/sample - loss: 0.1191 - f1: 0.9963 - val_loss: 0.0943 - val_f1: 0.9982\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 3s 281us/sample - loss: 0.1547 - f1: 0.9899 - val_loss: 0.2523 - val_f1: 0.9829\n",
      "Epoch 24/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.1865 - f1: 0.9904 - val_loss: 0.1296 - val_f1: 0.9997\n",
      "Epoch 25/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.0824 - f1: 0.9996 - val_loss: 0.0693 - val_f1: 0.9992\n",
      "Epoch 26/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.2215 - f1: 0.9841 - val_loss: 0.2591 - val_f1: 0.9943\n",
      "Epoch 27/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.1078 - f1: 0.9992 - val_loss: 0.0682 - val_f1: 0.9998\n",
      "Running through fold 2\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 497us/sample - loss: 1.2084 - f1: 0.7521 - val_loss: 0.5688 - val_f1: 0.9159\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 3s 287us/sample - loss: 0.4957 - f1: 0.9192 - val_loss: 0.4042 - val_f1: 0.9370\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 3s 290us/sample - loss: 0.3943 - f1: 0.9351 - val_loss: 0.4004 - val_f1: 0.9441\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 3s 286us/sample - loss: 0.3370 - f1: 0.9446 - val_loss: 0.3113 - val_f1: 0.9496\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.3047 - f1: 0.9486 - val_loss: 0.3327 - val_f1: 0.9435\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.2858 - f1: 0.9529 - val_loss: 0.3006 - val_f1: 0.9523\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 3s 286us/sample - loss: 0.2674 - f1: 0.9578 - val_loss: 0.2191 - val_f1: 0.9700\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.2621 - f1: 0.9598 - val_loss: 0.2800 - val_f1: 0.9505\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.2460 - f1: 0.9654 - val_loss: 0.2100 - val_f1: 0.9729\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.2321 - f1: 0.9745 - val_loss: 0.1953 - val_f1: 0.9810\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.1963 - f1: 0.9813 - val_loss: 0.2257 - val_f1: 0.9728\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.1772 - f1: 0.9856 - val_loss: 0.1918 - val_f1: 0.9861\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.1911 - f1: 0.9844 - val_loss: 0.1925 - val_f1: 0.9897\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.1484 - f1: 0.9902 - val_loss: 0.2342 - val_f1: 0.9746\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.1939 - f1: 0.9873 - val_loss: 0.2491 - val_f1: 0.9777\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.1609 - f1: 0.9897 - val_loss: 0.1281 - val_f1: 0.9933\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.1551 - f1: 0.9905 - val_loss: 0.1884 - val_f1: 0.9796\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 3s 288us/sample - loss: 0.1629 - f1: 0.9922 - val_loss: 0.1119 - val_f1: 0.9955\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.1784 - f1: 0.9860 - val_loss: 0.1594 - val_f1: 0.9977\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 3s 281us/sample - loss: 0.1072 - f1: 0.9976 - val_loss: 0.0948 - val_f1: 0.9960\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 3s 281us/sample - loss: 0.1691 - f1: 0.9886 - val_loss: 0.2475 - val_f1: 0.9857\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 3s 281us/sample - loss: 0.1303 - f1: 0.9951 - val_loss: 0.0966 - val_f1: 0.9980\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.0922 - f1: 0.9972 - val_loss: 0.2050 - val_f1: 0.9696\n",
      "Epoch 24/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.1906 - f1: 0.9891 - val_loss: 0.1186 - val_f1: 0.9942\n",
      "Epoch 25/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.0889 - f1: 0.9974 - val_loss: 0.0826 - val_f1: 0.9957\n",
      "Epoch 26/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.2738 - f1: 0.9816 - val_loss: 0.1397 - val_f1: 0.9963\n",
      "Running through fold 3\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 5s 505us/sample - loss: 1.2173 - f1: 0.7424 - val_loss: 0.6101 - val_f1: 0.8955\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 3s 292us/sample - loss: 0.4968 - f1: 0.9183 - val_loss: 0.4028 - val_f1: 0.9412\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 3s 291us/sample - loss: 0.3793 - f1: 0.9406 - val_loss: 0.3238 - val_f1: 0.9523\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 3s 288us/sample - loss: 0.3313 - f1: 0.9467 - val_loss: 0.2955 - val_f1: 0.9491\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 3s 288us/sample - loss: 0.2952 - f1: 0.9519 - val_loss: 0.3126 - val_f1: 0.9466\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 3s 289us/sample - loss: 0.3071 - f1: 0.9506 - val_loss: 0.2626 - val_f1: 0.9527\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 3s 288us/sample - loss: 0.2699 - f1: 0.9579 - val_loss: 0.2347 - val_f1: 0.9567\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 3s 288us/sample - loss: 0.2468 - f1: 0.9628 - val_loss: 0.2360 - val_f1: 0.9607\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 3s 289us/sample - loss: 0.2491 - f1: 0.9648 - val_loss: 0.2458 - val_f1: 0.9676\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 3s 288us/sample - loss: 0.2463 - f1: 0.9724 - val_loss: 0.2462 - val_f1: 0.9665\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 3s 289us/sample - loss: 0.2063 - f1: 0.9789 - val_loss: 0.2309 - val_f1: 0.9788\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 3s 287us/sample - loss: 0.1962 - f1: 0.9801 - val_loss: 0.2650 - val_f1: 0.9682\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.1870 - f1: 0.9860 - val_loss: 0.1936 - val_f1: 0.9778\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.1972 - f1: 0.9839 - val_loss: 0.2164 - val_f1: 0.9782\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.1982 - f1: 0.9850 - val_loss: 0.2279 - val_f1: 0.9755\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.1619 - f1: 0.9904 - val_loss: 0.2062 - val_f1: 0.9801\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.1528 - f1: 0.9904 - val_loss: 0.1259 - val_f1: 0.9933\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.1863 - f1: 0.9855 - val_loss: 0.2100 - val_f1: 0.9748\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 3s 290us/sample - loss: 0.1479 - f1: 0.9914 - val_loss: 0.1259 - val_f1: 0.9895\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.1262 - f1: 0.9925 - val_loss: 0.2567 - val_f1: 0.9719\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.1865 - f1: 0.9887 - val_loss: 0.1891 - val_f1: 0.9861\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.1345 - f1: 0.9933 - val_loss: 0.0873 - val_f1: 0.9965\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.0982 - f1: 0.9959 - val_loss: 0.1427 - val_f1: 0.9882\n",
      "Epoch 24/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.1354 - f1: 0.9931 - val_loss: 0.1436 - val_f1: 0.9813\n",
      "Epoch 25/2000\n",
      "10000/10000 [==============================] - 3s 283us/sample - loss: 0.1906 - f1: 0.9899 - val_loss: 0.1110 - val_f1: 0.9977\n",
      "Epoch 26/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.0847 - f1: 0.9988 - val_loss: 0.0725 - val_f1: 0.9977\n",
      "Epoch 27/2000\n",
      "10000/10000 [==============================] - 3s 284us/sample - loss: 0.1009 - f1: 0.9968 - val_loss: 0.1006 - val_f1: 0.9967\n",
      "Running through fold 4\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 5s 520us/sample - loss: 1.2018 - f1: 0.7503 - val_loss: 0.5733 - val_f1: 0.9143\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 3s 294us/sample - loss: 0.4934 - f1: 0.9223 - val_loss: 0.4564 - val_f1: 0.9213\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 3s 293us/sample - loss: 0.3835 - f1: 0.9424 - val_loss: 0.3199 - val_f1: 0.9461\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 3s 294us/sample - loss: 0.3391 - f1: 0.9445 - val_loss: 0.2935 - val_f1: 0.9523\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 3s 291us/sample - loss: 0.3061 - f1: 0.9491 - val_loss: 0.3023 - val_f1: 0.9464\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 3s 289us/sample - loss: 0.2847 - f1: 0.9546 - val_loss: 0.2749 - val_f1: 0.9612\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 3s 289us/sample - loss: 0.2778 - f1: 0.9575 - val_loss: 0.2659 - val_f1: 0.9551\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 3s 290us/sample - loss: 0.2617 - f1: 0.9562 - val_loss: 0.2949 - val_f1: 0.9499\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 3s 289us/sample - loss: 0.2495 - f1: 0.9638 - val_loss: 0.2214 - val_f1: 0.9650\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 3s 290us/sample - loss: 0.2455 - f1: 0.9637 - val_loss: 0.2085 - val_f1: 0.9708\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 3s 286us/sample - loss: 0.2197 - f1: 0.9716 - val_loss: 0.1963 - val_f1: 0.9708\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 3s 286us/sample - loss: 0.2112 - f1: 0.9731 - val_loss: 0.2333 - val_f1: 0.9758\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 3s 286us/sample - loss: 0.2154 - f1: 0.9774 - val_loss: 0.1711 - val_f1: 0.9896\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.1794 - f1: 0.9809 - val_loss: 0.1552 - val_f1: 0.9901\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 3s 286us/sample - loss: 0.1680 - f1: 0.9871 - val_loss: 0.2631 - val_f1: 0.9813\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.1675 - f1: 0.9897 - val_loss: 0.1826 - val_f1: 0.9786\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 3s 286us/sample - loss: 0.1695 - f1: 0.9892 - val_loss: 0.1556 - val_f1: 0.9956\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 3s 286us/sample - loss: 0.1488 - f1: 0.9934 - val_loss: 0.0970 - val_f1: 0.9966\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 3s 286us/sample - loss: 0.1844 - f1: 0.9886 - val_loss: 0.1336 - val_f1: 0.9972\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.1213 - f1: 0.9957 - val_loss: 0.1524 - val_f1: 0.9952\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 3s 286us/sample - loss: 0.1266 - f1: 0.9952 - val_loss: 0.1041 - val_f1: 0.9967\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.1755 - f1: 0.9905 - val_loss: 0.1500 - val_f1: 0.9978\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 3s 285us/sample - loss: 0.0866 - f1: 0.9992 - val_loss: 0.0819 - val_f1: 0.9990\n",
      "\n",
      "\n",
      "Running through training size 15000\n",
      "Running through fold 0\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 440us/sample - loss: 0.9858 - f1: 0.8032 - val_loss: 0.4979 - val_f1: 0.9170\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.4173 - f1: 0.9266 - val_loss: 0.3372 - val_f1: 0.9459\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.3233 - f1: 0.9460 - val_loss: 0.3002 - val_f1: 0.9454\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.3143 - f1: 0.9463 - val_loss: 0.2965 - val_f1: 0.9473\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2824 - f1: 0.9516 - val_loss: 0.2191 - val_f1: 0.9613\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 283us/sample - loss: 0.2475 - f1: 0.9581 - val_loss: 0.2427 - val_f1: 0.9593\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.2400 - f1: 0.9623 - val_loss: 0.2724 - val_f1: 0.9641\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2333 - f1: 0.9691 - val_loss: 0.2473 - val_f1: 0.9576\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2027 - f1: 0.9767 - val_loss: 0.2387 - val_f1: 0.9667\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1633 - f1: 0.9865 - val_loss: 0.1930 - val_f1: 0.9741\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1813 - f1: 0.9884 - val_loss: 0.1253 - val_f1: 0.9950\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1452 - f1: 0.9919 - val_loss: 0.0993 - val_f1: 0.9972\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1652 - f1: 0.9906 - val_loss: 0.2245 - val_f1: 0.9928\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1077 - f1: 0.9981 - val_loss: 0.0994 - val_f1: 0.9978\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1400 - f1: 0.9925 - val_loss: 0.1701 - val_f1: 0.9958\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1039 - f1: 0.9967 - val_loss: 0.2180 - val_f1: 0.9865\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1998 - f1: 0.9890 - val_loss: 0.0784 - val_f1: 0.9990\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1119 - f1: 0.9954 - val_loss: 0.1727 - val_f1: 0.9899\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.0836 - f1: 0.9984 - val_loss: 0.1567 - val_f1: 0.9842\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1059 - f1: 0.9964 - val_loss: 0.0630 - val_f1: 0.9985\n",
      "Epoch 21/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.2054 - f1: 0.9886 - val_loss: 0.2016 - val_f1: 0.9945\n",
      "Running through fold 1\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 446us/sample - loss: 0.9841 - f1: 0.8050 - val_loss: 0.4580 - val_f1: 0.9294\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 283us/sample - loss: 0.4187 - f1: 0.9301 - val_loss: 0.3463 - val_f1: 0.9496\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 283us/sample - loss: 0.3306 - f1: 0.9451 - val_loss: 0.2907 - val_f1: 0.9564\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.2962 - f1: 0.9495 - val_loss: 0.2793 - val_f1: 0.9619\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2663 - f1: 0.9567 - val_loss: 0.2591 - val_f1: 0.9647\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.2358 - f1: 0.9649 - val_loss: 0.2414 - val_f1: 0.9637\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2175 - f1: 0.9728 - val_loss: 0.2838 - val_f1: 0.9480\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2079 - f1: 0.9782 - val_loss: 0.2206 - val_f1: 0.9517\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1747 - f1: 0.9862 - val_loss: 0.1969 - val_f1: 0.9590\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1859 - f1: 0.9874 - val_loss: 0.1531 - val_f1: 0.9955\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1704 - f1: 0.9899 - val_loss: 0.2777 - val_f1: 0.9842\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1306 - f1: 0.9961 - val_loss: 0.1058 - val_f1: 0.9942\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1110 - f1: 0.9968 - val_loss: 0.0859 - val_f1: 0.9983\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1508 - f1: 0.9933 - val_loss: 0.0883 - val_f1: 0.9992\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2259 - f1: 0.9866 - val_loss: 0.1069 - val_f1: 0.9998\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1005 - f1: 0.9968 - val_loss: 0.1303 - val_f1: 0.9952\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.0932 - f1: 0.9976 - val_loss: 0.1789 - val_f1: 0.9848\n",
      "Epoch 18/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1240 - f1: 0.9951 - val_loss: 0.0646 - val_f1: 0.9985\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.1986 - f1: 0.9874 - val_loss: 0.2581 - val_f1: 0.9865\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.0876 - f1: 0.9993 - val_loss: 0.0589 - val_f1: 1.0000\n",
      "Running through fold 2\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 457us/sample - loss: 0.9713 - f1: 0.8098 - val_loss: 0.5557 - val_f1: 0.9038\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.4131 - f1: 0.9321 - val_loss: 0.3418 - val_f1: 0.9456\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.3316 - f1: 0.9446 - val_loss: 0.2713 - val_f1: 0.9529\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.3002 - f1: 0.9494 - val_loss: 0.3053 - val_f1: 0.9506\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2827 - f1: 0.9546 - val_loss: 0.2489 - val_f1: 0.9641\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.2476 - f1: 0.9588 - val_loss: 0.2094 - val_f1: 0.9737\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.2418 - f1: 0.9641 - val_loss: 0.3093 - val_f1: 0.9466\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.2249 - f1: 0.9751 - val_loss: 0.1773 - val_f1: 0.9713\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1861 - f1: 0.9829 - val_loss: 0.1770 - val_f1: 0.9761\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1761 - f1: 0.9857 - val_loss: 0.1580 - val_f1: 0.9958\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1471 - f1: 0.9913 - val_loss: 0.1139 - val_f1: 0.9960\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1854 - f1: 0.9880 - val_loss: 0.1137 - val_f1: 0.9945\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1600 - f1: 0.9910 - val_loss: 0.1317 - val_f1: 0.9963\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1319 - f1: 0.9952 - val_loss: 0.1939 - val_f1: 0.9887\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1144 - f1: 0.9960 - val_loss: 0.0888 - val_f1: 0.9985\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1289 - f1: 0.9947 - val_loss: 0.0799 - val_f1: 0.9978\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1402 - f1: 0.9938 - val_loss: 0.0734 - val_f1: 0.9982\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1396 - f1: 0.9936 - val_loss: 0.1542 - val_f1: 0.9980\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.0832 - f1: 0.9990 - val_loss: 0.0654 - val_f1: 0.9990\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.0989 - f1: 0.9968 - val_loss: 0.1215 - val_f1: 0.9926\n",
      "Running through fold 3\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 453us/sample - loss: 0.9917 - f1: 0.7994 - val_loss: 0.4895 - val_f1: 0.9315\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.4156 - f1: 0.9334 - val_loss: 0.3519 - val_f1: 0.9451\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.3338 - f1: 0.9437 - val_loss: 0.3223 - val_f1: 0.9476\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.2910 - f1: 0.9517 - val_loss: 0.2963 - val_f1: 0.9493\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2709 - f1: 0.9544 - val_loss: 0.3863 - val_f1: 0.9469\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2587 - f1: 0.9613 - val_loss: 0.2181 - val_f1: 0.9691\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2422 - f1: 0.9664 - val_loss: 0.3911 - val_f1: 0.9522\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2054 - f1: 0.9801 - val_loss: 0.2046 - val_f1: 0.9734\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1919 - f1: 0.9826 - val_loss: 0.2160 - val_f1: 0.9697\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 288us/sample - loss: 0.1809 - f1: 0.9863 - val_loss: 0.1337 - val_f1: 0.9882\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1829 - f1: 0.9859 - val_loss: 0.1319 - val_f1: 0.9932\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1596 - f1: 0.9909 - val_loss: 0.1093 - val_f1: 0.9985\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1608 - f1: 0.9913 - val_loss: 0.1720 - val_f1: 0.9894\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1597 - f1: 0.9925 - val_loss: 0.1252 - val_f1: 0.9962\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.1398 - f1: 0.9932 - val_loss: 0.0864 - val_f1: 0.9985\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1001 - f1: 0.9971 - val_loss: 0.0897 - val_f1: 0.9978\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1659 - f1: 0.9906 - val_loss: 0.0881 - val_f1: 0.9970\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.0915 - f1: 0.9975 - val_loss: 0.1004 - val_f1: 0.9952\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1677 - f1: 0.9921 - val_loss: 0.1411 - val_f1: 0.9972\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1980 - f1: 0.9905 - val_loss: 0.1252 - val_f1: 0.9990\n",
      "Epoch 21/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.0738 - f1: 0.9993 - val_loss: 0.0587 - val_f1: 1.0000\n",
      "Epoch 22/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1045 - f1: 0.9951 - val_loss: 0.2354 - val_f1: 0.9770\n",
      "Running through fold 4\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 462us/sample - loss: 0.9956 - f1: 0.8007 - val_loss: 0.4719 - val_f1: 0.9298\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.4094 - f1: 0.9324 - val_loss: 0.3668 - val_f1: 0.9403\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.3302 - f1: 0.9431 - val_loss: 0.2924 - val_f1: 0.9494\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.2987 - f1: 0.9492 - val_loss: 0.3132 - val_f1: 0.9484\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 292us/sample - loss: 0.2763 - f1: 0.9536 - val_loss: 0.2501 - val_f1: 0.9619\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 295us/sample - loss: 0.2586 - f1: 0.9588 - val_loss: 0.3054 - val_f1: 0.9573\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.2248 - f1: 0.9677 - val_loss: 0.2174 - val_f1: 0.9809\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.2282 - f1: 0.9729 - val_loss: 0.1832 - val_f1: 0.9809\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 295us/sample - loss: 0.2013 - f1: 0.9823 - val_loss: 0.1358 - val_f1: 0.9952\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 293us/sample - loss: 0.1601 - f1: 0.9864 - val_loss: 0.1601 - val_f1: 0.9851\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.1745 - f1: 0.9871 - val_loss: 0.1676 - val_f1: 0.9821\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.1630 - f1: 0.9907 - val_loss: 0.1253 - val_f1: 0.9940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.1520 - f1: 0.9916 - val_loss: 0.3512 - val_f1: 0.9787\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 292us/sample - loss: 0.1565 - f1: 0.9927 - val_loss: 0.1560 - val_f1: 0.9902\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1132 - f1: 0.9950 - val_loss: 0.0899 - val_f1: 0.9972\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.1559 - f1: 0.9928 - val_loss: 0.1022 - val_f1: 0.9960\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1170 - f1: 0.9952 - val_loss: 0.1852 - val_f1: 0.9963\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1327 - f1: 0.9954 - val_loss: 0.0667 - val_f1: 0.9988\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1577 - f1: 0.9925 - val_loss: 0.1163 - val_f1: 0.9985\n",
      "\n",
      "\n",
      "Running through training size 20000\n",
      "Running through fold 0\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 8s 422us/sample - loss: 0.8452 - f1: 0.8362 - val_loss: 0.4093 - val_f1: 0.9375\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.3714 - f1: 0.9386 - val_loss: 0.3548 - val_f1: 0.9411\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 286us/sample - loss: 0.2990 - f1: 0.9483 - val_loss: 0.2583 - val_f1: 0.9610\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 286us/sample - loss: 0.2715 - f1: 0.9545 - val_loss: 0.2291 - val_f1: 0.9556\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.2359 - f1: 0.9633 - val_loss: 0.2137 - val_f1: 0.9639\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.2180 - f1: 0.9739 - val_loss: 0.2104 - val_f1: 0.9880\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.2173 - f1: 0.9780 - val_loss: 0.1736 - val_f1: 0.9918\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1767 - f1: 0.9879 - val_loss: 0.1749 - val_f1: 0.9882\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 286us/sample - loss: 0.1328 - f1: 0.9924 - val_loss: 0.2067 - val_f1: 0.9746\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 286us/sample - loss: 0.1678 - f1: 0.9873 - val_loss: 0.3495 - val_f1: 0.9801\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1433 - f1: 0.9936 - val_loss: 0.1386 - val_f1: 0.9957\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 286us/sample - loss: 0.1579 - f1: 0.9917 - val_loss: 0.1909 - val_f1: 0.9905\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 286us/sample - loss: 0.1146 - f1: 0.9949 - val_loss: 0.1878 - val_f1: 0.9898\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1374 - f1: 0.9928 - val_loss: 0.2257 - val_f1: 0.9860\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 286us/sample - loss: 0.1056 - f1: 0.9964 - val_loss: 0.1572 - val_f1: 0.9885\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1060 - f1: 0.9959 - val_loss: 0.0754 - val_f1: 0.9953\n",
      "Running through fold 1\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 8s 421us/sample - loss: 0.8503 - f1: 0.8332 - val_loss: 0.3953 - val_f1: 0.9348\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.3601 - f1: 0.9419 - val_loss: 0.3582 - val_f1: 0.9417\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.2992 - f1: 0.9510 - val_loss: 0.2998 - val_f1: 0.9467\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.2595 - f1: 0.9600 - val_loss: 0.2258 - val_f1: 0.9668\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.2401 - f1: 0.9679 - val_loss: 0.2289 - val_f1: 0.9740\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.2057 - f1: 0.9797 - val_loss: 0.2624 - val_f1: 0.9856\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 291us/sample - loss: 0.2009 - f1: 0.9859 - val_loss: 0.1366 - val_f1: 0.9965\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1473 - f1: 0.9917 - val_loss: 0.1533 - val_f1: 0.9933\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1522 - f1: 0.9921 - val_loss: 0.1281 - val_f1: 0.9975\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1653 - f1: 0.9918 - val_loss: 0.1285 - val_f1: 0.9973\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1164 - f1: 0.9955 - val_loss: 0.1560 - val_f1: 0.9910\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1298 - f1: 0.9951 - val_loss: 0.0786 - val_f1: 0.9995\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1396 - f1: 0.9938 - val_loss: 0.0691 - val_f1: 0.9998\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1460 - f1: 0.9932 - val_loss: 0.0986 - val_f1: 0.9985\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1061 - f1: 0.9966 - val_loss: 0.0684 - val_f1: 0.9998\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.0863 - f1: 0.9961 - val_loss: 0.3973 - val_f1: 0.9665\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1633 - f1: 0.9938 - val_loss: 0.0548 - val_f1: 0.9990\n",
      "Running through fold 2\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 9s 427us/sample - loss: 0.8482 - f1: 0.8335 - val_loss: 0.3883 - val_f1: 0.9406\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.3625 - f1: 0.9428 - val_loss: 0.3560 - val_f1: 0.9380\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.3030 - f1: 0.9490 - val_loss: 0.3199 - val_f1: 0.9420\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.2701 - f1: 0.9556 - val_loss: 0.3104 - val_f1: 0.9375\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.2421 - f1: 0.9641 - val_loss: 0.1877 - val_f1: 0.9784\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2238 - f1: 0.9702 - val_loss: 0.3404 - val_f1: 0.9619\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1895 - f1: 0.9863 - val_loss: 0.1473 - val_f1: 0.9935\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1700 - f1: 0.9900 - val_loss: 0.2117 - val_f1: 0.9932\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1607 - f1: 0.9915 - val_loss: 0.2372 - val_f1: 0.9907\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1186 - f1: 0.9964 - val_loss: 0.0924 - val_f1: 0.9977\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1667 - f1: 0.9917 - val_loss: 0.0857 - val_f1: 0.9988\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1616 - f1: 0.9919 - val_loss: 0.1959 - val_f1: 0.9899\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.0957 - f1: 0.9978 - val_loss: 0.1127 - val_f1: 0.9973\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1163 - f1: 0.9951 - val_loss: 0.1601 - val_f1: 0.9838\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1894 - f1: 0.9910 - val_loss: 0.0611 - val_f1: 0.9998\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.0876 - f1: 0.9964 - val_loss: 0.2454 - val_f1: 0.9917\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1267 - f1: 0.9957 - val_loss: 0.0650 - val_f1: 0.9990\n",
      "Running through fold 3\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 9s 430us/sample - loss: 0.8587 - f1: 0.8285 - val_loss: 0.4404 - val_f1: 0.9218\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.3776 - f1: 0.9356 - val_loss: 0.3378 - val_f1: 0.9499\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.3072 - f1: 0.9481 - val_loss: 0.2493 - val_f1: 0.9586\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2742 - f1: 0.9537 - val_loss: 0.3367 - val_f1: 0.9356\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2507 - f1: 0.9620 - val_loss: 0.2343 - val_f1: 0.9674\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2231 - f1: 0.9732 - val_loss: 0.2345 - val_f1: 0.9744\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2013 - f1: 0.9822 - val_loss: 0.1689 - val_f1: 0.9912\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1771 - f1: 0.9877 - val_loss: 0.1220 - val_f1: 0.9982\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1697 - f1: 0.9909 - val_loss: 0.1138 - val_f1: 0.9987\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1336 - f1: 0.9947 - val_loss: 0.1098 - val_f1: 0.9998\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1549 - f1: 0.9924 - val_loss: 0.1033 - val_f1: 0.9995\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1108 - f1: 0.9959 - val_loss: 0.1435 - val_f1: 0.9947\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1429 - f1: 0.9932 - val_loss: 0.1051 - val_f1: 0.9985\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1250 - f1: 0.9955 - val_loss: 0.0662 - val_f1: 0.9992\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1637 - f1: 0.9920 - val_loss: 0.0867 - val_f1: 0.9987\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.0997 - f1: 0.9965 - val_loss: 0.0599 - val_f1: 0.9990\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 6s 294us/sample - loss: 0.1748 - f1: 0.9913 - val_loss: 0.0740 - val_f1: 0.9997\n",
      "Running through fold 4\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 9s 444us/sample - loss: 0.8444 - f1: 0.8372 - val_loss: 0.4118 - val_f1: 0.9298\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.3653 - f1: 0.9395 - val_loss: 0.3750 - val_f1: 0.9316\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.3015 - f1: 0.9520 - val_loss: 0.2740 - val_f1: 0.9492\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.2720 - f1: 0.9599 - val_loss: 0.2562 - val_f1: 0.9656\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.2273 - f1: 0.9762 - val_loss: 0.2107 - val_f1: 0.9903\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.2033 - f1: 0.9829 - val_loss: 0.1888 - val_f1: 0.9875\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.2137 - f1: 0.9823 - val_loss: 0.1580 - val_f1: 0.9945\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1587 - f1: 0.9906 - val_loss: 0.2243 - val_f1: 0.9895\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1720 - f1: 0.9880 - val_loss: 0.1284 - val_f1: 0.9947\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1593 - f1: 0.9901 - val_loss: 0.0942 - val_f1: 0.9963\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1506 - f1: 0.9912 - val_loss: 0.0889 - val_f1: 0.9967\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1586 - f1: 0.9907 - val_loss: 0.1119 - val_f1: 0.9955\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1455 - f1: 0.9913 - val_loss: 0.1779 - val_f1: 0.9864\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1259 - f1: 0.9935 - val_loss: 0.2744 - val_f1: 0.9792\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 291us/sample - loss: 0.1151 - f1: 0.9961 - val_loss: 0.0716 - val_f1: 0.9978\n"
     ]
    }
   ],
   "source": [
    "mlb=LabelBinarizer()\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    print('\\n\\nRunning through training size '+str(train_size))\n",
    "    k_folds_errors = []\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=5, train_size=train_size)\n",
    "    k = 0\n",
    "    for train_index, _ in sss.split(training_spectra, training_keys):\n",
    "        print('Running through fold '+str(k))\n",
    "        training_keys_binarized = mlb.fit_transform(training_keys.reshape([training_keys.shape[0],1]))\n",
    "        testing_keys_binarized = mlb.transform(testing_keys)\n",
    "        \n",
    "        model = compile_model(\n",
    "            build_cnn_model,\n",
    "            model_features)\n",
    "        model_weights = model.get_weights()\n",
    "        model_weights_updated = model_weights[:]\n",
    "        model_weights_updated[0:6] = cae_model.get_weights()[0:6]\n",
    "        model.set_weights(model_weights_updated)\n",
    "\n",
    "        csv_logger = tf.keras.callbacks.CSVLogger('./final-models-keras/'+model_id_save_as+'_trainsize'+str(train_size)+'_fold'+str(k)+'.log')\n",
    "\n",
    "        output = model.fit(\n",
    "            x=training_spectra_scaled[train_index],\n",
    "            y=training_keys_binarized[train_index],\n",
    "            epochs=num_epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(testing_spectra_scaled,\n",
    "                             testing_keys_binarized),\n",
    "            shuffle=True,\n",
    "            callbacks=[earlystop_callback, csv_logger],\n",
    "        )\n",
    "        model.save('./final-models-keras/'+model_id_save_as+'_trainsize'+str(train_size)+'_fold'+str(k)+'.hdf5')\n",
    "        k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36_update)",
   "language": "python",
   "name": "conda_tensorflow_p36_update"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
