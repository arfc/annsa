{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_device_id = str(0)\n",
    "model_id_save_as = 'learningcurve-cnn-easy-final-reluupdate'\n",
    "# architecture_id = '../hyperparameter_search/hyperparameter-search-results/CNN-kfoldseasy-final-1_14'\n",
    "architecture_id = '../hyperparameter_search/hyperparameter-search-results/CNN-kfoldseasy-final-1-reluupdate_33'\n",
    "model_class_id = 'CNN1D'\n",
    "testing_dataset_id = '../../source-interdiction/dataset_generation/validation_dataset_200keV_log10time_100.npy'\n",
    "training_dataset_id = '../../source-interdiction/dataset_generation/training_dataset_200keV_log10time_10000.npy'\n",
    "difficulty_setting = 'easy'\n",
    "\n",
    "train_sizes = [10000, 50, 100, 500, 1000, 5000, 15000, 20000, ]\n",
    "earlystop_patience = 10\n",
    "num_epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_device_id\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(5)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import model, training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from annsa.model_classes import build_cnn_model, compile_model, f1\n",
    "from annsa.load_dataset import load_easy, load_full, dataset_to_spectrakeys\n",
    "from annsa.load_pretrained_network import load_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = np.load(training_dataset_id)\n",
    "training_spectra, training_keys = dataset_to_spectrakeys(training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = np.load(testing_dataset_id)\n",
    "testing_spectra, testing_keys = dataset_to_spectrakeys(testing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = load_features(architecture_id)\n",
    "model_features.output_function = tf.nn.softmax\n",
    "model_features.cnn_kernels = model_features.cnn_kernel\n",
    "model_features.pool_sizes = model_features.pool_size\n",
    "model_features.loss = tf.keras.losses.categorical_crossentropy\n",
    "model_features.optimizer = tf.keras.optimizers.Adam\n",
    "model_features.metrics = [f1]\n",
    "model_features.dropout_rate = model_features.dropout_probability\n",
    "model_features.output_function = tf.nn.softmax\n",
    "model_features.input_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 1024, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 1024, 4)           68        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 512, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 512, 8)            520       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 256, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 256, 16)           2064      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 128, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1950      \n",
      "=================================================================\n",
      "Total params: 275,130\n",
      "Trainable params: 275,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = compile_model(\n",
    "            build_cnn_model,\n",
    "            model_features)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_spectra_scaled = model_features.scaler.transform(training_spectra)\n",
    "testing_spectra_scaled = model_features.scaler.transform(testing_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_f1',\n",
    "    patience=earlystop_patience,\n",
    "    mode='max',\n",
    "    min_delta=0.01,\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running through training size 10000\n",
      "Running through fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 4s 386us/sample - loss: 1.5050 - f1: 0.6233 - val_loss: 0.6766 - val_f1: 0.8853\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.5624 - f1: 0.8951 - val_loss: 0.4881 - val_f1: 0.9122\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.4416 - f1: 0.9137 - val_loss: 0.4302 - val_f1: 0.9099\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.3943 - f1: 0.9242 - val_loss: 0.3405 - val_f1: 0.9450\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.3461 - f1: 0.9372 - val_loss: 0.3634 - val_f1: 0.9290\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.3246 - f1: 0.9441 - val_loss: 0.2917 - val_f1: 0.9539\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.3137 - f1: 0.9460 - val_loss: 0.2817 - val_f1: 0.9451\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.2779 - f1: 0.9512 - val_loss: 0.2683 - val_f1: 0.9572\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.2855 - f1: 0.9486 - val_loss: 0.2420 - val_f1: 0.9630\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.2879 - f1: 0.9468 - val_loss: 0.2802 - val_f1: 0.9489\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.2514 - f1: 0.9556 - val_loss: 0.2849 - val_f1: 0.9504\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.2340 - f1: 0.9596 - val_loss: 0.2121 - val_f1: 0.9593\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 2s 220us/sample - loss: 0.2541 - f1: 0.9540 - val_loss: 0.2108 - val_f1: 0.9706\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.2383 - f1: 0.9594 - val_loss: 0.1726 - val_f1: 0.9718\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.2186 - f1: 0.9655 - val_loss: 0.2099 - val_f1: 0.9688\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.1674 - f1: 0.9848 - val_loss: 0.1566 - val_f1: 0.9888\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.2021 - f1: 0.9840 - val_loss: 0.2194 - val_f1: 0.9910\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.1688 - f1: 0.9901 - val_loss: 0.1975 - val_f1: 0.9832\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.1346 - f1: 0.9940 - val_loss: 0.1107 - val_f1: 0.9962\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.1537 - f1: 0.9919 - val_loss: 0.1745 - val_f1: 0.9892\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.1684 - f1: 0.9889 - val_loss: 0.1770 - val_f1: 0.9839\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.1657 - f1: 0.9921 - val_loss: 0.0946 - val_f1: 0.9983\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.1080 - f1: 0.9953 - val_loss: 0.2169 - val_f1: 0.9881\n",
      "Epoch 24/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.1534 - f1: 0.9932 - val_loss: 0.0872 - val_f1: 0.9968\n",
      "Epoch 25/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.1462 - f1: 0.9902 - val_loss: 0.2866 - val_f1: 0.9833\n",
      "Epoch 26/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.1794 - f1: 0.9919 - val_loss: 0.0847 - val_f1: 0.9987\n",
      "Running through fold 1\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 3s 291us/sample - loss: 1.5060 - f1: 0.6216 - val_loss: 0.6566 - val_f1: 0.8857\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.5651 - f1: 0.9003 - val_loss: 0.4449 - val_f1: 0.9330\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 2s 222us/sample - loss: 0.4297 - f1: 0.9271 - val_loss: 0.3429 - val_f1: 0.9490\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.3624 - f1: 0.9398 - val_loss: 0.3582 - val_f1: 0.9337\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.3165 - f1: 0.9509 - val_loss: 0.2939 - val_f1: 0.9492\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.2963 - f1: 0.9573 - val_loss: 0.2543 - val_f1: 0.9668\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.2633 - f1: 0.9706 - val_loss: 0.2862 - val_f1: 0.9701\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.2371 - f1: 0.9794 - val_loss: 0.2008 - val_f1: 0.9889\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.2200 - f1: 0.9850 - val_loss: 0.2361 - val_f1: 0.9756\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.1632 - f1: 0.9927 - val_loss: 0.2071 - val_f1: 0.9888\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.1890 - f1: 0.9899 - val_loss: 0.1234 - val_f1: 0.9982\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.1602 - f1: 0.9922 - val_loss: 0.1219 - val_f1: 0.9973\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.1591 - f1: 0.9918 - val_loss: 0.2831 - val_f1: 0.9547\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.1634 - f1: 0.9916 - val_loss: 0.1587 - val_f1: 0.9895\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.1531 - f1: 0.9930 - val_loss: 0.1169 - val_f1: 0.9957\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 2s 218us/sample - loss: 0.2110 - f1: 0.9871 - val_loss: 0.1131 - val_f1: 0.9988\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 2s 219us/sample - loss: 0.1233 - f1: 0.9952 - val_loss: 0.3506 - val_f1: 0.9443\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 2s 234us/sample - loss: 0.1601 - f1: 0.9935 - val_loss: 0.0882 - val_f1: 0.9988\n",
      "Running through fold 2\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 3s 295us/sample - loss: 1.3562 - f1: 0.6809 - val_loss: 0.6228 - val_f1: 0.9003\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.5413 - f1: 0.9016 - val_loss: 0.4407 - val_f1: 0.9241\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.4361 - f1: 0.9178 - val_loss: 0.3523 - val_f1: 0.9432\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.3689 - f1: 0.9357 - val_loss: 0.3448 - val_f1: 0.9282\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.3224 - f1: 0.9449 - val_loss: 0.3113 - val_f1: 0.9519\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.2969 - f1: 0.9508 - val_loss: 0.2734 - val_f1: 0.9564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.2881 - f1: 0.9504 - val_loss: 0.3426 - val_f1: 0.9469\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.2620 - f1: 0.9578 - val_loss: 0.2450 - val_f1: 0.9587\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.2309 - f1: 0.9629 - val_loss: 0.2408 - val_f1: 0.9510\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.2789 - f1: 0.9563 - val_loss: 0.2641 - val_f1: 0.9505\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 2s 220us/sample - loss: 0.2223 - f1: 0.9668 - val_loss: 0.2206 - val_f1: 0.9629\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.1998 - f1: 0.9733 - val_loss: 0.1754 - val_f1: 0.9802\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.2282 - f1: 0.9676 - val_loss: 0.1992 - val_f1: 0.9771\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.1939 - f1: 0.9770 - val_loss: 0.2097 - val_f1: 0.9791\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.2507 - f1: 0.9738 - val_loss: 0.1580 - val_f1: 0.9943\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.1489 - f1: 0.9903 - val_loss: 0.2095 - val_f1: 0.9797\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.1392 - f1: 0.9945 - val_loss: 0.1184 - val_f1: 0.9978\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 2s 220us/sample - loss: 0.2273 - f1: 0.9842 - val_loss: 0.1344 - val_f1: 0.9980\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.1217 - f1: 0.9971 - val_loss: 0.1019 - val_f1: 0.9982\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.1589 - f1: 0.9927 - val_loss: 0.1264 - val_f1: 0.9990\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.1395 - f1: 0.9950 - val_loss: 0.0854 - val_f1: 0.9997\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.0983 - f1: 0.9977 - val_loss: 0.1645 - val_f1: 0.9825\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.2231 - f1: 0.9865 - val_loss: 0.1352 - val_f1: 0.9982\n",
      "Epoch 24/2000\n",
      "10000/10000 [==============================] - 2s 221us/sample - loss: 0.1005 - f1: 0.9980 - val_loss: 0.0935 - val_f1: 0.9991\n",
      "Epoch 25/2000\n",
      "10000/10000 [==============================] - 2s 241us/sample - loss: 0.1569 - f1: 0.9904 - val_loss: 0.0828 - val_f1: 0.9997\n",
      "Running through fold 3\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 3s 311us/sample - loss: 1.4765 - f1: 0.6093 - val_loss: 0.6691 - val_f1: 0.8747\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.5631 - f1: 0.8911 - val_loss: 0.4938 - val_f1: 0.9101\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.4538 - f1: 0.9107 - val_loss: 0.3942 - val_f1: 0.9330\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.3832 - f1: 0.9284 - val_loss: 0.3439 - val_f1: 0.9340\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.3565 - f1: 0.9352 - val_loss: 0.3186 - val_f1: 0.9424\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.3363 - f1: 0.9408 - val_loss: 0.3037 - val_f1: 0.9392\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.2968 - f1: 0.9472 - val_loss: 0.3907 - val_f1: 0.9278\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.2793 - f1: 0.9547 - val_loss: 0.2598 - val_f1: 0.9556\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.2803 - f1: 0.9545 - val_loss: 0.2467 - val_f1: 0.9601\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 2s 228us/sample - loss: 0.2803 - f1: 0.9578 - val_loss: 0.2288 - val_f1: 0.9773\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 2s 228us/sample - loss: 0.2274 - f1: 0.9683 - val_loss: 0.2096 - val_f1: 0.9635\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.2368 - f1: 0.9705 - val_loss: 0.2085 - val_f1: 0.9796\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 2s 225us/sample - loss: 0.2374 - f1: 0.9732 - val_loss: 0.1688 - val_f1: 0.9853\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 2s 225us/sample - loss: 0.2165 - f1: 0.9788 - val_loss: 0.1744 - val_f1: 0.9918\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.1859 - f1: 0.9834 - val_loss: 0.2168 - val_f1: 0.9784\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.1675 - f1: 0.9892 - val_loss: 0.2898 - val_f1: 0.9503\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.2008 - f1: 0.9843 - val_loss: 0.1375 - val_f1: 0.9935\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.2032 - f1: 0.9838 - val_loss: 0.1852 - val_f1: 0.9901\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 2s 225us/sample - loss: 0.1469 - f1: 0.9913 - val_loss: 0.3159 - val_f1: 0.9535\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.1825 - f1: 0.9889 - val_loss: 0.1473 - val_f1: 0.9894\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.1496 - f1: 0.9922 - val_loss: 0.1094 - val_f1: 0.9937\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.1816 - f1: 0.9867 - val_loss: 0.1907 - val_f1: 0.9892\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 2s 226us/sample - loss: 0.1825 - f1: 0.9887 - val_loss: 0.1221 - val_f1: 0.9945\n",
      "Epoch 24/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.1303 - f1: 0.9926 - val_loss: 0.3086 - val_f1: 0.9476\n",
      "Running through fold 4\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 3s 321us/sample - loss: 1.3808 - f1: 0.6629 - val_loss: 0.6130 - val_f1: 0.9008\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 2s 232us/sample - loss: 0.5128 - f1: 0.9208 - val_loss: 0.3878 - val_f1: 0.9483\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 2s 230us/sample - loss: 0.3755 - f1: 0.9430 - val_loss: 0.3455 - val_f1: 0.9482\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 2s 229us/sample - loss: 0.3236 - f1: 0.9506 - val_loss: 0.2975 - val_f1: 0.9519\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 2s 228us/sample - loss: 0.2954 - f1: 0.9556 - val_loss: 0.2503 - val_f1: 0.9580\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.2795 - f1: 0.9567 - val_loss: 0.3373 - val_f1: 0.9472\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 2s 228us/sample - loss: 0.2614 - f1: 0.9701 - val_loss: 0.2720 - val_f1: 0.9758\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.2415 - f1: 0.9725 - val_loss: 0.1887 - val_f1: 0.9837\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 2s 228us/sample - loss: 0.2388 - f1: 0.9744 - val_loss: 0.1742 - val_f1: 0.9928\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.2103 - f1: 0.9820 - val_loss: 0.2195 - val_f1: 0.9776\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.1811 - f1: 0.9906 - val_loss: 0.2139 - val_f1: 0.9713\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.1871 - f1: 0.9882 - val_loss: 0.1196 - val_f1: 0.9970\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.1683 - f1: 0.9913 - val_loss: 0.1266 - val_f1: 0.9967\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.1448 - f1: 0.9943 - val_loss: 0.1056 - val_f1: 0.9967\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.1673 - f1: 0.9898 - val_loss: 0.1123 - val_f1: 0.9972\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.1119 - f1: 0.9962 - val_loss: 0.1810 - val_f1: 0.9850\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.1494 - f1: 0.9944 - val_loss: 0.1105 - val_f1: 0.9972\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 2s 227us/sample - loss: 0.1450 - f1: 0.9933 - val_loss: 0.1888 - val_f1: 0.9875\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.1773 - f1: 0.9907 - val_loss: 0.0896 - val_f1: 0.9988\n",
      "\n",
      "\n",
      "Running through training size 50\n",
      "Running through fold 0\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 22ms/sample - loss: 4.8269 - f1: 0.0000e+00 - val_loss: 4.6795 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.6355 - f1: 0.0000e+00 - val_loss: 4.5552 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.4822 - f1: 0.0000e+00 - val_loss: 4.4421 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.3546 - f1: 0.0000e+00 - val_loss: 4.3319 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.2268 - f1: 0.0000e+00 - val_loss: 4.2163 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.0917 - f1: 0.0000e+00 - val_loss: 4.0904 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.9368 - f1: 0.0000e+00 - val_loss: 3.9612 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7968 - f1: 0.0000e+00 - val_loss: 3.8481 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.6933 - f1: 0.0000e+00 - val_loss: 3.7353 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.5045 - f1: 0.0000e+00 - val_loss: 3.6386 - val_f1: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 1s 12ms/sample - loss: 3.4285 - f1: 0.0000e+00 - val_loss: 3.5472 - val_f1: 0.0000e+00\n",
      "Running through fold 1\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 23ms/sample - loss: 4.8116 - f1: 0.0000e+00 - val_loss: 4.6612 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.6086 - f1: 0.0000e+00 - val_loss: 4.5242 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.4496 - f1: 0.0000e+00 - val_loss: 4.3947 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.2871 - f1: 0.0000e+00 - val_loss: 4.2635 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.1250 - f1: 0.0000e+00 - val_loss: 4.1294 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.9637 - f1: 0.0000e+00 - val_loss: 3.9876 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.7793 - f1: 0.0000e+00 - val_loss: 3.8237 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.5931 - f1: 0.0000e+00 - val_loss: 3.6691 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.4141 - f1: 0.0000e+00 - val_loss: 3.5136 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.2469 - f1: 0.0000e+00 - val_loss: 3.3752 - val_f1: 0.0111\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.0675 - f1: 0.0303 - val_loss: 3.2513 - val_f1: 0.0195\n",
      "Epoch 12/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.9334 - f1: 0.0526 - val_loss: 3.1197 - val_f1: 0.0236\n",
      "Epoch 13/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.7388 - f1: 0.0303 - val_loss: 3.0205 - val_f1: 0.0422\n",
      "Epoch 14/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.6021 - f1: 0.1303 - val_loss: 2.9117 - val_f1: 0.0591\n",
      "Epoch 15/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.4715 - f1: 0.2017 - val_loss: 2.8203 - val_f1: 0.0747\n",
      "Epoch 16/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.3669 - f1: 0.1732 - val_loss: 2.7485 - val_f1: 0.1063\n",
      "Epoch 17/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.2673 - f1: 0.2780 - val_loss: 2.6930 - val_f1: 0.1543\n",
      "Epoch 18/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.1598 - f1: 0.2929 - val_loss: 2.6183 - val_f1: 0.1822\n",
      "Epoch 19/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.0547 - f1: 0.3558 - val_loss: 2.5541 - val_f1: 0.2135\n",
      "Epoch 20/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.9450 - f1: 0.4995 - val_loss: 2.4683 - val_f1: 0.2365\n",
      "Epoch 21/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.8717 - f1: 0.5227 - val_loss: 2.4062 - val_f1: 0.2526\n",
      "Epoch 22/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.8172 - f1: 0.4620 - val_loss: 2.3783 - val_f1: 0.2971\n",
      "Epoch 23/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.7191 - f1: 0.5543 - val_loss: 2.3452 - val_f1: 0.3092\n",
      "Epoch 24/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.6492 - f1: 0.6120 - val_loss: 2.3046 - val_f1: 0.3212\n",
      "Epoch 25/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.5656 - f1: 0.6460 - val_loss: 2.2710 - val_f1: 0.3341\n",
      "Epoch 26/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.5146 - f1: 0.5991 - val_loss: 2.2524 - val_f1: 0.3526\n",
      "Epoch 27/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.5199 - f1: 0.6268 - val_loss: 2.2243 - val_f1: 0.3691\n",
      "Epoch 28/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.4327 - f1: 0.7126 - val_loss: 2.2120 - val_f1: 0.3894\n",
      "Epoch 29/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3994 - f1: 0.7179 - val_loss: 2.2012 - val_f1: 0.4005\n",
      "Epoch 30/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3424 - f1: 0.7519 - val_loss: 2.1664 - val_f1: 0.4044\n",
      "Epoch 31/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3113 - f1: 0.7755 - val_loss: 2.1571 - val_f1: 0.4068\n",
      "Epoch 32/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.2276 - f1: 0.7646 - val_loss: 2.1448 - val_f1: 0.4168\n",
      "Epoch 33/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1714 - f1: 0.8054 - val_loss: 2.1575 - val_f1: 0.4146\n",
      "Epoch 34/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1511 - f1: 0.8375 - val_loss: 2.1555 - val_f1: 0.4172\n",
      "Epoch 35/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1480 - f1: 0.8156 - val_loss: 2.1017 - val_f1: 0.4337\n",
      "Epoch 36/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0834 - f1: 0.8727 - val_loss: 2.1015 - val_f1: 0.4360\n",
      "Epoch 37/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0720 - f1: 0.8375 - val_loss: 2.1328 - val_f1: 0.4186\n",
      "Epoch 38/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0495 - f1: 0.8620 - val_loss: 2.1052 - val_f1: 0.4242\n",
      "Epoch 39/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9980 - f1: 0.8326 - val_loss: 2.0699 - val_f1: 0.4438\n",
      "Epoch 40/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9788 - f1: 0.8931 - val_loss: 2.0574 - val_f1: 0.4371\n",
      "Epoch 41/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9420 - f1: 0.8661 - val_loss: 2.0703 - val_f1: 0.4308\n",
      "Epoch 42/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9335 - f1: 0.8858 - val_loss: 2.0428 - val_f1: 0.4472\n",
      "Epoch 43/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8992 - f1: 0.9042 - val_loss: 2.0206 - val_f1: 0.4655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8836 - f1: 0.8951 - val_loss: 2.0138 - val_f1: 0.4668\n",
      "Epoch 45/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8634 - f1: 0.9189 - val_loss: 2.0132 - val_f1: 0.4630\n",
      "Epoch 46/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8394 - f1: 0.9122 - val_loss: 2.0086 - val_f1: 0.4756\n",
      "Epoch 47/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8371 - f1: 0.9483 - val_loss: 2.0033 - val_f1: 0.4796\n",
      "Epoch 48/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8026 - f1: 0.9384 - val_loss: 1.9925 - val_f1: 0.4800\n",
      "Epoch 49/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7829 - f1: 0.9611 - val_loss: 1.9942 - val_f1: 0.4819\n",
      "Epoch 50/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7624 - f1: 0.9611 - val_loss: 1.9818 - val_f1: 0.4885\n",
      "Epoch 51/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7454 - f1: 0.9627 - val_loss: 1.9787 - val_f1: 0.4973\n",
      "Epoch 52/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7273 - f1: 0.9384 - val_loss: 1.9818 - val_f1: 0.4867\n",
      "Epoch 53/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7119 - f1: 0.9921 - val_loss: 1.9563 - val_f1: 0.4940\n",
      "Epoch 54/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6983 - f1: 0.9839 - val_loss: 1.9393 - val_f1: 0.5072\n",
      "Epoch 55/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6783 - f1: 0.9857 - val_loss: 1.9491 - val_f1: 0.5074\n",
      "Epoch 56/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6765 - f1: 0.9839 - val_loss: 1.9660 - val_f1: 0.5054\n",
      "Epoch 57/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6527 - f1: 0.9778 - val_loss: 1.9790 - val_f1: 0.5055\n",
      "Epoch 58/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6465 - f1: 0.9921 - val_loss: 1.9677 - val_f1: 0.5104\n",
      "Epoch 59/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6394 - f1: 0.9921 - val_loss: 1.9432 - val_f1: 0.5230\n",
      "Epoch 60/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6246 - f1: 0.9921 - val_loss: 1.9318 - val_f1: 0.5195\n",
      "Epoch 61/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6165 - f1: 0.9857 - val_loss: 1.9283 - val_f1: 0.5169\n",
      "Epoch 62/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6022 - f1: 1.0000 - val_loss: 1.9269 - val_f1: 0.5134\n",
      "Epoch 63/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6218 - f1: 0.9921 - val_loss: 1.9068 - val_f1: 0.5200\n",
      "Epoch 64/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5928 - f1: 1.0000 - val_loss: 1.9008 - val_f1: 0.5322\n",
      "Epoch 65/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5647 - f1: 1.0000 - val_loss: 1.9135 - val_f1: 0.5228\n",
      "Epoch 66/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5693 - f1: 1.0000 - val_loss: 1.9239 - val_f1: 0.5179\n",
      "Epoch 67/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5589 - f1: 1.0000 - val_loss: 1.9046 - val_f1: 0.5307\n",
      "Epoch 68/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5577 - f1: 1.0000 - val_loss: 1.8941 - val_f1: 0.5292\n",
      "Epoch 69/2000\n",
      "50/50 [==============================] - 1s 14ms/sample - loss: 0.5473 - f1: 1.0000 - val_loss: 1.8823 - val_f1: 0.5328\n",
      "Running through fold 2\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 23ms/sample - loss: 4.8118 - f1: 0.0000e+00 - val_loss: 4.6542 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.6001 - f1: 0.0000e+00 - val_loss: 4.5184 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.4453 - f1: 0.0000e+00 - val_loss: 4.3968 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.2857 - f1: 0.0000e+00 - val_loss: 4.2522 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.1191 - f1: 0.0000e+00 - val_loss: 4.1058 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.9763 - f1: 0.0000e+00 - val_loss: 3.9561 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.7954 - f1: 0.0000e+00 - val_loss: 3.8034 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.6080 - f1: 0.0000e+00 - val_loss: 3.6486 - val_f1: 0.0077\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.4535 - f1: 0.0000e+00 - val_loss: 3.5042 - val_f1: 0.0546\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.2745 - f1: 0.0829 - val_loss: 3.3919 - val_f1: 0.0842\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.1095 - f1: 0.1115 - val_loss: 3.2693 - val_f1: 0.0900\n",
      "Epoch 12/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.9840 - f1: 0.1115 - val_loss: 3.1672 - val_f1: 0.0925\n",
      "Epoch 13/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.8337 - f1: 0.1115 - val_loss: 3.0750 - val_f1: 0.1059\n",
      "Epoch 14/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.7410 - f1: 0.1383 - val_loss: 2.9922 - val_f1: 0.1104\n",
      "Epoch 15/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.6302 - f1: 0.1637 - val_loss: 2.8839 - val_f1: 0.1250\n",
      "Epoch 16/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.4829 - f1: 0.1383 - val_loss: 2.7986 - val_f1: 0.1381\n",
      "Epoch 17/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.3848 - f1: 0.1878 - val_loss: 2.7313 - val_f1: 0.1619\n",
      "Epoch 18/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.2651 - f1: 0.2795 - val_loss: 2.6695 - val_f1: 0.2055\n",
      "Epoch 19/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.1672 - f1: 0.3381 - val_loss: 2.6151 - val_f1: 0.2248\n",
      "Epoch 20/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.0861 - f1: 0.4295 - val_loss: 2.5554 - val_f1: 0.2374\n",
      "Epoch 21/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.9850 - f1: 0.4199 - val_loss: 2.4994 - val_f1: 0.2572\n",
      "Epoch 22/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.8855 - f1: 0.4732 - val_loss: 2.4537 - val_f1: 0.2890\n",
      "Epoch 23/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.8132 - f1: 0.5358 - val_loss: 2.4171 - val_f1: 0.3044\n",
      "Epoch 24/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.7656 - f1: 0.5507 - val_loss: 2.3826 - val_f1: 0.3218\n",
      "Epoch 25/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.6819 - f1: 0.5966 - val_loss: 2.3339 - val_f1: 0.3389\n",
      "Epoch 26/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.5957 - f1: 0.6120 - val_loss: 2.2912 - val_f1: 0.3670\n",
      "Epoch 27/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.5399 - f1: 0.6682 - val_loss: 2.2587 - val_f1: 0.3772\n",
      "Epoch 28/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.5324 - f1: 0.6667 - val_loss: 2.2265 - val_f1: 0.3929\n",
      "Epoch 29/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.4271 - f1: 0.7469 - val_loss: 2.2030 - val_f1: 0.4174\n",
      "Epoch 30/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3691 - f1: 0.7059 - val_loss: 2.1739 - val_f1: 0.4300\n",
      "Epoch 31/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3386 - f1: 0.7600 - val_loss: 2.1528 - val_f1: 0.4450\n",
      "Epoch 32/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.3053 - f1: 0.7179 - val_loss: 2.1301 - val_f1: 0.4527\n",
      "Epoch 33/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.2479 - f1: 0.7646 - val_loss: 2.0992 - val_f1: 0.4562\n",
      "Epoch 34/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.2023 - f1: 0.8182 - val_loss: 2.0884 - val_f1: 0.4588\n",
      "Epoch 35/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1881 - f1: 0.7846 - val_loss: 2.0795 - val_f1: 0.4634\n",
      "Epoch 36/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1754 - f1: 0.7646 - val_loss: 2.0606 - val_f1: 0.4807\n",
      "Epoch 37/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.1254 - f1: 0.8179 - val_loss: 2.0546 - val_f1: 0.4826\n",
      "Epoch 38/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0926 - f1: 0.8182 - val_loss: 2.0028 - val_f1: 0.4835\n",
      "Epoch 39/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.0518 - f1: 0.8386 - val_loss: 1.9992 - val_f1: 0.4794\n",
      "Epoch 40/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0091 - f1: 0.8888 - val_loss: 1.9516 - val_f1: 0.5039\n",
      "Epoch 41/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9789 - f1: 0.9182 - val_loss: 1.9616 - val_f1: 0.5100\n",
      "Epoch 42/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.9770 - f1: 0.8725 - val_loss: 1.9284 - val_f1: 0.5201\n",
      "Epoch 43/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9437 - f1: 0.8858 - val_loss: 1.9274 - val_f1: 0.5156\n",
      "Epoch 44/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.9194 - f1: 0.9243 - val_loss: 1.8905 - val_f1: 0.5260\n",
      "Epoch 45/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8968 - f1: 0.9282 - val_loss: 1.8786 - val_f1: 0.5390\n",
      "Epoch 46/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8917 - f1: 0.9212 - val_loss: 1.8669 - val_f1: 0.5412\n",
      "Epoch 47/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8364 - f1: 0.9373 - val_loss: 1.8614 - val_f1: 0.5237\n",
      "Epoch 48/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8395 - f1: 0.9282 - val_loss: 1.8594 - val_f1: 0.5314\n",
      "Epoch 49/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8139 - f1: 0.9611 - val_loss: 1.8445 - val_f1: 0.5470\n",
      "Epoch 50/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7899 - f1: 0.9545 - val_loss: 1.8422 - val_f1: 0.5586\n",
      "Epoch 51/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7789 - f1: 0.9667 - val_loss: 1.8174 - val_f1: 0.5636\n",
      "Epoch 52/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7588 - f1: 0.9466 - val_loss: 1.8047 - val_f1: 0.5633\n",
      "Epoch 53/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7516 - f1: 0.9627 - val_loss: 1.7897 - val_f1: 0.5594\n",
      "Epoch 54/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7342 - f1: 0.9696 - val_loss: 1.7895 - val_f1: 0.5647\n",
      "Epoch 55/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7146 - f1: 0.9778 - val_loss: 1.8020 - val_f1: 0.5733\n",
      "Epoch 56/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6924 - f1: 0.9921 - val_loss: 1.7943 - val_f1: 0.5770\n",
      "Epoch 57/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6992 - f1: 0.9545 - val_loss: 1.7917 - val_f1: 0.5759\n",
      "Epoch 58/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6917 - f1: 0.9921 - val_loss: 1.7702 - val_f1: 0.5723\n",
      "Epoch 59/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6747 - f1: 0.9921 - val_loss: 1.7738 - val_f1: 0.5699\n",
      "Epoch 60/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6743 - f1: 0.9627 - val_loss: 1.7612 - val_f1: 0.5731\n",
      "Epoch 61/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6298 - f1: 0.9857 - val_loss: 1.7533 - val_f1: 0.5780\n",
      "Epoch 62/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6420 - f1: 0.9778 - val_loss: 1.7519 - val_f1: 0.5913\n",
      "Epoch 63/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6333 - f1: 0.9722 - val_loss: 1.7388 - val_f1: 0.5942\n",
      "Epoch 64/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6161 - f1: 0.9921 - val_loss: 1.7260 - val_f1: 0.5867\n",
      "Epoch 65/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5981 - f1: 0.9921 - val_loss: 1.7283 - val_f1: 0.5843\n",
      "Epoch 66/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5929 - f1: 1.0000 - val_loss: 1.7325 - val_f1: 0.5860\n",
      "Epoch 67/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5745 - f1: 0.9857 - val_loss: 1.7283 - val_f1: 0.5879\n",
      "Epoch 68/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5762 - f1: 0.9857 - val_loss: 1.7264 - val_f1: 0.5926\n",
      "Epoch 69/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5660 - f1: 1.0000 - val_loss: 1.7220 - val_f1: 0.5905\n",
      "Epoch 70/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5524 - f1: 1.0000 - val_loss: 1.7170 - val_f1: 0.5882\n",
      "Epoch 71/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5508 - f1: 1.0000 - val_loss: 1.6975 - val_f1: 0.5932\n",
      "Epoch 72/2000\n",
      "50/50 [==============================] - 1s 15ms/sample - loss: 0.5389 - f1: 1.0000 - val_loss: 1.6976 - val_f1: 0.5927\n",
      "Running through fold 3\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 25ms/sample - loss: 4.9896 - f1: 0.0000e+00 - val_loss: 4.7687 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 4.7058 - f1: 0.0000e+00 - val_loss: 4.6429 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.5648 - f1: 0.0000e+00 - val_loss: 4.5485 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 4.4682 - f1: 0.0000e+00 - val_loss: 4.4472 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 4.3231 - f1: 0.0000e+00 - val_loss: 4.3450 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 4.2198 - f1: 0.0000e+00 - val_loss: 4.2401 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 4.0877 - f1: 0.0000e+00 - val_loss: 4.1271 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.9404 - f1: 0.0000e+00 - val_loss: 4.0104 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7943 - f1: 0.0000e+00 - val_loss: 3.8997 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.6542 - f1: 0.0000e+00 - val_loss: 3.7924 - val_f1: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 1s 16ms/sample - loss: 3.4961 - f1: 0.0000e+00 - val_loss: 3.6959 - val_f1: 0.0000e+00\n",
      "Running through fold 4\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 26ms/sample - loss: 4.8323 - f1: 0.0000e+00 - val_loss: 4.6493 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 4.5939 - f1: 0.0000e+00 - val_loss: 4.5040 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 4.4347 - f1: 0.0000e+00 - val_loss: 4.3642 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 4.2498 - f1: 0.0000e+00 - val_loss: 4.2148 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 4.0623 - f1: 0.0000e+00 - val_loss: 4.0483 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.9039 - f1: 0.0000e+00 - val_loss: 3.9019 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7201 - f1: 0.0000e+00 - val_loss: 3.7638 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.5752 - f1: 0.0000e+00 - val_loss: 3.6445 - val_f1: 0.0161\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.4328 - f1: 0.0000e+00 - val_loss: 3.5316 - val_f1: 0.0719\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 3.3087 - f1: 0.1588 - val_loss: 3.4349 - val_f1: 0.0713\n",
      "Epoch 11/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.2057 - f1: 0.1303 - val_loss: 3.3510 - val_f1: 0.0807\n",
      "Epoch 12/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.0989 - f1: 0.1383 - val_loss: 3.2785 - val_f1: 0.0980\n",
      "Epoch 13/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.0137 - f1: 0.1732 - val_loss: 3.2069 - val_f1: 0.1056\n",
      "Epoch 14/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 2.9124 - f1: 0.1383 - val_loss: 3.1394 - val_f1: 0.1224\n",
      "Epoch 15/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 2.7635 - f1: 0.1637 - val_loss: 3.0673 - val_f1: 0.1253\n",
      "Epoch 16/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 2.7149 - f1: 0.1732 - val_loss: 3.0019 - val_f1: 0.1401\n",
      "Epoch 17/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 2.5869 - f1: 0.1637 - val_loss: 2.9372 - val_f1: 0.1506\n",
      "Epoch 18/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.5517 - f1: 0.1857 - val_loss: 2.8638 - val_f1: 0.1542\n",
      "Epoch 19/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 2.4266 - f1: 0.2111 - val_loss: 2.8119 - val_f1: 0.1604\n",
      "Epoch 20/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 2.3367 - f1: 0.2286 - val_loss: 2.7453 - val_f1: 0.1746\n",
      "Epoch 21/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.2756 - f1: 0.1878 - val_loss: 2.6873 - val_f1: 0.1745\n",
      "Epoch 22/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.2133 - f1: 0.1579 - val_loss: 2.6143 - val_f1: 0.1816\n",
      "Epoch 23/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 2.1005 - f1: 0.3008 - val_loss: 2.5967 - val_f1: 0.1926\n",
      "Epoch 24/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 2.0194 - f1: 0.3008 - val_loss: 2.5550 - val_f1: 0.1998\n",
      "Epoch 25/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.9575 - f1: 0.2000 - val_loss: 2.5164 - val_f1: 0.2050\n",
      "Epoch 26/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.9046 - f1: 0.3195 - val_loss: 2.4304 - val_f1: 0.2198\n",
      "Epoch 27/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.7958 - f1: 0.4295 - val_loss: 2.3732 - val_f1: 0.2567\n",
      "Epoch 28/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.7180 - f1: 0.4545 - val_loss: 2.3339 - val_f1: 0.3078\n",
      "Epoch 29/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.7031 - f1: 0.5010 - val_loss: 2.3267 - val_f1: 0.3256\n",
      "Epoch 30/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.5729 - f1: 0.6727 - val_loss: 2.3124 - val_f1: 0.3092\n",
      "Epoch 31/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.5343 - f1: 0.5689 - val_loss: 2.2554 - val_f1: 0.3089\n",
      "Epoch 32/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.4908 - f1: 0.5643 - val_loss: 2.2058 - val_f1: 0.3184\n",
      "Epoch 33/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.4137 - f1: 0.6400 - val_loss: 2.1853 - val_f1: 0.3498\n",
      "Epoch 34/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.3812 - f1: 0.6400 - val_loss: 2.1797 - val_f1: 0.3766\n",
      "Epoch 35/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.3181 - f1: 0.7600 - val_loss: 2.1859 - val_f1: 0.3872\n",
      "Epoch 36/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.2519 - f1: 0.8100 - val_loss: 2.1698 - val_f1: 0.4172\n",
      "Epoch 37/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.2328 - f1: 0.7975 - val_loss: 2.1378 - val_f1: 0.4418\n",
      "Epoch 38/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.1690 - f1: 0.8286 - val_loss: 2.1025 - val_f1: 0.4565\n",
      "Epoch 39/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.1286 - f1: 0.8276 - val_loss: 2.0922 - val_f1: 0.4623\n",
      "Epoch 40/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.0837 - f1: 0.8754 - val_loss: 2.0775 - val_f1: 0.4681\n",
      "Epoch 41/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.0567 - f1: 0.8770 - val_loss: 2.0524 - val_f1: 0.4763\n",
      "Epoch 42/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 1.0451 - f1: 0.9282 - val_loss: 2.0317 - val_f1: 0.4902\n",
      "Epoch 43/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 1.0033 - f1: 0.9433 - val_loss: 2.0163 - val_f1: 0.5034\n",
      "Epoch 44/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.9684 - f1: 0.9433 - val_loss: 2.0147 - val_f1: 0.5063\n",
      "Epoch 45/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.9440 - f1: 0.9524 - val_loss: 2.0093 - val_f1: 0.5110\n",
      "Epoch 46/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.9110 - f1: 0.9696 - val_loss: 1.9889 - val_f1: 0.5190\n",
      "Epoch 47/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8773 - f1: 0.9611 - val_loss: 1.9697 - val_f1: 0.5234\n",
      "Epoch 48/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.8617 - f1: 0.9545 - val_loss: 1.9495 - val_f1: 0.5295\n",
      "Epoch 49/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.8428 - f1: 0.9754 - val_loss: 1.9523 - val_f1: 0.5246\n",
      "Epoch 50/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.8111 - f1: 0.9778 - val_loss: 1.9452 - val_f1: 0.5262\n",
      "Epoch 51/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.8042 - f1: 0.9857 - val_loss: 1.9179 - val_f1: 0.5351\n",
      "Epoch 52/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.7719 - f1: 0.9921 - val_loss: 1.9094 - val_f1: 0.5420\n",
      "Epoch 53/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.7530 - f1: 0.9839 - val_loss: 1.9174 - val_f1: 0.5376\n",
      "Epoch 54/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.7409 - f1: 1.0000 - val_loss: 1.9199 - val_f1: 0.5384\n",
      "Epoch 55/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7400 - f1: 1.0000 - val_loss: 1.8983 - val_f1: 0.5430\n",
      "Epoch 56/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.7201 - f1: 1.0000 - val_loss: 1.8740 - val_f1: 0.5454\n",
      "Epoch 57/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.6954 - f1: 1.0000 - val_loss: 1.8583 - val_f1: 0.5513\n",
      "Epoch 58/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6947 - f1: 1.0000 - val_loss: 1.8546 - val_f1: 0.5598\n",
      "Epoch 59/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.6842 - f1: 1.0000 - val_loss: 1.8552 - val_f1: 0.5605\n",
      "Epoch 60/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6535 - f1: 1.0000 - val_loss: 1.8681 - val_f1: 0.5545\n",
      "Epoch 61/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6528 - f1: 1.0000 - val_loss: 1.8471 - val_f1: 0.5562\n",
      "Epoch 62/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6398 - f1: 1.0000 - val_loss: 1.8378 - val_f1: 0.5542\n",
      "Epoch 63/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.6195 - f1: 1.0000 - val_loss: 1.8244 - val_f1: 0.5564\n",
      "Epoch 64/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 0.6137 - f1: 1.0000 - val_loss: 1.8227 - val_f1: 0.5601\n",
      "Epoch 65/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6192 - f1: 1.0000 - val_loss: 1.8201 - val_f1: 0.5644\n",
      "Epoch 66/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.6031 - f1: 1.0000 - val_loss: 1.8167 - val_f1: 0.5593\n",
      "Epoch 67/2000\n",
      "50/50 [==============================] - 0s 5ms/sample - loss: 0.5922 - f1: 1.0000 - val_loss: 1.8059 - val_f1: 0.5627\n",
      "Epoch 68/2000\n",
      "50/50 [==============================] - 1s 17ms/sample - loss: 0.5784 - f1: 1.0000 - val_loss: 1.7964 - val_f1: 0.5642\n",
      "\n",
      "\n",
      "Running through training size 100\n",
      "Running through fold 0\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 1s 14ms/sample - loss: 4.7944 - f1: 0.0000e+00 - val_loss: 4.5354 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.4699 - f1: 0.0000e+00 - val_loss: 4.3411 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.2779 - f1: 0.0000e+00 - val_loss: 4.1390 - val_f1: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.0616 - f1: 0.0000e+00 - val_loss: 3.9408 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8112 - f1: 0.0000e+00 - val_loss: 3.7354 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.6137 - f1: 0.0000e+00 - val_loss: 3.5639 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.4739 - f1: 0.0000e+00 - val_loss: 3.4655 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.3376 - f1: 0.0000e+00 - val_loss: 3.2880 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.1524 - f1: 0.0000e+00 - val_loss: 3.1843 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.0146 - f1: 0.0000e+00 - val_loss: 3.0452 - val_f1: 0.0273\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.8843 - f1: 0.0429 - val_loss: 2.9440 - val_f1: 0.0625\n",
      "Epoch 12/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.7350 - f1: 0.1104 - val_loss: 2.7984 - val_f1: 0.0940\n",
      "Epoch 13/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.6236 - f1: 0.2541 - val_loss: 2.6825 - val_f1: 0.1458\n",
      "Epoch 14/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.4936 - f1: 0.1759 - val_loss: 2.5878 - val_f1: 0.1693\n",
      "Epoch 15/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.3590 - f1: 0.2759 - val_loss: 2.4505 - val_f1: 0.2034\n",
      "Epoch 16/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.2423 - f1: 0.3795 - val_loss: 2.3488 - val_f1: 0.2570\n",
      "Epoch 17/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.0782 - f1: 0.2912 - val_loss: 2.2441 - val_f1: 0.2945\n",
      "Epoch 18/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.9663 - f1: 0.3611 - val_loss: 2.1808 - val_f1: 0.3178\n",
      "Epoch 19/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.8974 - f1: 0.4823 - val_loss: 2.1238 - val_f1: 0.3446\n",
      "Epoch 20/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.8034 - f1: 0.3499 - val_loss: 2.0322 - val_f1: 0.3648\n",
      "Epoch 21/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6994 - f1: 0.6017 - val_loss: 1.9503 - val_f1: 0.4130\n",
      "Epoch 22/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6128 - f1: 0.5286 - val_loss: 1.8824 - val_f1: 0.4286\n",
      "Epoch 23/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.5376 - f1: 0.6141 - val_loss: 1.8516 - val_f1: 0.4559\n",
      "Epoch 24/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4791 - f1: 0.6101 - val_loss: 1.8090 - val_f1: 0.4917\n",
      "Epoch 25/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4481 - f1: 0.7686 - val_loss: 1.7301 - val_f1: 0.5478\n",
      "Epoch 26/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3531 - f1: 0.6401 - val_loss: 1.7109 - val_f1: 0.5784\n",
      "Epoch 27/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3370 - f1: 0.7329 - val_loss: 1.7006 - val_f1: 0.5824\n",
      "Epoch 28/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2711 - f1: 0.8163 - val_loss: 1.6389 - val_f1: 0.6154\n",
      "Epoch 29/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2179 - f1: 0.7007 - val_loss: 1.6180 - val_f1: 0.6197\n",
      "Epoch 30/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2322 - f1: 0.6953 - val_loss: 1.6442 - val_f1: 0.6031\n",
      "Epoch 31/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1936 - f1: 0.7996 - val_loss: 1.5909 - val_f1: 0.6182\n",
      "Epoch 32/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1275 - f1: 0.8733 - val_loss: 1.5275 - val_f1: 0.6380\n",
      "Epoch 33/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0984 - f1: 0.7954 - val_loss: 1.5059 - val_f1: 0.6538\n",
      "Epoch 34/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0390 - f1: 0.8087 - val_loss: 1.5200 - val_f1: 0.6580\n",
      "Epoch 35/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0588 - f1: 0.8499 - val_loss: 1.4893 - val_f1: 0.6580\n",
      "Epoch 36/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0134 - f1: 0.8937 - val_loss: 1.4952 - val_f1: 0.6573\n",
      "Epoch 37/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9998 - f1: 0.8371 - val_loss: 1.4328 - val_f1: 0.6868\n",
      "Epoch 38/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9705 - f1: 0.9185 - val_loss: 1.4264 - val_f1: 0.6846\n",
      "Epoch 39/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9368 - f1: 0.8874 - val_loss: 1.4039 - val_f1: 0.6797\n",
      "Epoch 40/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9273 - f1: 0.8732 - val_loss: 1.3836 - val_f1: 0.6927\n",
      "Epoch 41/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8769 - f1: 0.9217 - val_loss: 1.3975 - val_f1: 0.6946\n",
      "Epoch 42/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8793 - f1: 0.9013 - val_loss: 1.3734 - val_f1: 0.6942\n",
      "Epoch 43/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8348 - f1: 0.9369 - val_loss: 1.3949 - val_f1: 0.6717\n",
      "Epoch 44/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8232 - f1: 0.9274 - val_loss: 1.3517 - val_f1: 0.6885\n",
      "Epoch 45/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8057 - f1: 0.9321 - val_loss: 1.3366 - val_f1: 0.6937\n",
      "Epoch 46/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7825 - f1: 0.9414 - val_loss: 1.3102 - val_f1: 0.7020\n",
      "Epoch 47/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7497 - f1: 0.9138 - val_loss: 1.3100 - val_f1: 0.6937\n",
      "Epoch 48/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7572 - f1: 0.9505 - val_loss: 1.3073 - val_f1: 0.6977\n",
      "Epoch 49/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7505 - f1: 0.9185 - val_loss: 1.2778 - val_f1: 0.7159\n",
      "Epoch 50/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7450 - f1: 0.8835 - val_loss: 1.2958 - val_f1: 0.7212\n",
      "Epoch 51/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7081 - f1: 0.9359 - val_loss: 1.3324 - val_f1: 0.6912\n",
      "Epoch 52/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7179 - f1: 0.9585 - val_loss: 1.3413 - val_f1: 0.6807\n",
      "Epoch 53/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7027 - f1: 0.9546 - val_loss: 1.3070 - val_f1: 0.6947\n",
      "Epoch 54/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6853 - f1: 0.9542 - val_loss: 1.2829 - val_f1: 0.7005\n",
      "Epoch 55/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6613 - f1: 0.9672 - val_loss: 1.2542 - val_f1: 0.7109\n",
      "Epoch 56/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6358 - f1: 0.9754 - val_loss: 1.2521 - val_f1: 0.7128\n",
      "Epoch 57/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6231 - f1: 0.9483 - val_loss: 1.2798 - val_f1: 0.6995\n",
      "Epoch 58/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6161 - f1: 0.9877 - val_loss: 1.2583 - val_f1: 0.7039\n",
      "Epoch 59/2000\n",
      "100/100 [==============================] - 1s 10ms/sample - loss: 0.6056 - f1: 0.9837 - val_loss: 1.2416 - val_f1: 0.7147\n",
      "Running through fold 1\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 1s 15ms/sample - loss: 4.7843 - f1: 0.0000e+00 - val_loss: 4.5397 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.4635 - f1: 0.0000e+00 - val_loss: 4.3055 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.2127 - f1: 0.0000e+00 - val_loss: 4.1341 - val_f1: 0.0064\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.0194 - f1: 0.0446 - val_loss: 3.8837 - val_f1: 0.0039\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7490 - f1: 0.0000e+00 - val_loss: 3.7355 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.5811 - f1: 0.0000e+00 - val_loss: 3.5140 - val_f1: 0.0368\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.3349 - f1: 0.1446 - val_loss: 3.3196 - val_f1: 0.0501\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.0918 - f1: 0.1597 - val_loss: 3.1493 - val_f1: 0.0765\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.8994 - f1: 0.1009 - val_loss: 2.9873 - val_f1: 0.1029\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.7068 - f1: 0.1303 - val_loss: 2.8320 - val_f1: 0.1254\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.5580 - f1: 0.2723 - val_loss: 2.7116 - val_f1: 0.1613\n",
      "Epoch 12/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.3829 - f1: 0.3915 - val_loss: 2.5399 - val_f1: 0.1634\n",
      "Epoch 13/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.2088 - f1: 0.2008 - val_loss: 2.4257 - val_f1: 0.1833\n",
      "Epoch 14/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.0546 - f1: 0.3351 - val_loss: 2.3555 - val_f1: 0.2190\n",
      "Epoch 15/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.9891 - f1: 0.4814 - val_loss: 2.2509 - val_f1: 0.2767\n",
      "Epoch 16/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.8979 - f1: 0.5010 - val_loss: 2.1557 - val_f1: 0.3044\n",
      "Epoch 17/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.7707 - f1: 0.4777 - val_loss: 2.1429 - val_f1: 0.3204\n",
      "Epoch 18/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.7225 - f1: 0.4914 - val_loss: 2.0860 - val_f1: 0.3350\n",
      "Epoch 19/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6078 - f1: 0.5753 - val_loss: 2.0235 - val_f1: 0.3746\n",
      "Epoch 20/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.5272 - f1: 0.4467 - val_loss: 1.9993 - val_f1: 0.4001\n",
      "Epoch 21/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4799 - f1: 0.5778 - val_loss: 1.9709 - val_f1: 0.4551\n",
      "Epoch 22/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4121 - f1: 0.6849 - val_loss: 1.9427 - val_f1: 0.4985\n",
      "Epoch 23/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3561 - f1: 0.7089 - val_loss: 1.8846 - val_f1: 0.5192\n",
      "Epoch 24/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3188 - f1: 0.6601 - val_loss: 1.8333 - val_f1: 0.5255\n",
      "Epoch 25/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2436 - f1: 0.7059 - val_loss: 1.8145 - val_f1: 0.5112\n",
      "Epoch 26/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2440 - f1: 0.6568 - val_loss: 1.7636 - val_f1: 0.5285\n",
      "Epoch 27/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1257 - f1: 0.8663 - val_loss: 1.7799 - val_f1: 0.5387\n",
      "Epoch 28/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1358 - f1: 0.8144 - val_loss: 1.7079 - val_f1: 0.5697\n",
      "Epoch 29/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0644 - f1: 0.8142 - val_loss: 1.6790 - val_f1: 0.5712\n",
      "Epoch 30/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0497 - f1: 0.7471 - val_loss: 1.6985 - val_f1: 0.5737\n",
      "Epoch 31/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0056 - f1: 0.8543 - val_loss: 1.6872 - val_f1: 0.5731\n",
      "Epoch 32/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9797 - f1: 0.9080 - val_loss: 1.6504 - val_f1: 0.5954\n",
      "Epoch 33/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9489 - f1: 0.8298 - val_loss: 1.6103 - val_f1: 0.5979\n",
      "Epoch 34/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9392 - f1: 0.8779 - val_loss: 1.6206 - val_f1: 0.6086\n",
      "Epoch 35/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9100 - f1: 0.9080 - val_loss: 1.6291 - val_f1: 0.6110\n",
      "Epoch 36/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9027 - f1: 0.9234 - val_loss: 1.5998 - val_f1: 0.6217\n",
      "Epoch 37/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8389 - f1: 0.9314 - val_loss: 1.5663 - val_f1: 0.6212\n",
      "Epoch 38/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8160 - f1: 0.8961 - val_loss: 1.5306 - val_f1: 0.6399\n",
      "Epoch 39/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7802 - f1: 0.9673 - val_loss: 1.5176 - val_f1: 0.6430\n",
      "Epoch 40/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7716 - f1: 0.9591 - val_loss: 1.5454 - val_f1: 0.6253\n",
      "Epoch 41/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7526 - f1: 0.9588 - val_loss: 1.4994 - val_f1: 0.6456\n",
      "Epoch 42/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7269 - f1: 0.9546 - val_loss: 1.4698 - val_f1: 0.6542\n",
      "Epoch 43/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7163 - f1: 0.9630 - val_loss: 1.4473 - val_f1: 0.6578\n",
      "Epoch 44/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7079 - f1: 0.9716 - val_loss: 1.4353 - val_f1: 0.6735\n",
      "Epoch 45/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6667 - f1: 0.9357 - val_loss: 1.4467 - val_f1: 0.6646\n",
      "Epoch 46/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6773 - f1: 0.9593 - val_loss: 1.4600 - val_f1: 0.6478\n",
      "Epoch 47/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6810 - f1: 0.9320 - val_loss: 1.4387 - val_f1: 0.6549\n",
      "Epoch 48/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6605 - f1: 0.9721 - val_loss: 1.4244 - val_f1: 0.6637\n",
      "Epoch 49/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6465 - f1: 0.9670 - val_loss: 1.3710 - val_f1: 0.6778\n",
      "Epoch 50/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6184 - f1: 0.9881 - val_loss: 1.3946 - val_f1: 0.6732\n",
      "Epoch 51/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6192 - f1: 0.9880 - val_loss: 1.3999 - val_f1: 0.6806\n",
      "Epoch 52/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6141 - f1: 0.9840 - val_loss: 1.3910 - val_f1: 0.6825\n",
      "Epoch 53/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5972 - f1: 0.9840 - val_loss: 1.4240 - val_f1: 0.6566\n",
      "Epoch 54/2000\n",
      "100/100 [==============================] - 1s 10ms/sample - loss: 0.6139 - f1: 0.9680 - val_loss: 1.3655 - val_f1: 0.6804\n",
      "Running through fold 2\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 1s 15ms/sample - loss: 4.7659 - f1: 0.0000e+00 - val_loss: 4.5377 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.4675 - f1: 0.0000e+00 - val_loss: 4.2586 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.1779 - f1: 0.0000e+00 - val_loss: 4.0026 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.9118 - f1: 0.0000e+00 - val_loss: 3.7634 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.6998 - f1: 0.0000e+00 - val_loss: 3.5811 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.4820 - f1: 0.0000e+00 - val_loss: 3.3851 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.2734 - f1: 0.0000e+00 - val_loss: 3.2511 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.1465 - f1: 0.0000e+00 - val_loss: 3.0950 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.9769 - f1: 0.0152 - val_loss: 2.9604 - val_f1: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.8270 - f1: 0.0455 - val_loss: 2.8272 - val_f1: 0.0565\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.7066 - f1: 0.0580 - val_loss: 2.7209 - val_f1: 0.0791\n",
      "Epoch 12/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.5750 - f1: 0.0874 - val_loss: 2.5955 - val_f1: 0.1430\n",
      "Epoch 13/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.4331 - f1: 0.1667 - val_loss: 2.4981 - val_f1: 0.2112\n",
      "Epoch 14/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.3151 - f1: 0.2141 - val_loss: 2.3752 - val_f1: 0.2108\n",
      "Epoch 15/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.1777 - f1: 0.3540 - val_loss: 2.2514 - val_f1: 0.2568\n",
      "Epoch 16/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.0738 - f1: 0.2651 - val_loss: 2.1712 - val_f1: 0.2902\n",
      "Epoch 17/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.9671 - f1: 0.3749 - val_loss: 2.0872 - val_f1: 0.3189\n",
      "Epoch 18/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.8685 - f1: 0.5177 - val_loss: 2.0042 - val_f1: 0.3302\n",
      "Epoch 19/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.7492 - f1: 0.5205 - val_loss: 1.9220 - val_f1: 0.3443\n",
      "Epoch 20/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6843 - f1: 0.4635 - val_loss: 1.8471 - val_f1: 0.3812\n",
      "Epoch 21/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6042 - f1: 0.4798 - val_loss: 1.7859 - val_f1: 0.4342\n",
      "Epoch 22/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.5388 - f1: 0.5601 - val_loss: 1.7534 - val_f1: 0.4545\n",
      "Epoch 23/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4513 - f1: 0.5819 - val_loss: 1.7008 - val_f1: 0.4920\n",
      "Epoch 24/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3895 - f1: 0.6688 - val_loss: 1.6512 - val_f1: 0.5117\n",
      "Epoch 25/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3564 - f1: 0.7185 - val_loss: 1.6258 - val_f1: 0.5233\n",
      "Epoch 26/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2888 - f1: 0.7799 - val_loss: 1.5520 - val_f1: 0.5742\n",
      "Epoch 27/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2196 - f1: 0.5624 - val_loss: 1.5320 - val_f1: 0.5892\n",
      "Epoch 28/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1969 - f1: 0.8194 - val_loss: 1.5183 - val_f1: 0.6285\n",
      "Epoch 29/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1644 - f1: 0.8372 - val_loss: 1.4768 - val_f1: 0.6367\n",
      "Epoch 30/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0904 - f1: 0.8464 - val_loss: 1.4304 - val_f1: 0.6533\n",
      "Epoch 31/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0587 - f1: 0.8773 - val_loss: 1.3874 - val_f1: 0.6600\n",
      "Epoch 32/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0054 - f1: 0.8559 - val_loss: 1.3564 - val_f1: 0.6688\n",
      "Epoch 33/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9792 - f1: 0.7666 - val_loss: 1.3353 - val_f1: 0.6939\n",
      "Epoch 34/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9778 - f1: 0.8672 - val_loss: 1.3527 - val_f1: 0.6899\n",
      "Epoch 35/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9481 - f1: 0.7678 - val_loss: 1.3026 - val_f1: 0.7125\n",
      "Epoch 36/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9360 - f1: 0.8570 - val_loss: 1.3786 - val_f1: 0.6685\n",
      "Epoch 37/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9415 - f1: 0.9264 - val_loss: 1.3160 - val_f1: 0.6926\n",
      "Epoch 38/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9199 - f1: 0.9185 - val_loss: 1.2830 - val_f1: 0.7205\n",
      "Epoch 39/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8820 - f1: 0.9258 - val_loss: 1.2618 - val_f1: 0.7255\n",
      "Epoch 40/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8295 - f1: 0.9403 - val_loss: 1.2299 - val_f1: 0.7459\n",
      "Epoch 41/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8049 - f1: 0.8709 - val_loss: 1.2224 - val_f1: 0.7379\n",
      "Epoch 42/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7939 - f1: 0.9410 - val_loss: 1.2080 - val_f1: 0.7445\n",
      "Epoch 43/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7896 - f1: 0.9487 - val_loss: 1.1839 - val_f1: 0.7574\n",
      "Epoch 44/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7655 - f1: 0.8961 - val_loss: 1.1700 - val_f1: 0.7599\n",
      "Epoch 45/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7441 - f1: 0.9411 - val_loss: 1.1557 - val_f1: 0.7648\n",
      "Epoch 46/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7507 - f1: 0.9092 - val_loss: 1.1514 - val_f1: 0.7635\n",
      "Epoch 47/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7162 - f1: 0.9546 - val_loss: 1.1408 - val_f1: 0.7608\n",
      "Epoch 48/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6980 - f1: 0.9553 - val_loss: 1.1300 - val_f1: 0.7619\n",
      "Epoch 49/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6890 - f1: 0.9631 - val_loss: 1.1046 - val_f1: 0.7717\n",
      "Epoch 50/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6742 - f1: 0.9316 - val_loss: 1.0996 - val_f1: 0.7765\n",
      "Epoch 51/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6523 - f1: 0.9710 - val_loss: 1.0923 - val_f1: 0.7788\n",
      "Epoch 52/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6559 - f1: 0.9716 - val_loss: 1.0816 - val_f1: 0.7676\n",
      "Epoch 53/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6494 - f1: 0.9365 - val_loss: 1.0615 - val_f1: 0.7735\n",
      "Epoch 54/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6291 - f1: 0.9716 - val_loss: 1.0561 - val_f1: 0.7828\n",
      "Epoch 55/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6204 - f1: 0.9397 - val_loss: 1.0523 - val_f1: 0.7769\n",
      "Epoch 56/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6124 - f1: 0.9757 - val_loss: 1.0759 - val_f1: 0.7611\n",
      "Epoch 57/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5996 - f1: 0.9800 - val_loss: 1.0751 - val_f1: 0.7662\n",
      "Epoch 58/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5832 - f1: 0.9714 - val_loss: 1.0497 - val_f1: 0.7785\n",
      "Epoch 59/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5707 - f1: 0.9753 - val_loss: 1.0306 - val_f1: 0.7869\n",
      "Epoch 60/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5579 - f1: 0.9840 - val_loss: 1.0182 - val_f1: 0.7816\n",
      "Epoch 61/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5661 - f1: 0.9442 - val_loss: 1.0379 - val_f1: 0.7675\n",
      "Epoch 62/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5484 - f1: 0.9839 - val_loss: 1.0276 - val_f1: 0.7814\n",
      "Epoch 63/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5506 - f1: 0.9839 - val_loss: 1.0219 - val_f1: 0.7815\n",
      "Epoch 64/2000\n",
      "100/100 [==============================] - 1s 11ms/sample - loss: 0.5254 - f1: 0.9960 - val_loss: 1.0241 - val_f1: 0.7780\n",
      "Running through fold 3\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 2s 16ms/sample - loss: 4.8491 - f1: 0.0000e+00 - val_loss: 4.5849 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.5399 - f1: 0.0000e+00 - val_loss: 4.4007 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.3423 - f1: 0.0000e+00 - val_loss: 4.2229 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.1357 - f1: 0.0000e+00 - val_loss: 4.0267 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8988 - f1: 0.0000e+00 - val_loss: 3.8276 - val_f1: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.6897 - f1: 0.0000e+00 - val_loss: 3.6396 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.5203 - f1: 0.0000e+00 - val_loss: 3.4737 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.3380 - f1: 0.0000e+00 - val_loss: 3.3821 - val_f1: 0.0090\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.2059 - f1: 0.0152 - val_loss: 3.2255 - val_f1: 0.0475\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.0780 - f1: 0.0429 - val_loss: 3.1293 - val_f1: 0.0914\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.9604 - f1: 0.1017 - val_loss: 2.9651 - val_f1: 0.1133\n",
      "Epoch 12/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.7598 - f1: 0.1001 - val_loss: 2.8849 - val_f1: 0.0782\n",
      "Epoch 13/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.6767 - f1: 0.1017 - val_loss: 2.7972 - val_f1: 0.1132\n",
      "Epoch 14/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.5785 - f1: 0.2009 - val_loss: 2.6976 - val_f1: 0.1272\n",
      "Epoch 15/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.4543 - f1: 0.2121 - val_loss: 2.5835 - val_f1: 0.1751\n",
      "Epoch 16/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.3162 - f1: 0.1707 - val_loss: 2.5016 - val_f1: 0.2214\n",
      "Epoch 17/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.2306 - f1: 0.3676 - val_loss: 2.4317 - val_f1: 0.2343\n",
      "Epoch 18/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.1334 - f1: 0.3074 - val_loss: 2.3360 - val_f1: 0.2852\n",
      "Epoch 19/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.9971 - f1: 0.4837 - val_loss: 2.2869 - val_f1: 0.3192\n",
      "Epoch 20/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.9229 - f1: 0.5488 - val_loss: 2.2055 - val_f1: 0.3677\n",
      "Epoch 21/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.8506 - f1: 0.5653 - val_loss: 2.1674 - val_f1: 0.3774\n",
      "Epoch 22/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.7693 - f1: 0.6141 - val_loss: 2.0635 - val_f1: 0.4020\n",
      "Epoch 23/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6753 - f1: 0.6230 - val_loss: 2.0165 - val_f1: 0.4359\n",
      "Epoch 24/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6147 - f1: 0.6844 - val_loss: 1.9712 - val_f1: 0.4467\n",
      "Epoch 25/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.5466 - f1: 0.6522 - val_loss: 1.9399 - val_f1: 0.4644\n",
      "Epoch 26/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4850 - f1: 0.5961 - val_loss: 1.8996 - val_f1: 0.4689\n",
      "Epoch 27/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4152 - f1: 0.6852 - val_loss: 1.8494 - val_f1: 0.4749\n",
      "Epoch 28/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3828 - f1: 0.7312 - val_loss: 1.8077 - val_f1: 0.5169\n",
      "Epoch 29/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3314 - f1: 0.5556 - val_loss: 1.8203 - val_f1: 0.5004\n",
      "Epoch 30/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3262 - f1: 0.7431 - val_loss: 1.8430 - val_f1: 0.5215\n",
      "Epoch 31/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2833 - f1: 0.7828 - val_loss: 1.7517 - val_f1: 0.5590\n",
      "Epoch 32/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2311 - f1: 0.7503 - val_loss: 1.7243 - val_f1: 0.5531\n",
      "Epoch 33/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1645 - f1: 0.7824 - val_loss: 1.6933 - val_f1: 0.5665\n",
      "Epoch 34/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1465 - f1: 0.7572 - val_loss: 1.6833 - val_f1: 0.5813\n",
      "Epoch 35/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0915 - f1: 0.7776 - val_loss: 1.6420 - val_f1: 0.5967\n",
      "Epoch 36/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0764 - f1: 0.7215 - val_loss: 1.6234 - val_f1: 0.5901\n",
      "Epoch 37/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0633 - f1: 0.8624 - val_loss: 1.6059 - val_f1: 0.6083\n",
      "Epoch 38/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0100 - f1: 0.8053 - val_loss: 1.5895 - val_f1: 0.6224\n",
      "Epoch 39/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9970 - f1: 0.8687 - val_loss: 1.5913 - val_f1: 0.6255\n",
      "Epoch 40/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9701 - f1: 0.8836 - val_loss: 1.5721 - val_f1: 0.6436\n",
      "Epoch 41/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9274 - f1: 0.8582 - val_loss: 1.5314 - val_f1: 0.6452\n",
      "Epoch 42/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9096 - f1: 0.8959 - val_loss: 1.5150 - val_f1: 0.6551\n",
      "Epoch 43/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8828 - f1: 0.9415 - val_loss: 1.5148 - val_f1: 0.6534\n",
      "Epoch 44/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8599 - f1: 0.9371 - val_loss: 1.4789 - val_f1: 0.6589\n",
      "Epoch 45/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8592 - f1: 0.9535 - val_loss: 1.4627 - val_f1: 0.6660\n",
      "Epoch 46/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8375 - f1: 0.9148 - val_loss: 1.4533 - val_f1: 0.6758\n",
      "Epoch 47/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8095 - f1: 0.8596 - val_loss: 1.4503 - val_f1: 0.6761\n",
      "Epoch 48/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8033 - f1: 0.9538 - val_loss: 1.4091 - val_f1: 0.6941\n",
      "Epoch 49/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8070 - f1: 0.9236 - val_loss: 1.4317 - val_f1: 0.6882\n",
      "Epoch 50/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7915 - f1: 0.9115 - val_loss: 1.4178 - val_f1: 0.6947\n",
      "Epoch 51/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7684 - f1: 0.8762 - val_loss: 1.4380 - val_f1: 0.6865\n",
      "Epoch 52/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7553 - f1: 0.9627 - val_loss: 1.4443 - val_f1: 0.6805\n",
      "Epoch 53/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7516 - f1: 0.9714 - val_loss: 1.4270 - val_f1: 0.6828\n",
      "Epoch 54/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7529 - f1: 0.9591 - val_loss: 1.4425 - val_f1: 0.6873\n",
      "Epoch 55/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7328 - f1: 0.9716 - val_loss: 1.4540 - val_f1: 0.6830\n",
      "Epoch 56/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7261 - f1: 0.9363 - val_loss: 1.4433 - val_f1: 0.6892\n",
      "Epoch 57/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7031 - f1: 0.9714 - val_loss: 1.4341 - val_f1: 0.6904\n",
      "Epoch 58/2000\n",
      "100/100 [==============================] - 1s 12ms/sample - loss: 0.6796 - f1: 0.9837 - val_loss: 1.4038 - val_f1: 0.6953\n",
      "Running through fold 4\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 2s 17ms/sample - loss: 4.7883 - f1: 0.0000e+00 - val_loss: 4.5412 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.4859 - f1: 0.0000e+00 - val_loss: 4.3632 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 4.2899 - f1: 0.0000e+00 - val_loss: 4.1661 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 4.0896 - f1: 0.0000e+00 - val_loss: 3.9597 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8615 - f1: 0.0000e+00 - val_loss: 3.7478 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.6413 - f1: 0.0000e+00 - val_loss: 3.5554 - val_f1: 0.0098\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.4837 - f1: 0.0000e+00 - val_loss: 3.3844 - val_f1: 0.0739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.2717 - f1: 0.0882 - val_loss: 3.2289 - val_f1: 0.1147\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.0883 - f1: 0.1136 - val_loss: 3.0473 - val_f1: 0.1145\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.8931 - f1: 0.1136 - val_loss: 2.9155 - val_f1: 0.1208\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.7578 - f1: 0.2398 - val_loss: 2.8225 - val_f1: 0.1443\n",
      "Epoch 12/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.6532 - f1: 0.2383 - val_loss: 2.6385 - val_f1: 0.1553\n",
      "Epoch 13/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.4325 - f1: 0.1889 - val_loss: 2.4843 - val_f1: 0.1803\n",
      "Epoch 14/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.2881 - f1: 0.3129 - val_loss: 2.3786 - val_f1: 0.1956\n",
      "Epoch 15/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.1974 - f1: 0.2907 - val_loss: 2.2950 - val_f1: 0.2343\n",
      "Epoch 16/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 2.0916 - f1: 0.4120 - val_loss: 2.1724 - val_f1: 0.2936\n",
      "Epoch 17/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.9558 - f1: 0.3377 - val_loss: 2.0702 - val_f1: 0.3437\n",
      "Epoch 18/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.8382 - f1: 0.4833 - val_loss: 2.0229 - val_f1: 0.4052\n",
      "Epoch 19/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.7591 - f1: 0.5523 - val_loss: 1.9697 - val_f1: 0.4205\n",
      "Epoch 20/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.7057 - f1: 0.5375 - val_loss: 1.9024 - val_f1: 0.4531\n",
      "Epoch 21/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.6103 - f1: 0.6593 - val_loss: 1.8352 - val_f1: 0.4770\n",
      "Epoch 22/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.5451 - f1: 0.6149 - val_loss: 1.7824 - val_f1: 0.4914\n",
      "Epoch 23/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4903 - f1: 0.7726 - val_loss: 1.7402 - val_f1: 0.5320\n",
      "Epoch 24/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.4472 - f1: 0.7658 - val_loss: 1.6838 - val_f1: 0.5610\n",
      "Epoch 25/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3948 - f1: 0.7446 - val_loss: 1.6276 - val_f1: 0.5940\n",
      "Epoch 26/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.3338 - f1: 0.7987 - val_loss: 1.5956 - val_f1: 0.6146\n",
      "Epoch 27/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2713 - f1: 0.7961 - val_loss: 1.5678 - val_f1: 0.6153\n",
      "Epoch 28/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2543 - f1: 0.8147 - val_loss: 1.5593 - val_f1: 0.6217\n",
      "Epoch 29/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.2146 - f1: 0.7973 - val_loss: 1.5188 - val_f1: 0.6529\n",
      "Epoch 30/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1532 - f1: 0.7739 - val_loss: 1.5032 - val_f1: 0.6481\n",
      "Epoch 31/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1269 - f1: 0.8559 - val_loss: 1.4661 - val_f1: 0.6625\n",
      "Epoch 32/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.1185 - f1: 0.8487 - val_loss: 1.4499 - val_f1: 0.6827\n",
      "Epoch 33/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0825 - f1: 0.8523 - val_loss: 1.4377 - val_f1: 0.6982\n",
      "Epoch 34/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0611 - f1: 0.7902 - val_loss: 1.4239 - val_f1: 0.6861\n",
      "Epoch 35/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 1.0431 - f1: 0.8913 - val_loss: 1.3889 - val_f1: 0.7022\n",
      "Epoch 36/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9968 - f1: 0.8163 - val_loss: 1.3891 - val_f1: 0.6839\n",
      "Epoch 37/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9665 - f1: 0.8787 - val_loss: 1.3627 - val_f1: 0.6886\n",
      "Epoch 38/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9551 - f1: 0.8645 - val_loss: 1.3436 - val_f1: 0.7063\n",
      "Epoch 39/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9410 - f1: 0.8415 - val_loss: 1.3539 - val_f1: 0.7027\n",
      "Epoch 40/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9174 - f1: 0.8558 - val_loss: 1.3998 - val_f1: 0.6820\n",
      "Epoch 41/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9307 - f1: 0.8533 - val_loss: 1.3652 - val_f1: 0.6957\n",
      "Epoch 42/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.9035 - f1: 0.8100 - val_loss: 1.3364 - val_f1: 0.7110\n",
      "Epoch 43/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8657 - f1: 0.9206 - val_loss: 1.3013 - val_f1: 0.7220\n",
      "Epoch 44/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8502 - f1: 0.9277 - val_loss: 1.2977 - val_f1: 0.7107\n",
      "Epoch 45/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8293 - f1: 0.8545 - val_loss: 1.3054 - val_f1: 0.7051\n",
      "Epoch 46/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.8386 - f1: 0.7526 - val_loss: 1.3133 - val_f1: 0.7018\n",
      "Epoch 47/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7983 - f1: 0.9066 - val_loss: 1.3078 - val_f1: 0.7176\n",
      "Epoch 48/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7760 - f1: 0.9231 - val_loss: 1.3006 - val_f1: 0.7232\n",
      "Epoch 49/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7759 - f1: 0.8578 - val_loss: 1.2537 - val_f1: 0.7474\n",
      "Epoch 50/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7567 - f1: 0.9148 - val_loss: 1.2938 - val_f1: 0.7174\n",
      "Epoch 51/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7636 - f1: 0.9218 - val_loss: 1.2854 - val_f1: 0.7321\n",
      "Epoch 52/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7223 - f1: 0.9510 - val_loss: 1.2424 - val_f1: 0.7373\n",
      "Epoch 53/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.7115 - f1: 0.9595 - val_loss: 1.2296 - val_f1: 0.7342\n",
      "Epoch 54/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6940 - f1: 0.9093 - val_loss: 1.2007 - val_f1: 0.7411\n",
      "Epoch 55/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6858 - f1: 0.9676 - val_loss: 1.1923 - val_f1: 0.7446\n",
      "Epoch 56/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6857 - f1: 0.9549 - val_loss: 1.1590 - val_f1: 0.7544\n",
      "Epoch 57/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6498 - f1: 0.9675 - val_loss: 1.1390 - val_f1: 0.7646\n",
      "Epoch 58/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6336 - f1: 0.9761 - val_loss: 1.1302 - val_f1: 0.7666\n",
      "Epoch 59/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6115 - f1: 0.9796 - val_loss: 1.1257 - val_f1: 0.7671\n",
      "Epoch 60/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6140 - f1: 0.9283 - val_loss: 1.1307 - val_f1: 0.7602\n",
      "Epoch 61/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5978 - f1: 0.9720 - val_loss: 1.1355 - val_f1: 0.7571\n",
      "Epoch 62/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.6020 - f1: 0.9599 - val_loss: 1.1271 - val_f1: 0.7630\n",
      "Epoch 63/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5977 - f1: 0.9759 - val_loss: 1.1022 - val_f1: 0.7680\n",
      "Epoch 64/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5738 - f1: 0.9881 - val_loss: 1.0917 - val_f1: 0.7716\n",
      "Epoch 65/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5665 - f1: 0.9880 - val_loss: 1.0885 - val_f1: 0.7704\n",
      "Epoch 66/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 0.5634 - f1: 0.9802 - val_loss: 1.0803 - val_f1: 0.7646\n",
      "Epoch 67/2000\n",
      "100/100 [==============================] - 1s 13ms/sample - loss: 0.5482 - f1: 0.9841 - val_loss: 1.0901 - val_f1: 0.7656\n",
      "\n",
      "\n",
      "Running through training size 500\n",
      "Running through fold 0\n",
      "Train on 500 samples, validate on 3000 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 4.3512 - f1: 0.0000e+00 - val_loss: 3.6989 - val_f1: 0.0197\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 806us/sample - loss: 3.2833 - f1: 0.0322 - val_loss: 2.7585 - val_f1: 0.1487\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 2.4894 - f1: 0.2073 - val_loss: 2.1273 - val_f1: 0.2490\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 818us/sample - loss: 1.9168 - f1: 0.4148 - val_loss: 1.6975 - val_f1: 0.4985\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 803us/sample - loss: 1.5632 - f1: 0.5981 - val_loss: 1.4179 - val_f1: 0.6943\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 805us/sample - loss: 1.3285 - f1: 0.7106 - val_loss: 1.2426 - val_f1: 0.7325\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 801us/sample - loss: 1.1711 - f1: 0.7592 - val_loss: 1.1516 - val_f1: 0.7621\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 808us/sample - loss: 1.0379 - f1: 0.8222 - val_loss: 1.0410 - val_f1: 0.8125\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 806us/sample - loss: 0.9580 - f1: 0.8518 - val_loss: 0.9535 - val_f1: 0.8412\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 810us/sample - loss: 0.8739 - f1: 0.8732 - val_loss: 0.8759 - val_f1: 0.8701\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 0.8321 - f1: 0.8800 - val_loss: 0.8185 - val_f1: 0.8833\n",
      "Epoch 12/2000\n",
      "500/500 [==============================] - 0s 805us/sample - loss: 0.7757 - f1: 0.8992 - val_loss: 0.7963 - val_f1: 0.8850\n",
      "Epoch 13/2000\n",
      "500/500 [==============================] - 0s 807us/sample - loss: 0.7114 - f1: 0.9212 - val_loss: 0.7569 - val_f1: 0.8891\n",
      "Epoch 14/2000\n",
      "500/500 [==============================] - 0s 802us/sample - loss: 0.6792 - f1: 0.9144 - val_loss: 0.7181 - val_f1: 0.8905\n",
      "Epoch 15/2000\n",
      "500/500 [==============================] - 0s 820us/sample - loss: 0.6639 - f1: 0.9132 - val_loss: 0.7020 - val_f1: 0.8922\n",
      "Epoch 16/2000\n",
      "500/500 [==============================] - 0s 809us/sample - loss: 0.6402 - f1: 0.9215 - val_loss: 0.6806 - val_f1: 0.8992\n",
      "Epoch 17/2000\n",
      "500/500 [==============================] - 0s 804us/sample - loss: 0.6079 - f1: 0.9301 - val_loss: 0.6345 - val_f1: 0.9046\n",
      "Epoch 18/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 0.5681 - f1: 0.9381 - val_loss: 0.6176 - val_f1: 0.9014\n",
      "Epoch 19/2000\n",
      "500/500 [==============================] - 0s 804us/sample - loss: 0.5462 - f1: 0.9372 - val_loss: 0.6365 - val_f1: 0.8953\n",
      "Epoch 20/2000\n",
      "500/500 [==============================] - 0s 818us/sample - loss: 0.5343 - f1: 0.9326 - val_loss: 0.5969 - val_f1: 0.9059\n",
      "Epoch 21/2000\n",
      "500/500 [==============================] - 0s 808us/sample - loss: 0.5059 - f1: 0.9486 - val_loss: 0.5729 - val_f1: 0.9130\n",
      "Epoch 22/2000\n",
      "500/500 [==============================] - 0s 806us/sample - loss: 0.4940 - f1: 0.9367 - val_loss: 0.5657 - val_f1: 0.9090\n",
      "Epoch 23/2000\n",
      "500/500 [==============================] - 0s 804us/sample - loss: 0.5046 - f1: 0.9424 - val_loss: 0.5841 - val_f1: 0.9018\n",
      "Epoch 24/2000\n",
      "500/500 [==============================] - 0s 809us/sample - loss: 0.4832 - f1: 0.9362 - val_loss: 0.5436 - val_f1: 0.9128\n",
      "Epoch 25/2000\n",
      "500/500 [==============================] - 0s 804us/sample - loss: 0.4573 - f1: 0.9524 - val_loss: 0.5276 - val_f1: 0.9160\n",
      "Epoch 26/2000\n",
      "500/500 [==============================] - 0s 805us/sample - loss: 0.4304 - f1: 0.9562 - val_loss: 0.5296 - val_f1: 0.9085\n",
      "Epoch 27/2000\n",
      "500/500 [==============================] - 0s 805us/sample - loss: 0.4166 - f1: 0.9627 - val_loss: 0.4992 - val_f1: 0.9121\n",
      "Epoch 28/2000\n",
      "500/500 [==============================] - 0s 810us/sample - loss: 0.4260 - f1: 0.9581 - val_loss: 0.5249 - val_f1: 0.9139\n",
      "Epoch 29/2000\n",
      "500/500 [==============================] - 0s 813us/sample - loss: 0.4049 - f1: 0.9586 - val_loss: 0.4987 - val_f1: 0.9135\n",
      "Epoch 30/2000\n",
      "500/500 [==============================] - 0s 814us/sample - loss: 0.3990 - f1: 0.9630 - val_loss: 0.4915 - val_f1: 0.9145\n",
      "Epoch 31/2000\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 0.4079 - f1: 0.9541 - val_loss: 0.5377 - val_f1: 0.8979\n",
      "Running through fold 1\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 4.3419 - f1: 0.0000e+00 - val_loss: 3.6335 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 815us/sample - loss: 3.2434 - f1: 0.0074 - val_loss: 2.7646 - val_f1: 0.1109\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 813us/sample - loss: 2.4749 - f1: 0.1678 - val_loss: 2.1234 - val_f1: 0.2250\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 815us/sample - loss: 1.9057 - f1: 0.3224 - val_loss: 1.6792 - val_f1: 0.4838\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 818us/sample - loss: 1.5174 - f1: 0.6222 - val_loss: 1.4227 - val_f1: 0.6854\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 813us/sample - loss: 1.3169 - f1: 0.7251 - val_loss: 1.2484 - val_f1: 0.7390\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 1.1611 - f1: 0.7723 - val_loss: 1.1375 - val_f1: 0.7711\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 814us/sample - loss: 1.0564 - f1: 0.7922 - val_loss: 1.0394 - val_f1: 0.8049\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 815us/sample - loss: 0.9769 - f1: 0.8387 - val_loss: 0.9599 - val_f1: 0.8327\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 0.9042 - f1: 0.8469 - val_loss: 0.9327 - val_f1: 0.8412\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 0.8535 - f1: 0.8677 - val_loss: 0.8713 - val_f1: 0.8563\n",
      "Epoch 12/2000\n",
      "500/500 [==============================] - 0s 813us/sample - loss: 0.7819 - f1: 0.8869 - val_loss: 0.8216 - val_f1: 0.8669\n",
      "Epoch 13/2000\n",
      "500/500 [==============================] - 0s 817us/sample - loss: 0.7307 - f1: 0.8895 - val_loss: 0.7811 - val_f1: 0.8740\n",
      "Epoch 14/2000\n",
      "500/500 [==============================] - 0s 815us/sample - loss: 0.7048 - f1: 0.8961 - val_loss: 0.7581 - val_f1: 0.8737\n",
      "Epoch 15/2000\n",
      "500/500 [==============================] - 0s 813us/sample - loss: 0.6816 - f1: 0.9072 - val_loss: 0.7215 - val_f1: 0.8774\n",
      "Epoch 16/2000\n",
      "500/500 [==============================] - 0s 818us/sample - loss: 0.6385 - f1: 0.9120 - val_loss: 0.6954 - val_f1: 0.8875\n",
      "Epoch 17/2000\n",
      "500/500 [==============================] - 0s 811us/sample - loss: 0.6251 - f1: 0.9124 - val_loss: 0.6728 - val_f1: 0.8929\n",
      "Epoch 18/2000\n",
      "500/500 [==============================] - 0s 809us/sample - loss: 0.6012 - f1: 0.9158 - val_loss: 0.6957 - val_f1: 0.8793\n",
      "Epoch 19/2000\n",
      "500/500 [==============================] - 0s 806us/sample - loss: 0.5818 - f1: 0.9207 - val_loss: 0.6609 - val_f1: 0.8869\n",
      "Epoch 20/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 0.5696 - f1: 0.9339 - val_loss: 0.6181 - val_f1: 0.9062\n",
      "Epoch 21/2000\n",
      "500/500 [==============================] - 0s 814us/sample - loss: 0.5515 - f1: 0.9329 - val_loss: 0.6456 - val_f1: 0.8880\n",
      "Epoch 22/2000\n",
      "500/500 [==============================] - 0s 813us/sample - loss: 0.5211 - f1: 0.9388 - val_loss: 0.5780 - val_f1: 0.9054\n",
      "Epoch 23/2000\n",
      "500/500 [==============================] - 0s 815us/sample - loss: 0.4972 - f1: 0.9352 - val_loss: 0.5841 - val_f1: 0.8971\n",
      "Epoch 24/2000\n",
      "500/500 [==============================] - 0s 820us/sample - loss: 0.4902 - f1: 0.9367 - val_loss: 0.5698 - val_f1: 0.9022\n",
      "Epoch 25/2000\n",
      "500/500 [==============================] - 0s 830us/sample - loss: 0.4833 - f1: 0.9376 - val_loss: 0.5559 - val_f1: 0.9053\n",
      "Epoch 26/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 0.4894 - f1: 0.9374 - val_loss: 0.5681 - val_f1: 0.9001\n",
      "Epoch 27/2000\n",
      "500/500 [==============================] - 0s 809us/sample - loss: 0.4983 - f1: 0.9309 - val_loss: 0.5610 - val_f1: 0.9062\n",
      "Epoch 28/2000\n",
      "500/500 [==============================] - 0s 810us/sample - loss: 0.4740 - f1: 0.9484 - val_loss: 0.5766 - val_f1: 0.8913\n",
      "Epoch 29/2000\n",
      "500/500 [==============================] - 0s 808us/sample - loss: 0.4646 - f1: 0.9340 - val_loss: 0.5184 - val_f1: 0.9164\n",
      "Epoch 30/2000\n",
      "500/500 [==============================] - 0s 813us/sample - loss: 0.4531 - f1: 0.9404 - val_loss: 0.5505 - val_f1: 0.9043\n",
      "Epoch 31/2000\n",
      "500/500 [==============================] - 0s 814us/sample - loss: 0.4412 - f1: 0.9512 - val_loss: 0.5450 - val_f1: 0.9060\n",
      "Epoch 32/2000\n",
      "500/500 [==============================] - 0s 812us/sample - loss: 0.4206 - f1: 0.9539 - val_loss: 0.4914 - val_f1: 0.9200\n",
      "Epoch 33/2000\n",
      "500/500 [==============================] - 0s 809us/sample - loss: 0.4032 - f1: 0.9571 - val_loss: 0.4981 - val_f1: 0.9186\n",
      "Epoch 34/2000\n",
      "500/500 [==============================] - 0s 808us/sample - loss: 0.3980 - f1: 0.9618 - val_loss: 0.5080 - val_f1: 0.9063\n",
      "Epoch 35/2000\n",
      "500/500 [==============================] - 0s 815us/sample - loss: 0.3909 - f1: 0.9597 - val_loss: 0.4872 - val_f1: 0.9155\n",
      "Epoch 36/2000\n",
      "500/500 [==============================] - 0s 814us/sample - loss: 0.3767 - f1: 0.9594 - val_loss: 0.4946 - val_f1: 0.9018\n",
      "Epoch 37/2000\n",
      "500/500 [==============================] - 0s 814us/sample - loss: 0.3682 - f1: 0.9557 - val_loss: 0.4894 - val_f1: 0.9090\n",
      "Epoch 38/2000\n",
      "500/500 [==============================] - 0s 811us/sample - loss: 0.3690 - f1: 0.9619 - val_loss: 0.4920 - val_f1: 0.9109\n",
      "Epoch 39/2000\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 0.3774 - f1: 0.9531 - val_loss: 0.4740 - val_f1: 0.9174\n",
      "Running through fold 2\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 4.3105 - f1: 0.0038 - val_loss: 3.6635 - val_f1: 0.0628\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 818us/sample - loss: 3.3732 - f1: 0.0408 - val_loss: 2.9493 - val_f1: 0.1043\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 824us/sample - loss: 2.6578 - f1: 0.1273 - val_loss: 2.3089 - val_f1: 0.1413\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 822us/sample - loss: 2.0656 - f1: 0.3078 - val_loss: 1.8211 - val_f1: 0.4106\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 823us/sample - loss: 1.6584 - f1: 0.5277 - val_loss: 1.5252 - val_f1: 0.6222\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 821us/sample - loss: 1.3991 - f1: 0.6846 - val_loss: 1.3141 - val_f1: 0.7224\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 822us/sample - loss: 1.2105 - f1: 0.7720 - val_loss: 1.1855 - val_f1: 0.7533\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 824us/sample - loss: 1.0795 - f1: 0.8164 - val_loss: 1.0752 - val_f1: 0.8110\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 815us/sample - loss: 0.9681 - f1: 0.8511 - val_loss: 0.9727 - val_f1: 0.8327\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 826us/sample - loss: 0.8947 - f1: 0.8722 - val_loss: 0.9195 - val_f1: 0.8416\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 0s 824us/sample - loss: 0.8318 - f1: 0.8799 - val_loss: 0.8561 - val_f1: 0.8614\n",
      "Epoch 12/2000\n",
      "500/500 [==============================] - 0s 819us/sample - loss: 0.7845 - f1: 0.8907 - val_loss: 0.8308 - val_f1: 0.8717\n",
      "Epoch 13/2000\n",
      "500/500 [==============================] - 0s 819us/sample - loss: 0.7369 - f1: 0.8973 - val_loss: 0.8249 - val_f1: 0.8652\n",
      "Epoch 14/2000\n",
      "500/500 [==============================] - 0s 814us/sample - loss: 0.7046 - f1: 0.9197 - val_loss: 0.7598 - val_f1: 0.8763\n",
      "Epoch 15/2000\n",
      "500/500 [==============================] - 0s 824us/sample - loss: 0.6658 - f1: 0.9150 - val_loss: 0.7169 - val_f1: 0.8838\n",
      "Epoch 16/2000\n",
      "500/500 [==============================] - 0s 823us/sample - loss: 0.6292 - f1: 0.9208 - val_loss: 0.7307 - val_f1: 0.8810\n",
      "Epoch 17/2000\n",
      "500/500 [==============================] - 0s 823us/sample - loss: 0.6294 - f1: 0.9158 - val_loss: 0.6947 - val_f1: 0.8819\n",
      "Epoch 18/2000\n",
      "500/500 [==============================] - 0s 821us/sample - loss: 0.5954 - f1: 0.9233 - val_loss: 0.6564 - val_f1: 0.8997\n",
      "Epoch 19/2000\n",
      "500/500 [==============================] - 0s 819us/sample - loss: 0.5828 - f1: 0.9369 - val_loss: 0.6355 - val_f1: 0.8998\n",
      "Epoch 20/2000\n",
      "500/500 [==============================] - 0s 832us/sample - loss: 0.5505 - f1: 0.9286 - val_loss: 0.6313 - val_f1: 0.8943\n",
      "Epoch 21/2000\n",
      "500/500 [==============================] - 0s 817us/sample - loss: 0.5397 - f1: 0.9235 - val_loss: 0.6306 - val_f1: 0.8911\n",
      "Epoch 22/2000\n",
      "500/500 [==============================] - 0s 820us/sample - loss: 0.5063 - f1: 0.9403 - val_loss: 0.5999 - val_f1: 0.8995\n",
      "Epoch 23/2000\n",
      "500/500 [==============================] - 0s 818us/sample - loss: 0.4918 - f1: 0.9422 - val_loss: 0.5903 - val_f1: 0.8973\n",
      "Epoch 24/2000\n",
      "500/500 [==============================] - 0s 816us/sample - loss: 0.5018 - f1: 0.9382 - val_loss: 0.5921 - val_f1: 0.8993\n",
      "Epoch 25/2000\n",
      "500/500 [==============================] - 0s 821us/sample - loss: 0.4708 - f1: 0.9512 - val_loss: 0.5503 - val_f1: 0.9137\n",
      "Epoch 26/2000\n",
      "500/500 [==============================] - 0s 817us/sample - loss: 0.4560 - f1: 0.9503 - val_loss: 0.5396 - val_f1: 0.9105\n",
      "Epoch 27/2000\n",
      "500/500 [==============================] - 0s 817us/sample - loss: 0.4241 - f1: 0.9510 - val_loss: 0.5125 - val_f1: 0.9154\n",
      "Epoch 28/2000\n",
      "500/500 [==============================] - 0s 821us/sample - loss: 0.4296 - f1: 0.9516 - val_loss: 0.5290 - val_f1: 0.9127\n",
      "Epoch 29/2000\n",
      "500/500 [==============================] - 0s 813us/sample - loss: 0.4107 - f1: 0.9610 - val_loss: 0.4956 - val_f1: 0.9185\n",
      "Epoch 30/2000\n",
      "500/500 [==============================] - 0s 821us/sample - loss: 0.4083 - f1: 0.9537 - val_loss: 0.5178 - val_f1: 0.8936\n",
      "Epoch 31/2000\n",
      "500/500 [==============================] - 0s 817us/sample - loss: 0.4109 - f1: 0.9492 - val_loss: 0.5147 - val_f1: 0.9043\n",
      "Epoch 32/2000\n",
      "500/500 [==============================] - 0s 819us/sample - loss: 0.3960 - f1: 0.9581 - val_loss: 0.4842 - val_f1: 0.9225\n",
      "Epoch 33/2000\n",
      "500/500 [==============================] - 0s 825us/sample - loss: 0.3908 - f1: 0.9567 - val_loss: 0.4871 - val_f1: 0.9152\n",
      "Epoch 34/2000\n",
      "500/500 [==============================] - 0s 817us/sample - loss: 0.3748 - f1: 0.9623 - val_loss: 0.4636 - val_f1: 0.9219\n",
      "Epoch 35/2000\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 0.3659 - f1: 0.9634 - val_loss: 0.4752 - val_f1: 0.9212\n",
      "Running through fold 3\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 4.3548 - f1: 0.0000e+00 - val_loss: 3.6928 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 829us/sample - loss: 3.1950 - f1: 0.0400 - val_loss: 2.6098 - val_f1: 0.0957\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 830us/sample - loss: 2.3060 - f1: 0.1885 - val_loss: 1.9960 - val_f1: 0.2687\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 828us/sample - loss: 1.8215 - f1: 0.4132 - val_loss: 1.6129 - val_f1: 0.5337\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 826us/sample - loss: 1.5294 - f1: 0.5974 - val_loss: 1.3898 - val_f1: 0.6830\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 828us/sample - loss: 1.3209 - f1: 0.7031 - val_loss: 1.2597 - val_f1: 0.7083\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 822us/sample - loss: 1.1890 - f1: 0.7589 - val_loss: 1.1560 - val_f1: 0.7428\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 827us/sample - loss: 1.0845 - f1: 0.7892 - val_loss: 1.0906 - val_f1: 0.7691\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 824us/sample - loss: 1.0401 - f1: 0.7961 - val_loss: 1.0025 - val_f1: 0.8049\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 827us/sample - loss: 0.9478 - f1: 0.8242 - val_loss: 0.9320 - val_f1: 0.8158\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 0s 821us/sample - loss: 0.8808 - f1: 0.8399 - val_loss: 0.8525 - val_f1: 0.8500\n",
      "Epoch 12/2000\n",
      "500/500 [==============================] - 0s 821us/sample - loss: 0.8449 - f1: 0.8439 - val_loss: 0.8221 - val_f1: 0.8663\n",
      "Epoch 13/2000\n",
      "500/500 [==============================] - 0s 828us/sample - loss: 0.7665 - f1: 0.8792 - val_loss: 0.7843 - val_f1: 0.8668\n",
      "Epoch 14/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 822us/sample - loss: 0.7278 - f1: 0.8826 - val_loss: 0.7526 - val_f1: 0.8790\n",
      "Epoch 15/2000\n",
      "500/500 [==============================] - 0s 829us/sample - loss: 0.6786 - f1: 0.9030 - val_loss: 0.7033 - val_f1: 0.8895\n",
      "Epoch 16/2000\n",
      "500/500 [==============================] - 0s 838us/sample - loss: 0.6401 - f1: 0.9250 - val_loss: 0.6628 - val_f1: 0.8989\n",
      "Epoch 17/2000\n",
      "500/500 [==============================] - 0s 828us/sample - loss: 0.6249 - f1: 0.9209 - val_loss: 0.6374 - val_f1: 0.9074\n",
      "Epoch 18/2000\n",
      "500/500 [==============================] - 0s 823us/sample - loss: 0.6032 - f1: 0.9183 - val_loss: 0.6205 - val_f1: 0.9070\n",
      "Epoch 19/2000\n",
      "500/500 [==============================] - 0s 823us/sample - loss: 0.5765 - f1: 0.9236 - val_loss: 0.6285 - val_f1: 0.9033\n",
      "Epoch 20/2000\n",
      "500/500 [==============================] - 0s 829us/sample - loss: 0.5544 - f1: 0.9226 - val_loss: 0.5878 - val_f1: 0.9164\n",
      "Epoch 21/2000\n",
      "500/500 [==============================] - 0s 835us/sample - loss: 0.5430 - f1: 0.9182 - val_loss: 0.5819 - val_f1: 0.9096\n",
      "Epoch 22/2000\n",
      "500/500 [==============================] - 0s 819us/sample - loss: 0.5213 - f1: 0.9385 - val_loss: 0.5763 - val_f1: 0.9026\n",
      "Epoch 23/2000\n",
      "500/500 [==============================] - 0s 828us/sample - loss: 0.5200 - f1: 0.9285 - val_loss: 0.5361 - val_f1: 0.9292\n",
      "Epoch 24/2000\n",
      "500/500 [==============================] - 0s 818us/sample - loss: 0.4801 - f1: 0.9471 - val_loss: 0.5416 - val_f1: 0.9158\n",
      "Epoch 25/2000\n",
      "500/500 [==============================] - 0s 818us/sample - loss: 0.4715 - f1: 0.9526 - val_loss: 0.5423 - val_f1: 0.9098\n",
      "Epoch 26/2000\n",
      "500/500 [==============================] - 0s 827us/sample - loss: 0.4758 - f1: 0.9340 - val_loss: 0.5474 - val_f1: 0.9079\n",
      "Epoch 27/2000\n",
      "500/500 [==============================] - 0s 823us/sample - loss: 0.4432 - f1: 0.9469 - val_loss: 0.4919 - val_f1: 0.9299\n",
      "Epoch 28/2000\n",
      "500/500 [==============================] - 0s 819us/sample - loss: 0.4201 - f1: 0.9565 - val_loss: 0.4882 - val_f1: 0.9262\n",
      "Epoch 29/2000\n",
      "500/500 [==============================] - 0s 824us/sample - loss: 0.4066 - f1: 0.9591 - val_loss: 0.4689 - val_f1: 0.9317\n",
      "Epoch 30/2000\n",
      "500/500 [==============================] - 0s 822us/sample - loss: 0.3869 - f1: 0.9618 - val_loss: 0.4551 - val_f1: 0.9364\n",
      "Epoch 31/2000\n",
      "500/500 [==============================] - 0s 823us/sample - loss: 0.3835 - f1: 0.9617 - val_loss: 0.4705 - val_f1: 0.9288\n",
      "Epoch 32/2000\n",
      "500/500 [==============================] - 0s 825us/sample - loss: 0.3958 - f1: 0.9619 - val_loss: 0.4516 - val_f1: 0.9340\n",
      "Epoch 33/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 0.3840 - f1: 0.9625 - val_loss: 0.4705 - val_f1: 0.9275\n",
      "Running through fold 4\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 4.3549 - f1: 0.0000e+00 - val_loss: 3.7396 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 832us/sample - loss: 3.4359 - f1: 0.0152 - val_loss: 3.0257 - val_f1: 0.0565\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 844us/sample - loss: 2.7584 - f1: 0.1210 - val_loss: 2.3937 - val_f1: 0.1626\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 836us/sample - loss: 2.2171 - f1: 0.2455 - val_loss: 1.9712 - val_f1: 0.2884\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 829us/sample - loss: 1.8104 - f1: 0.3918 - val_loss: 1.6654 - val_f1: 0.5020\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 830us/sample - loss: 1.5235 - f1: 0.5631 - val_loss: 1.3867 - val_f1: 0.6716\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 835us/sample - loss: 1.3265 - f1: 0.6838 - val_loss: 1.2258 - val_f1: 0.7331\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 831us/sample - loss: 1.1802 - f1: 0.7298 - val_loss: 1.1318 - val_f1: 0.7712\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 826us/sample - loss: 1.0445 - f1: 0.8101 - val_loss: 1.0966 - val_f1: 0.7722\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 826us/sample - loss: 0.9756 - f1: 0.8190 - val_loss: 0.9494 - val_f1: 0.8381\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 0s 829us/sample - loss: 0.8786 - f1: 0.8494 - val_loss: 0.8951 - val_f1: 0.8474\n",
      "Epoch 12/2000\n",
      "500/500 [==============================] - 0s 829us/sample - loss: 0.8229 - f1: 0.8650 - val_loss: 0.8502 - val_f1: 0.8612\n",
      "Epoch 13/2000\n",
      "500/500 [==============================] - 0s 837us/sample - loss: 0.7639 - f1: 0.8828 - val_loss: 0.7847 - val_f1: 0.8818\n",
      "Epoch 14/2000\n",
      "500/500 [==============================] - 0s 828us/sample - loss: 0.7237 - f1: 0.8992 - val_loss: 0.7623 - val_f1: 0.8755\n",
      "Epoch 15/2000\n",
      "500/500 [==============================] - 0s 823us/sample - loss: 0.6969 - f1: 0.9029 - val_loss: 0.7442 - val_f1: 0.8844\n",
      "Epoch 16/2000\n",
      "500/500 [==============================] - 0s 824us/sample - loss: 0.6824 - f1: 0.9045 - val_loss: 0.7065 - val_f1: 0.8877\n",
      "Epoch 17/2000\n",
      "500/500 [==============================] - 0s 829us/sample - loss: 0.6263 - f1: 0.9178 - val_loss: 0.6979 - val_f1: 0.8845\n",
      "Epoch 18/2000\n",
      "500/500 [==============================] - 0s 832us/sample - loss: 0.5942 - f1: 0.9365 - val_loss: 0.6471 - val_f1: 0.8970\n",
      "Epoch 19/2000\n",
      "500/500 [==============================] - 0s 830us/sample - loss: 0.5686 - f1: 0.9290 - val_loss: 0.6346 - val_f1: 0.8954\n",
      "Epoch 20/2000\n",
      "500/500 [==============================] - 0s 829us/sample - loss: 0.5463 - f1: 0.9323 - val_loss: 0.6367 - val_f1: 0.8832\n",
      "Epoch 21/2000\n",
      "500/500 [==============================] - 0s 826us/sample - loss: 0.5548 - f1: 0.9247 - val_loss: 0.6744 - val_f1: 0.8750\n",
      "Epoch 22/2000\n",
      "500/500 [==============================] - 0s 835us/sample - loss: 0.5362 - f1: 0.9380 - val_loss: 0.6085 - val_f1: 0.8951\n",
      "Epoch 23/2000\n",
      "500/500 [==============================] - 0s 828us/sample - loss: 0.5296 - f1: 0.9320 - val_loss: 0.6113 - val_f1: 0.8877\n",
      "Epoch 24/2000\n",
      "500/500 [==============================] - 0s 819us/sample - loss: 0.5030 - f1: 0.9411 - val_loss: 0.5684 - val_f1: 0.9050\n",
      "Epoch 25/2000\n",
      "500/500 [==============================] - 0s 834us/sample - loss: 0.4805 - f1: 0.9470 - val_loss: 0.5463 - val_f1: 0.9121\n",
      "Epoch 26/2000\n",
      "500/500 [==============================] - 0s 828us/sample - loss: 0.4605 - f1: 0.9496 - val_loss: 0.5705 - val_f1: 0.8954\n",
      "Epoch 27/2000\n",
      "500/500 [==============================] - 0s 826us/sample - loss: 0.4644 - f1: 0.9484 - val_loss: 0.5405 - val_f1: 0.9054\n",
      "Epoch 28/2000\n",
      "500/500 [==============================] - 0s 828us/sample - loss: 0.4417 - f1: 0.9547 - val_loss: 0.5238 - val_f1: 0.9094\n",
      "Epoch 29/2000\n",
      "500/500 [==============================] - 0s 822us/sample - loss: 0.4346 - f1: 0.9564 - val_loss: 0.5218 - val_f1: 0.9074\n",
      "Epoch 30/2000\n",
      "500/500 [==============================] - 0s 826us/sample - loss: 0.4188 - f1: 0.9546 - val_loss: 0.5370 - val_f1: 0.8996\n",
      "Epoch 31/2000\n",
      "500/500 [==============================] - 0s 828us/sample - loss: 0.4168 - f1: 0.9584 - val_loss: 0.5221 - val_f1: 0.9073\n",
      "Epoch 32/2000\n",
      "500/500 [==============================] - 0s 821us/sample - loss: 0.4173 - f1: 0.9670 - val_loss: 0.4966 - val_f1: 0.9175\n",
      "Epoch 33/2000\n",
      "500/500 [==============================] - 0s 832us/sample - loss: 0.4405 - f1: 0.9372 - val_loss: 0.5439 - val_f1: 0.8955\n",
      "Epoch 34/2000\n",
      "500/500 [==============================] - 0s 827us/sample - loss: 0.4260 - f1: 0.9549 - val_loss: 0.5453 - val_f1: 0.9058\n",
      "Epoch 35/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 0.4319 - f1: 0.9466 - val_loss: 0.5079 - val_f1: 0.9047\n",
      "\n",
      "\n",
      "Running through training size 1000\n",
      "Running through fold 0\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 3.9854 - f1: 0.0000e+00 - val_loss: 3.2401 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 2.8497 - f1: 0.0776 - val_loss: 2.3774 - val_f1: 0.2073\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.9859 - f1: 0.3314 - val_loss: 1.6797 - val_f1: 0.4828\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 1.4322 - f1: 0.6492 - val_loss: 1.2417 - val_f1: 0.7280\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 1.1172 - f1: 0.7872 - val_loss: 1.0297 - val_f1: 0.8189\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.9227 - f1: 0.8672 - val_loss: 0.8860 - val_f1: 0.8690\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.8355 - f1: 0.8876 - val_loss: 0.8222 - val_f1: 0.8734\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.7519 - f1: 0.8970 - val_loss: 0.7673 - val_f1: 0.8695\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.7273 - f1: 0.8872 - val_loss: 0.7063 - val_f1: 0.8865\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.6723 - f1: 0.9057 - val_loss: 0.6660 - val_f1: 0.8981\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.6081 - f1: 0.9128 - val_loss: 0.6622 - val_f1: 0.8812\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.5768 - f1: 0.9191 - val_loss: 0.6062 - val_f1: 0.8906\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.5444 - f1: 0.9108 - val_loss: 0.5706 - val_f1: 0.8979\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.5275 - f1: 0.9227 - val_loss: 0.5477 - val_f1: 0.9057\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.5397 - f1: 0.9053 - val_loss: 0.5590 - val_f1: 0.9003\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.5225 - f1: 0.9223 - val_loss: 0.5751 - val_f1: 0.8974\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.4734 - f1: 0.9298 - val_loss: 0.4926 - val_f1: 0.9143\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.4394 - f1: 0.9270 - val_loss: 0.4824 - val_f1: 0.9076\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.4447 - f1: 0.9288 - val_loss: 0.4790 - val_f1: 0.9106\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 521us/sample - loss: 0.4377 - f1: 0.9230 - val_loss: 0.4644 - val_f1: 0.9134\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.4293 - f1: 0.9281 - val_loss: 0.4840 - val_f1: 0.9088\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.4111 - f1: 0.9326 - val_loss: 0.5315 - val_f1: 0.8870\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 516us/sample - loss: 0.4066 - f1: 0.9295 - val_loss: 0.4602 - val_f1: 0.9061\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.4040 - f1: 0.9343 - val_loss: 0.4837 - val_f1: 0.9085\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.3904 - f1: 0.9357 - val_loss: 0.4920 - val_f1: 0.8968\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.3960 - f1: 0.9334 - val_loss: 0.4724 - val_f1: 0.8959\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.3718 - f1: 0.9429 - val_loss: 0.4098 - val_f1: 0.9207\n",
      "Running through fold 1\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 3.9701 - f1: 0.0074 - val_loss: 3.2394 - val_f1: 0.0629\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 545us/sample - loss: 2.7175 - f1: 0.1394 - val_loss: 2.1960 - val_f1: 0.2367\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 1.8388 - f1: 0.4099 - val_loss: 1.5650 - val_f1: 0.5756\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 1.3625 - f1: 0.6738 - val_loss: 1.2170 - val_f1: 0.7283\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 1.1075 - f1: 0.7837 - val_loss: 1.0397 - val_f1: 0.8171\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.9350 - f1: 0.8476 - val_loss: 0.8868 - val_f1: 0.8540\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.8243 - f1: 0.8790 - val_loss: 0.7946 - val_f1: 0.8756\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.7486 - f1: 0.8862 - val_loss: 0.7419 - val_f1: 0.8862\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 521us/sample - loss: 0.7118 - f1: 0.8934 - val_loss: 0.7508 - val_f1: 0.8673\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.6711 - f1: 0.8956 - val_loss: 0.6800 - val_f1: 0.8824\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.5998 - f1: 0.9156 - val_loss: 0.6569 - val_f1: 0.8839\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.5856 - f1: 0.9077 - val_loss: 0.6306 - val_f1: 0.8895\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.5506 - f1: 0.9120 - val_loss: 0.5598 - val_f1: 0.9033\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 521us/sample - loss: 0.5245 - f1: 0.9161 - val_loss: 0.5658 - val_f1: 0.8950\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.5062 - f1: 0.9190 - val_loss: 0.5282 - val_f1: 0.9003\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.4827 - f1: 0.9164 - val_loss: 0.5590 - val_f1: 0.8889\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.4894 - f1: 0.9223 - val_loss: 0.5400 - val_f1: 0.8966\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.4650 - f1: 0.9264 - val_loss: 0.5296 - val_f1: 0.8949\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.4417 - f1: 0.9273 - val_loss: 0.5277 - val_f1: 0.8947\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.4803 - f1: 0.9095 - val_loss: 0.5123 - val_f1: 0.9066\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 521us/sample - loss: 0.4447 - f1: 0.9221 - val_loss: 0.5046 - val_f1: 0.9093\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.4276 - f1: 0.9296 - val_loss: 0.5302 - val_f1: 0.8962\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.4196 - f1: 0.9350 - val_loss: 0.4428 - val_f1: 0.9147\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.3896 - f1: 0.9321 - val_loss: 0.4641 - val_f1: 0.9041\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.3848 - f1: 0.9412 - val_loss: 0.4823 - val_f1: 0.8929\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.3835 - f1: 0.9345 - val_loss: 0.4433 - val_f1: 0.9158\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.3847 - f1: 0.9402 - val_loss: 0.4245 - val_f1: 0.9153\n",
      "Epoch 28/2000\n",
      "1000/1000 [==============================] - 1s 521us/sample - loss: 0.3511 - f1: 0.9426 - val_loss: 0.4906 - val_f1: 0.8937\n",
      "Epoch 29/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.3896 - f1: 0.9294 - val_loss: 0.4337 - val_f1: 0.9134\n",
      "Epoch 30/2000\n",
      "1000/1000 [==============================] - 1s 521us/sample - loss: 0.3427 - f1: 0.9514 - val_loss: 0.3988 - val_f1: 0.9239\n",
      "Epoch 31/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.3221 - f1: 0.9541 - val_loss: 0.3968 - val_f1: 0.9207\n",
      "Epoch 32/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.3330 - f1: 0.9446 - val_loss: 0.3850 - val_f1: 0.9265\n",
      "Epoch 33/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.3396 - f1: 0.9513 - val_loss: 0.3915 - val_f1: 0.9199\n",
      "Epoch 34/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.3247 - f1: 0.9535 - val_loss: 0.3930 - val_f1: 0.9251\n",
      "Epoch 35/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.3367 - f1: 0.9501 - val_loss: 0.3789 - val_f1: 0.9287\n",
      "Epoch 36/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.3187 - f1: 0.9594 - val_loss: 0.3929 - val_f1: 0.9197\n",
      "Epoch 37/2000\n",
      "1000/1000 [==============================] - 1s 521us/sample - loss: 0.3138 - f1: 0.9600 - val_loss: 0.4348 - val_f1: 0.9167\n",
      "Epoch 38/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.3348 - f1: 0.9522 - val_loss: 0.4228 - val_f1: 0.9197\n",
      "Epoch 39/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.3328 - f1: 0.9509 - val_loss: 0.3844 - val_f1: 0.9252\n",
      "Epoch 40/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.3566 - f1: 0.9435 - val_loss: 0.3827 - val_f1: 0.9358\n",
      "Epoch 41/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.3320 - f1: 0.9516 - val_loss: 0.4334 - val_f1: 0.9043\n",
      "Epoch 42/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.3043 - f1: 0.9654 - val_loss: 0.3578 - val_f1: 0.9322\n",
      "Running through fold 2\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 3.9260 - f1: 0.0057 - val_loss: 3.0713 - val_f1: 0.0122\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 554us/sample - loss: 2.5308 - f1: 0.1503 - val_loss: 1.9727 - val_f1: 0.2993\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 550us/sample - loss: 1.6678 - f1: 0.4664 - val_loss: 1.3999 - val_f1: 0.6004\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 553us/sample - loss: 1.2424 - f1: 0.7110 - val_loss: 1.1099 - val_f1: 0.7788\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 543us/sample - loss: 1.0121 - f1: 0.8256 - val_loss: 0.9563 - val_f1: 0.8293\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.8828 - f1: 0.8544 - val_loss: 0.8388 - val_f1: 0.8665\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.7953 - f1: 0.8742 - val_loss: 0.8050 - val_f1: 0.8566\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.7213 - f1: 0.8880 - val_loss: 0.7368 - val_f1: 0.8633\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.6747 - f1: 0.8897 - val_loss: 0.6600 - val_f1: 0.8876\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 0.6325 - f1: 0.9030 - val_loss: 0.6299 - val_f1: 0.8916\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.5900 - f1: 0.9076 - val_loss: 0.5806 - val_f1: 0.9017\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.5609 - f1: 0.9092 - val_loss: 0.5641 - val_f1: 0.9000\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.5357 - f1: 0.9147 - val_loss: 0.5308 - val_f1: 0.9100\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.4972 - f1: 0.9241 - val_loss: 0.5448 - val_f1: 0.8909\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.4766 - f1: 0.9270 - val_loss: 0.4937 - val_f1: 0.9087\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.4600 - f1: 0.9241 - val_loss: 0.4874 - val_f1: 0.9066\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.4441 - f1: 0.9280 - val_loss: 0.4660 - val_f1: 0.9190\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 0.4458 - f1: 0.9318 - val_loss: 0.4757 - val_f1: 0.9188\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.4238 - f1: 0.9406 - val_loss: 0.4184 - val_f1: 0.9333\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.4033 - f1: 0.9381 - val_loss: 0.5232 - val_f1: 0.9043\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 0.4264 - f1: 0.9273 - val_loss: 0.4569 - val_f1: 0.9173\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.4024 - f1: 0.9408 - val_loss: 0.4232 - val_f1: 0.9253\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.3824 - f1: 0.9397 - val_loss: 0.4213 - val_f1: 0.9176\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 517us/sample - loss: 0.3606 - f1: 0.9513 - val_loss: 0.4364 - val_f1: 0.9227\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 518us/sample - loss: 0.3546 - f1: 0.9437 - val_loss: 0.4265 - val_f1: 0.9110\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.3329 - f1: 0.9565 - val_loss: 0.3737 - val_f1: 0.9298\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 1s 516us/sample - loss: 0.3198 - f1: 0.9551 - val_loss: 0.3864 - val_f1: 0.9346\n",
      "Epoch 28/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.4003 - f1: 0.9327 - val_loss: 0.4427 - val_f1: 0.9189\n",
      "Epoch 29/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.3789 - f1: 0.9353 - val_loss: 0.4081 - val_f1: 0.9349\n",
      "Running through fold 3\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 3.9920 - f1: 0.0095 - val_loss: 3.1668 - val_f1: 0.0102\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 2.6902 - f1: 0.0874 - val_loss: 2.1413 - val_f1: 0.2271\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.7951 - f1: 0.3943 - val_loss: 1.5104 - val_f1: 0.6022\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.3449 - f1: 0.6749 - val_loss: 1.1679 - val_f1: 0.7532\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.0653 - f1: 0.7934 - val_loss: 0.9808 - val_f1: 0.8193\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 0.9092 - f1: 0.8429 - val_loss: 0.8904 - val_f1: 0.8289\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.8351 - f1: 0.8660 - val_loss: 0.8068 - val_f1: 0.8699\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.7432 - f1: 0.8803 - val_loss: 0.7031 - val_f1: 0.8867\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.6827 - f1: 0.8914 - val_loss: 0.6611 - val_f1: 0.8830\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 519us/sample - loss: 0.6291 - f1: 0.8965 - val_loss: 0.6140 - val_f1: 0.8963\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.6008 - f1: 0.9047 - val_loss: 0.6013 - val_f1: 0.8912\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 520us/sample - loss: 0.5531 - f1: 0.9181 - val_loss: 0.5561 - val_f1: 0.9041\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.5336 - f1: 0.9085 - val_loss: 0.5519 - val_f1: 0.9023\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.5108 - f1: 0.9240 - val_loss: 0.5019 - val_f1: 0.9150\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.4821 - f1: 0.9282 - val_loss: 0.4735 - val_f1: 0.9281\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.4536 - f1: 0.9341 - val_loss: 0.4505 - val_f1: 0.9340\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.4437 - f1: 0.9290 - val_loss: 0.4457 - val_f1: 0.9295\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 0.4442 - f1: 0.9347 - val_loss: 0.4964 - val_f1: 0.9025\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 0.4380 - f1: 0.9306 - val_loss: 0.4507 - val_f1: 0.9150\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 0.4192 - f1: 0.9361 - val_loss: 0.4541 - val_f1: 0.9221\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 0.3903 - f1: 0.9458 - val_loss: 0.4146 - val_f1: 0.9334\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 0.4052 - f1: 0.9380 - val_loss: 0.4537 - val_f1: 0.9098\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.4302 - f1: 0.9398 - val_loss: 0.4239 - val_f1: 0.9350\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.3754 - f1: 0.9451 - val_loss: 0.3766 - val_f1: 0.9399\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.3492 - f1: 0.9547 - val_loss: 0.3860 - val_f1: 0.9360\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.3645 - f1: 0.9380 - val_loss: 0.4583 - val_f1: 0.9120\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.3880 - f1: 0.9408 - val_loss: 0.4049 - val_f1: 0.9334\n",
      "Epoch 28/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.3529 - f1: 0.9498 - val_loss: 0.3796 - val_f1: 0.9380\n",
      "Epoch 29/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.3719 - f1: 0.9408 - val_loss: 0.3694 - val_f1: 0.9397\n",
      "Epoch 30/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.3413 - f1: 0.9556 - val_loss: 0.3600 - val_f1: 0.9476\n",
      "Epoch 31/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 0.3315 - f1: 0.9563 - val_loss: 0.3494 - val_f1: 0.9424\n",
      "Epoch 32/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.3015 - f1: 0.9577 - val_loss: 0.3271 - val_f1: 0.9458\n",
      "Epoch 33/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.2963 - f1: 0.9556 - val_loss: 0.3254 - val_f1: 0.9460\n",
      "Epoch 34/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.2827 - f1: 0.9641 - val_loss: 0.3136 - val_f1: 0.9459\n",
      "Running through fold 4\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 4.0461 - f1: 0.0019 - val_loss: 3.1602 - val_f1: 0.0189\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 565us/sample - loss: 2.6358 - f1: 0.1314 - val_loss: 2.0682 - val_f1: 0.3134\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 557us/sample - loss: 1.7112 - f1: 0.4582 - val_loss: 1.4675 - val_f1: 0.6180\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 555us/sample - loss: 1.2932 - f1: 0.7028 - val_loss: 1.1708 - val_f1: 0.7517\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 555us/sample - loss: 1.0637 - f1: 0.7979 - val_loss: 1.0218 - val_f1: 0.8058\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 553us/sample - loss: 0.9250 - f1: 0.8464 - val_loss: 0.9128 - val_f1: 0.8380\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 549us/sample - loss: 0.8168 - f1: 0.8894 - val_loss: 0.8372 - val_f1: 0.8509\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 550us/sample - loss: 0.7512 - f1: 0.8821 - val_loss: 0.7443 - val_f1: 0.8813\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 547us/sample - loss: 0.6854 - f1: 0.8977 - val_loss: 0.6920 - val_f1: 0.8818\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 550us/sample - loss: 0.6362 - f1: 0.9096 - val_loss: 0.6607 - val_f1: 0.8914\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 544us/sample - loss: 0.5984 - f1: 0.9122 - val_loss: 0.6361 - val_f1: 0.8889\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 547us/sample - loss: 0.5591 - f1: 0.9207 - val_loss: 0.5934 - val_f1: 0.9066\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.5458 - f1: 0.9242 - val_loss: 0.5787 - val_f1: 0.9104\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 543us/sample - loss: 0.5283 - f1: 0.9140 - val_loss: 0.5730 - val_f1: 0.8963\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.4981 - f1: 0.9193 - val_loss: 0.5513 - val_f1: 0.9020\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.4822 - f1: 0.9272 - val_loss: 0.5402 - val_f1: 0.9051\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.4826 - f1: 0.9219 - val_loss: 0.5886 - val_f1: 0.8762\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.4843 - f1: 0.9176 - val_loss: 0.5561 - val_f1: 0.8938\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.4251 - f1: 0.9387 - val_loss: 0.4709 - val_f1: 0.9152\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.4120 - f1: 0.9331 - val_loss: 0.4936 - val_f1: 0.9055\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.3896 - f1: 0.9467 - val_loss: 0.4632 - val_f1: 0.9051\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 0.3835 - f1: 0.9420 - val_loss: 0.4402 - val_f1: 0.9135\n",
      "\n",
      "\n",
      "Running through training size 5000\n",
      "Running through fold 0\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 4s 731us/sample - loss: 2.1683 - f1: 0.4216 - val_loss: 1.0409 - val_f1: 0.8014\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.8001 - f1: 0.8694 - val_loss: 0.6453 - val_f1: 0.8826\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.5819 - f1: 0.8988 - val_loss: 0.5127 - val_f1: 0.9159\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 302us/sample - loss: 0.5086 - f1: 0.9039 - val_loss: 0.4920 - val_f1: 0.9082\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.4684 - f1: 0.9114 - val_loss: 0.4066 - val_f1: 0.9278\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.4273 - f1: 0.9168 - val_loss: 0.4302 - val_f1: 0.9207\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.3921 - f1: 0.9255 - val_loss: 0.3533 - val_f1: 0.9310\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.3953 - f1: 0.9253 - val_loss: 0.3314 - val_f1: 0.9398\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.3490 - f1: 0.9330 - val_loss: 0.3543 - val_f1: 0.9332\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.3435 - f1: 0.9360 - val_loss: 0.3804 - val_f1: 0.9256\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.3273 - f1: 0.9367 - val_loss: 0.3116 - val_f1: 0.9456\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.3324 - f1: 0.9440 - val_loss: 0.2962 - val_f1: 0.9462\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.3026 - f1: 0.9442 - val_loss: 0.3607 - val_f1: 0.9376\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.3111 - f1: 0.9471 - val_loss: 0.2818 - val_f1: 0.9456\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.2803 - f1: 0.9491 - val_loss: 0.2707 - val_f1: 0.9468\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2735 - f1: 0.9544 - val_loss: 0.2926 - val_f1: 0.9433\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2921 - f1: 0.9503 - val_loss: 0.2618 - val_f1: 0.9578\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.2804 - f1: 0.9509 - val_loss: 0.3097 - val_f1: 0.9414\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.2515 - f1: 0.9593 - val_loss: 0.2412 - val_f1: 0.9559\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.2358 - f1: 0.9581 - val_loss: 0.2878 - val_f1: 0.9497\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.3352 - f1: 0.9560 - val_loss: 0.2296 - val_f1: 0.9652\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2102 - f1: 0.9716 - val_loss: 0.2017 - val_f1: 0.9743\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.2458 - f1: 0.9698 - val_loss: 0.2312 - val_f1: 0.9694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.2157 - f1: 0.9773 - val_loss: 0.1984 - val_f1: 0.9786\n",
      "Epoch 25/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.1956 - f1: 0.9827 - val_loss: 0.1860 - val_f1: 0.9847\n",
      "Epoch 26/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.1683 - f1: 0.9885 - val_loss: 0.1720 - val_f1: 0.9850\n",
      "Epoch 27/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.2436 - f1: 0.9774 - val_loss: 0.2216 - val_f1: 0.9865\n",
      "Epoch 28/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.1803 - f1: 0.9891 - val_loss: 0.2299 - val_f1: 0.9684\n",
      "Epoch 29/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2328 - f1: 0.9827 - val_loss: 0.1841 - val_f1: 0.9903\n",
      "Epoch 30/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.1734 - f1: 0.9907 - val_loss: 0.1705 - val_f1: 0.9902\n",
      "Epoch 31/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.1594 - f1: 0.9907 - val_loss: 0.1358 - val_f1: 0.9940\n",
      "Epoch 32/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.1607 - f1: 0.9901 - val_loss: 0.1313 - val_f1: 0.9923\n",
      "Epoch 33/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.1762 - f1: 0.9876 - val_loss: 0.1770 - val_f1: 0.9867\n",
      "Epoch 34/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.1417 - f1: 0.9959 - val_loss: 0.1300 - val_f1: 0.9922\n",
      "Epoch 35/2000\n",
      "5000/5000 [==============================] - 4s 790us/sample - loss: 0.1267 - f1: 0.9952 - val_loss: 0.1638 - val_f1: 0.9843\n",
      "Running through fold 1\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 4s 766us/sample - loss: 2.0175 - f1: 0.4605 - val_loss: 0.9247 - val_f1: 0.8284\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.7507 - f1: 0.8774 - val_loss: 0.6401 - val_f1: 0.8892\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.5654 - f1: 0.9023 - val_loss: 0.5010 - val_f1: 0.9087\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.4803 - f1: 0.9132 - val_loss: 0.5126 - val_f1: 0.8963\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.4474 - f1: 0.9189 - val_loss: 0.4324 - val_f1: 0.9290\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.3944 - f1: 0.9334 - val_loss: 0.4071 - val_f1: 0.9195\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3800 - f1: 0.9283 - val_loss: 0.3866 - val_f1: 0.9363\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.3634 - f1: 0.9350 - val_loss: 0.3272 - val_f1: 0.9412\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3120 - f1: 0.9449 - val_loss: 0.3773 - val_f1: 0.9169\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.3326 - f1: 0.9450 - val_loss: 0.2739 - val_f1: 0.9536\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3020 - f1: 0.9480 - val_loss: 0.3240 - val_f1: 0.9468\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.3048 - f1: 0.9487 - val_loss: 0.3041 - val_f1: 0.9461\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2829 - f1: 0.9527 - val_loss: 0.2754 - val_f1: 0.9444\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2717 - f1: 0.9542 - val_loss: 0.2921 - val_f1: 0.9464\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2759 - f1: 0.9521 - val_loss: 0.3750 - val_f1: 0.9170\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.3375 - f1: 0.9458 - val_loss: 0.3488 - val_f1: 0.9436\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2687 - f1: 0.9575 - val_loss: 0.2515 - val_f1: 0.9573\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2438 - f1: 0.9653 - val_loss: 0.3188 - val_f1: 0.9368\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2381 - f1: 0.9643 - val_loss: 0.2791 - val_f1: 0.9521\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2697 - f1: 0.9672 - val_loss: 0.2265 - val_f1: 0.9752\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2566 - f1: 0.9674 - val_loss: 0.3217 - val_f1: 0.9596\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2100 - f1: 0.9827 - val_loss: 0.2001 - val_f1: 0.9760\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1936 - f1: 0.9833 - val_loss: 0.2887 - val_f1: 0.9439\n",
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2165 - f1: 0.9804 - val_loss: 0.2544 - val_f1: 0.9750\n",
      "Epoch 25/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2197 - f1: 0.9834 - val_loss: 0.1928 - val_f1: 0.9816\n",
      "Epoch 26/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.1638 - f1: 0.9917 - val_loss: 0.1676 - val_f1: 0.9864\n",
      "Epoch 27/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1563 - f1: 0.9907 - val_loss: 0.1831 - val_f1: 0.9853\n",
      "Epoch 28/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.1605 - f1: 0.9915 - val_loss: 0.2580 - val_f1: 0.9671\n",
      "Epoch 29/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1852 - f1: 0.9898 - val_loss: 0.2304 - val_f1: 0.9858\n",
      "Epoch 30/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.1756 - f1: 0.9895 - val_loss: 0.2267 - val_f1: 0.9724\n",
      "Epoch 31/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2524 - f1: 0.9846 - val_loss: 0.1705 - val_f1: 0.9884\n",
      "Epoch 32/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.1419 - f1: 0.9960 - val_loss: 0.1225 - val_f1: 0.9953\n",
      "Epoch 33/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.1102 - f1: 0.9979 - val_loss: 0.1382 - val_f1: 0.9872\n",
      "Epoch 34/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.1139 - f1: 0.9969 - val_loss: 0.1887 - val_f1: 0.9725\n",
      "Epoch 35/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.2411 - f1: 0.9805 - val_loss: 0.2071 - val_f1: 0.9887\n",
      "Epoch 36/2000\n",
      "5000/5000 [==============================] - 4s 750us/sample - loss: 0.1311 - f1: 0.9962 - val_loss: 0.1222 - val_f1: 0.9900\n",
      "Running through fold 2\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 4s 777us/sample - loss: 2.4041 - f1: 0.3088 - val_loss: 1.1461 - val_f1: 0.7605\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 315us/sample - loss: 0.8834 - f1: 0.8446 - val_loss: 0.7236 - val_f1: 0.8793\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 0.6460 - f1: 0.8910 - val_loss: 0.5586 - val_f1: 0.9119\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.5398 - f1: 0.8992 - val_loss: 0.4968 - val_f1: 0.9118\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.4734 - f1: 0.9138 - val_loss: 0.4218 - val_f1: 0.9169\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.4321 - f1: 0.9152 - val_loss: 0.4657 - val_f1: 0.8948\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 316us/sample - loss: 0.4065 - f1: 0.9235 - val_loss: 0.3515 - val_f1: 0.9442\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.3569 - f1: 0.9400 - val_loss: 0.4794 - val_f1: 0.8997\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 0.3698 - f1: 0.9344 - val_loss: 0.3722 - val_f1: 0.9333\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 0.3253 - f1: 0.9468 - val_loss: 0.2943 - val_f1: 0.9503\n",
      "Epoch 11/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.3016 - f1: 0.9505 - val_loss: 0.3302 - val_f1: 0.9391\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.3208 - f1: 0.9463 - val_loss: 0.2899 - val_f1: 0.9458\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.2800 - f1: 0.9525 - val_loss: 0.3186 - val_f1: 0.9375\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.3078 - f1: 0.9507 - val_loss: 0.2671 - val_f1: 0.9529\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.3035 - f1: 0.9487 - val_loss: 0.2564 - val_f1: 0.9592\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2500 - f1: 0.9592 - val_loss: 0.2808 - val_f1: 0.9605\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2780 - f1: 0.9546 - val_loss: 0.3318 - val_f1: 0.9308\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.2616 - f1: 0.9589 - val_loss: 0.3151 - val_f1: 0.9289\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 318us/sample - loss: 0.2721 - f1: 0.9584 - val_loss: 0.2737 - val_f1: 0.9611\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.2222 - f1: 0.9688 - val_loss: 0.2052 - val_f1: 0.9723\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.2419 - f1: 0.9671 - val_loss: 0.2872 - val_f1: 0.9601\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.2047 - f1: 0.9823 - val_loss: 0.2001 - val_f1: 0.9763\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 2s 303us/sample - loss: 0.2269 - f1: 0.9754 - val_loss: 0.2464 - val_f1: 0.9815\n",
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.2409 - f1: 0.9801 - val_loss: 0.2069 - val_f1: 0.9766\n",
      "Epoch 25/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.1783 - f1: 0.9874 - val_loss: 0.1654 - val_f1: 0.9898\n",
      "Epoch 26/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.1933 - f1: 0.9866 - val_loss: 0.1544 - val_f1: 0.9904\n",
      "Epoch 27/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.1575 - f1: 0.9908 - val_loss: 0.1418 - val_f1: 0.9922\n",
      "Epoch 28/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.1449 - f1: 0.9928 - val_loss: 0.1828 - val_f1: 0.9820\n",
      "Epoch 29/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.2440 - f1: 0.9797 - val_loss: 0.2179 - val_f1: 0.9892\n",
      "Epoch 30/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.1661 - f1: 0.9913 - val_loss: 0.1649 - val_f1: 0.9882\n",
      "Epoch 31/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.1514 - f1: 0.9920 - val_loss: 0.1690 - val_f1: 0.9882\n",
      "Epoch 32/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.1607 - f1: 0.9908 - val_loss: 0.2986 - val_f1: 0.9664\n",
      "Epoch 33/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.1702 - f1: 0.9894 - val_loss: 0.1484 - val_f1: 0.9957\n",
      "Epoch 34/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.1241 - f1: 0.9950 - val_loss: 0.1341 - val_f1: 0.9916\n",
      "Epoch 35/2000\n",
      "5000/5000 [==============================] - 4s 783us/sample - loss: 0.2395 - f1: 0.9788 - val_loss: 0.2053 - val_f1: 0.9856\n",
      "Running through fold 3\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 4s 802us/sample - loss: 2.0812 - f1: 0.4408 - val_loss: 0.9358 - val_f1: 0.8302\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 321us/sample - loss: 0.7584 - f1: 0.8725 - val_loss: 0.6285 - val_f1: 0.8864\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 316us/sample - loss: 0.5670 - f1: 0.8980 - val_loss: 0.5187 - val_f1: 0.9062\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 316us/sample - loss: 0.4773 - f1: 0.9171 - val_loss: 0.4425 - val_f1: 0.9240\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 315us/sample - loss: 0.4322 - f1: 0.9244 - val_loss: 0.4646 - val_f1: 0.9034\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 0.4098 - f1: 0.9308 - val_loss: 0.3874 - val_f1: 0.9240\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.3737 - f1: 0.9338 - val_loss: 0.3393 - val_f1: 0.9426\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.3443 - f1: 0.9414 - val_loss: 0.3331 - val_f1: 0.9474\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.3205 - f1: 0.9462 - val_loss: 0.3339 - val_f1: 0.9425\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.3174 - f1: 0.9474 - val_loss: 0.3345 - val_f1: 0.9362\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.3111 - f1: 0.9471 - val_loss: 0.3073 - val_f1: 0.9474\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.2976 - f1: 0.9517 - val_loss: 0.3400 - val_f1: 0.9460\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.3085 - f1: 0.9493 - val_loss: 0.3325 - val_f1: 0.9467\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.2899 - f1: 0.9552 - val_loss: 0.2781 - val_f1: 0.9558\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.2771 - f1: 0.9592 - val_loss: 0.2903 - val_f1: 0.9565\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.2845 - f1: 0.9560 - val_loss: 0.3191 - val_f1: 0.9503\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.2542 - f1: 0.9693 - val_loss: 0.2076 - val_f1: 0.9807\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.2410 - f1: 0.9724 - val_loss: 0.2253 - val_f1: 0.9873\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.2235 - f1: 0.9789 - val_loss: 0.2313 - val_f1: 0.9793\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.2010 - f1: 0.9846 - val_loss: 0.1943 - val_f1: 0.9861\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.1856 - f1: 0.9863 - val_loss: 0.1934 - val_f1: 0.9892\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.1898 - f1: 0.9896 - val_loss: 0.1695 - val_f1: 0.9910\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.1924 - f1: 0.9881 - val_loss: 0.2218 - val_f1: 0.9792\n",
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.1838 - f1: 0.9872 - val_loss: 0.2419 - val_f1: 0.9826\n",
      "Epoch 25/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.1759 - f1: 0.9926 - val_loss: 0.2274 - val_f1: 0.9743\n",
      "Epoch 26/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.1521 - f1: 0.9952 - val_loss: 0.1374 - val_f1: 0.9941\n",
      "Epoch 27/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.2232 - f1: 0.9819 - val_loss: 0.2232 - val_f1: 0.9933\n",
      "Epoch 28/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.1557 - f1: 0.9960 - val_loss: 0.1243 - val_f1: 0.9963\n",
      "Epoch 29/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.1265 - f1: 0.9947 - val_loss: 0.2262 - val_f1: 0.9704\n",
      "Epoch 30/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.1962 - f1: 0.9889 - val_loss: 0.1270 - val_f1: 0.9985\n",
      "Epoch 31/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.1161 - f1: 0.9960 - val_loss: 0.1488 - val_f1: 0.9868\n",
      "Epoch 32/2000\n",
      "5000/5000 [==============================] - 4s 796us/sample - loss: 0.2146 - f1: 0.9852 - val_loss: 0.1993 - val_f1: 0.9923\n",
      "Running through fold 4\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 4s 824us/sample - loss: 2.4871 - f1: 0.2566 - val_loss: 1.1763 - val_f1: 0.7441\n",
      "Epoch 2/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 2s 322us/sample - loss: 0.8895 - f1: 0.8412 - val_loss: 0.7284 - val_f1: 0.8871\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 321us/sample - loss: 0.6130 - f1: 0.9022 - val_loss: 0.5575 - val_f1: 0.9082\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 323us/sample - loss: 0.5268 - f1: 0.9127 - val_loss: 0.4858 - val_f1: 0.9199\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 323us/sample - loss: 0.4691 - f1: 0.9175 - val_loss: 0.4052 - val_f1: 0.9350\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 321us/sample - loss: 0.4020 - f1: 0.9327 - val_loss: 0.4077 - val_f1: 0.9256\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 322us/sample - loss: 0.4008 - f1: 0.9316 - val_loss: 0.3731 - val_f1: 0.9283\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 323us/sample - loss: 0.3829 - f1: 0.9344 - val_loss: 0.3408 - val_f1: 0.9468\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 319us/sample - loss: 0.3516 - f1: 0.9356 - val_loss: 0.3313 - val_f1: 0.9490\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 317us/sample - loss: 0.3355 - f1: 0.9453 - val_loss: 0.3393 - val_f1: 0.9359\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 316us/sample - loss: 0.3190 - f1: 0.9475 - val_loss: 0.3163 - val_f1: 0.9355\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 318us/sample - loss: 0.3518 - f1: 0.9386 - val_loss: 0.3934 - val_f1: 0.9441\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 318us/sample - loss: 0.3005 - f1: 0.9549 - val_loss: 0.2705 - val_f1: 0.9565\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 318us/sample - loss: 0.2876 - f1: 0.9553 - val_loss: 0.3148 - val_f1: 0.9518\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 318us/sample - loss: 0.2780 - f1: 0.9581 - val_loss: 0.2699 - val_f1: 0.9603\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 316us/sample - loss: 0.2720 - f1: 0.9610 - val_loss: 0.2581 - val_f1: 0.9587\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.2698 - f1: 0.9595 - val_loss: 0.2658 - val_f1: 0.9531\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 315us/sample - loss: 0.2587 - f1: 0.9616 - val_loss: 0.2506 - val_f1: 0.9729\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.2956 - f1: 0.9544 - val_loss: 0.2905 - val_f1: 0.9552\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.2183 - f1: 0.9781 - val_loss: 0.2052 - val_f1: 0.9853\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.2393 - f1: 0.9700 - val_loss: 0.2500 - val_f1: 0.9605\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 0.2594 - f1: 0.9669 - val_loss: 0.2482 - val_f1: 0.9586\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.2354 - f1: 0.9750 - val_loss: 0.2270 - val_f1: 0.9796\n",
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 0.2025 - f1: 0.9803 - val_loss: 0.2212 - val_f1: 0.9750\n",
      "Epoch 25/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.1774 - f1: 0.9893 - val_loss: 0.1626 - val_f1: 0.9889\n",
      "Epoch 26/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.1868 - f1: 0.9872 - val_loss: 0.1784 - val_f1: 0.9887\n",
      "Epoch 27/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.1916 - f1: 0.9837 - val_loss: 0.3633 - val_f1: 0.9338\n",
      "Epoch 28/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.2026 - f1: 0.9834 - val_loss: 0.2529 - val_f1: 0.9773\n",
      "Epoch 29/2000\n",
      "5000/5000 [==============================] - 2s 315us/sample - loss: 0.2014 - f1: 0.9899 - val_loss: 0.1479 - val_f1: 0.9918\n",
      "Epoch 30/2000\n",
      "5000/5000 [==============================] - 4s 834us/sample - loss: 0.1414 - f1: 0.9940 - val_loss: 0.1582 - val_f1: 0.9890\n",
      "\n",
      "\n",
      "Running through training size 15000\n",
      "Running through fold 0\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 458us/sample - loss: 1.1477 - f1: 0.7329 - val_loss: 0.5538 - val_f1: 0.9145\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.4414 - f1: 0.9261 - val_loss: 0.3814 - val_f1: 0.9408\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 278us/sample - loss: 0.3517 - f1: 0.9443 - val_loss: 0.3969 - val_f1: 0.9402\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 278us/sample - loss: 0.3102 - f1: 0.9515 - val_loss: 0.2488 - val_f1: 0.9748\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 279us/sample - loss: 0.2698 - f1: 0.9667 - val_loss: 0.2221 - val_f1: 0.9756\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.2465 - f1: 0.9745 - val_loss: 0.2566 - val_f1: 0.9822\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.2306 - f1: 0.9806 - val_loss: 0.1831 - val_f1: 0.9799\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 278us/sample - loss: 0.1913 - f1: 0.9867 - val_loss: 0.1552 - val_f1: 0.9927\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.1672 - f1: 0.9903 - val_loss: 0.1536 - val_f1: 0.9938\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.1743 - f1: 0.9896 - val_loss: 0.1807 - val_f1: 0.9838\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 283us/sample - loss: 0.1712 - f1: 0.9904 - val_loss: 0.2135 - val_f1: 0.9923\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.1632 - f1: 0.9923 - val_loss: 0.1318 - val_f1: 0.9958\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.1239 - f1: 0.9948 - val_loss: 0.1153 - val_f1: 0.9987\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.1684 - f1: 0.9906 - val_loss: 0.1690 - val_f1: 0.9958\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.1427 - f1: 0.9939 - val_loss: 0.0874 - val_f1: 0.9957\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.1493 - f1: 0.9933 - val_loss: 0.1263 - val_f1: 0.9955\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 283us/sample - loss: 0.1149 - f1: 0.9956 - val_loss: 0.1828 - val_f1: 0.9806\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 7s 457us/sample - loss: 0.2240 - f1: 0.9860 - val_loss: 0.0961 - val_f1: 0.9989\n",
      "Running through fold 1\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 467us/sample - loss: 1.2419 - f1: 0.7016 - val_loss: 0.5367 - val_f1: 0.9028\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 288us/sample - loss: 0.4287 - f1: 0.9341 - val_loss: 0.4307 - val_f1: 0.9181\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.3294 - f1: 0.9541 - val_loss: 0.2623 - val_f1: 0.9787\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.2683 - f1: 0.9738 - val_loss: 0.2305 - val_f1: 0.9825\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 288us/sample - loss: 0.2342 - f1: 0.9831 - val_loss: 0.1892 - val_f1: 0.9856\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.1882 - f1: 0.9900 - val_loss: 0.2233 - val_f1: 0.9685\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.2003 - f1: 0.9889 - val_loss: 0.1763 - val_f1: 0.9890\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.1662 - f1: 0.9905 - val_loss: 0.2222 - val_f1: 0.9890\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 288us/sample - loss: 0.1708 - f1: 0.9911 - val_loss: 0.1768 - val_f1: 0.9880\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.1720 - f1: 0.9900 - val_loss: 0.1636 - val_f1: 0.9963\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.1249 - f1: 0.9967 - val_loss: 0.1104 - val_f1: 0.9978\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.1797 - f1: 0.9896 - val_loss: 0.1666 - val_f1: 0.9923\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.1165 - f1: 0.9972 - val_loss: 0.0787 - val_f1: 0.9993\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.1885 - f1: 0.9888 - val_loss: 0.1100 - val_f1: 0.9995\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.0944 - f1: 0.9982 - val_loss: 0.0996 - val_f1: 0.9967\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 288us/sample - loss: 0.1918 - f1: 0.9874 - val_loss: 0.0996 - val_f1: 0.9992\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.0946 - f1: 0.9964 - val_loss: 0.4414 - val_f1: 0.9483\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 4s 288us/sample - loss: 0.1584 - f1: 0.9933 - val_loss: 0.1831 - val_f1: 0.9852\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.0950 - f1: 0.9972 - val_loss: 0.0747 - val_f1: 0.9978\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.2115 - f1: 0.9872 - val_loss: 0.0798 - val_f1: 0.9998\n",
      "Epoch 21/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.0996 - f1: 0.9951 - val_loss: 0.2306 - val_f1: 0.9852\n",
      "Epoch 22/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.0994 - f1: 0.9979 - val_loss: 0.0547 - val_f1: 0.9998\n",
      "Epoch 23/2000\n",
      "15000/15000 [==============================] - 7s 491us/sample - loss: 0.2027 - f1: 0.9876 - val_loss: 0.1312 - val_f1: 0.9990\n",
      "Running through fold 2\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 481us/sample - loss: 1.3651 - f1: 0.6683 - val_loss: 0.5904 - val_f1: 0.8922\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.4816 - f1: 0.9145 - val_loss: 0.4045 - val_f1: 0.9211\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.3712 - f1: 0.9357 - val_loss: 0.3257 - val_f1: 0.9516\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.3262 - f1: 0.9445 - val_loss: 0.3242 - val_f1: 0.9549\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.2907 - f1: 0.9512 - val_loss: 0.2606 - val_f1: 0.9546\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.2925 - f1: 0.9496 - val_loss: 0.2522 - val_f1: 0.9606\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.2500 - f1: 0.9569 - val_loss: 0.3390 - val_f1: 0.9356\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.2496 - f1: 0.9600 - val_loss: 0.2613 - val_f1: 0.9557\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.2403 - f1: 0.9651 - val_loss: 0.2505 - val_f1: 0.9657\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.2296 - f1: 0.9690 - val_loss: 0.1655 - val_f1: 0.9872\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.1842 - f1: 0.9837 - val_loss: 0.1609 - val_f1: 0.9920\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.1705 - f1: 0.9881 - val_loss: 0.1519 - val_f1: 0.9931\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.2005 - f1: 0.9835 - val_loss: 0.1584 - val_f1: 0.9856\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.1780 - f1: 0.9864 - val_loss: 0.2065 - val_f1: 0.9885\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.1440 - f1: 0.9914 - val_loss: 0.2002 - val_f1: 0.9927\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.1263 - f1: 0.9944 - val_loss: 0.1037 - val_f1: 0.9950\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.1228 - f1: 0.9944 - val_loss: 0.1046 - val_f1: 0.9985\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 4s 292us/sample - loss: 0.1543 - f1: 0.9908 - val_loss: 0.1638 - val_f1: 0.9915\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.1364 - f1: 0.9936 - val_loss: 0.0846 - val_f1: 0.9987\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 4s 293us/sample - loss: 0.0874 - f1: 0.9965 - val_loss: 0.3594 - val_f1: 0.9563\n",
      "Epoch 21/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.2403 - f1: 0.9873 - val_loss: 0.0898 - val_f1: 0.9990\n",
      "Epoch 22/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.0827 - f1: 0.9981 - val_loss: 0.1045 - val_f1: 0.9952\n",
      "Epoch 23/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.1401 - f1: 0.9917 - val_loss: 0.1976 - val_f1: 0.9973\n",
      "Epoch 24/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.0986 - f1: 0.9981 - val_loss: 0.0651 - val_f1: 1.0000\n",
      "Epoch 25/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.1906 - f1: 0.9891 - val_loss: 0.0914 - val_f1: 0.9958\n",
      "Epoch 26/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.0657 - f1: 0.9992 - val_loss: 0.0578 - val_f1: 0.9977\n",
      "Epoch 27/2000\n",
      "15000/15000 [==============================] - 7s 500us/sample - loss: 0.1920 - f1: 0.9877 - val_loss: 0.1752 - val_f1: 0.9963\n",
      "Running through fold 3\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 495us/sample - loss: 1.1482 - f1: 0.7389 - val_loss: 0.5140 - val_f1: 0.9063\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 296us/sample - loss: 0.4479 - f1: 0.9214 - val_loss: 0.4065 - val_f1: 0.9372\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 295us/sample - loss: 0.3718 - f1: 0.9362 - val_loss: 0.3785 - val_f1: 0.9345\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.3101 - f1: 0.9529 - val_loss: 0.2949 - val_f1: 0.9466\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.2887 - f1: 0.9543 - val_loss: 0.2851 - val_f1: 0.9575\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 295us/sample - loss: 0.2731 - f1: 0.9608 - val_loss: 0.2352 - val_f1: 0.9716\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.2488 - f1: 0.9666 - val_loss: 0.2173 - val_f1: 0.9827\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.2449 - f1: 0.9704 - val_loss: 0.2117 - val_f1: 0.9731\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.2224 - f1: 0.9756 - val_loss: 0.2118 - val_f1: 0.9721\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 296us/sample - loss: 0.2097 - f1: 0.9813 - val_loss: 0.1604 - val_f1: 0.9909\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 293us/sample - loss: 0.2116 - f1: 0.9817 - val_loss: 0.2181 - val_f1: 0.9888\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 296us/sample - loss: 0.1873 - f1: 0.9857 - val_loss: 0.1612 - val_f1: 0.9932\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 293us/sample - loss: 0.1792 - f1: 0.9863 - val_loss: 0.2284 - val_f1: 0.9885\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.1653 - f1: 0.9884 - val_loss: 0.1972 - val_f1: 0.9883\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 295us/sample - loss: 0.1615 - f1: 0.9922 - val_loss: 0.1233 - val_f1: 0.9968\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 298us/sample - loss: 0.1680 - f1: 0.9878 - val_loss: 0.1766 - val_f1: 0.9889\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 299us/sample - loss: 0.1182 - f1: 0.9952 - val_loss: 0.1786 - val_f1: 0.9831\n",
      "Epoch 18/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 4s 298us/sample - loss: 0.1826 - f1: 0.9892 - val_loss: 0.1102 - val_f1: 0.9953\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 296us/sample - loss: 0.1621 - f1: 0.9906 - val_loss: 0.2353 - val_f1: 0.9799\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 5s 300us/sample - loss: 0.1336 - f1: 0.9945 - val_loss: 0.1364 - val_f1: 0.9947\n",
      "Epoch 21/2000\n",
      "15000/15000 [==============================] - 4s 297us/sample - loss: 0.1329 - f1: 0.9922 - val_loss: 0.1862 - val_f1: 0.9901\n",
      "Epoch 22/2000\n",
      "15000/15000 [==============================] - 8s 505us/sample - loss: 0.1154 - f1: 0.9960 - val_loss: 0.1363 - val_f1: 0.9946\n",
      "Running through fold 4\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 8s 504us/sample - loss: 1.1815 - f1: 0.7283 - val_loss: 0.5105 - val_f1: 0.9133\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 297us/sample - loss: 0.4483 - f1: 0.9254 - val_loss: 0.3808 - val_f1: 0.9316\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 296us/sample - loss: 0.3453 - f1: 0.9416 - val_loss: 0.3078 - val_f1: 0.9463\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 296us/sample - loss: 0.3061 - f1: 0.9484 - val_loss: 0.3073 - val_f1: 0.9336\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 298us/sample - loss: 0.2883 - f1: 0.9551 - val_loss: 0.2399 - val_f1: 0.9769\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 295us/sample - loss: 0.2733 - f1: 0.9651 - val_loss: 0.2084 - val_f1: 0.9794\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.2254 - f1: 0.9753 - val_loss: 0.2424 - val_f1: 0.9484\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.2062 - f1: 0.9818 - val_loss: 0.2007 - val_f1: 0.9774\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 296us/sample - loss: 0.2045 - f1: 0.9848 - val_loss: 0.1521 - val_f1: 0.9947\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 296us/sample - loss: 0.1654 - f1: 0.9895 - val_loss: 0.1905 - val_f1: 0.9745\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.1762 - f1: 0.9886 - val_loss: 0.3341 - val_f1: 0.9701\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 293us/sample - loss: 0.1934 - f1: 0.9885 - val_loss: 0.1569 - val_f1: 0.9945\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.1259 - f1: 0.9952 - val_loss: 0.1197 - val_f1: 0.9958\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 293us/sample - loss: 0.1700 - f1: 0.9905 - val_loss: 0.1255 - val_f1: 0.9980\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.1192 - f1: 0.9948 - val_loss: 0.3068 - val_f1: 0.9637\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 295us/sample - loss: 0.1480 - f1: 0.9938 - val_loss: 0.0777 - val_f1: 0.9990\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 294us/sample - loss: 0.1234 - f1: 0.9947 - val_loss: 0.0937 - val_f1: 0.9983\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 4s 292us/sample - loss: 0.1438 - f1: 0.9927 - val_loss: 0.2557 - val_f1: 0.9915\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 8s 509us/sample - loss: 0.1255 - f1: 0.9957 - val_loss: 0.1593 - val_f1: 0.9924\n",
      "\n",
      "\n",
      "Running through training size 20000\n",
      "Running through fold 0\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 9s 444us/sample - loss: 0.9479 - f1: 0.7938 - val_loss: 0.4751 - val_f1: 0.9274\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.3533 - f1: 0.9462 - val_loss: 0.2883 - val_f1: 0.9559\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2837 - f1: 0.9565 - val_loss: 0.2787 - val_f1: 0.9613\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2504 - f1: 0.9629 - val_loss: 0.2301 - val_f1: 0.9705\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2236 - f1: 0.9744 - val_loss: 0.2722 - val_f1: 0.9682\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1848 - f1: 0.9884 - val_loss: 0.4040 - val_f1: 0.9528\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1972 - f1: 0.9890 - val_loss: 0.1795 - val_f1: 0.9905\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1451 - f1: 0.9940 - val_loss: 0.1721 - val_f1: 0.9849\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1383 - f1: 0.9942 - val_loss: 0.1350 - val_f1: 0.9940\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1476 - f1: 0.9933 - val_loss: 0.1276 - val_f1: 0.9980\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1551 - f1: 0.9916 - val_loss: 0.2882 - val_f1: 0.9811\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 291us/sample - loss: 0.1395 - f1: 0.9951 - val_loss: 0.1333 - val_f1: 0.9983\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1452 - f1: 0.9923 - val_loss: 0.2205 - val_f1: 0.9928\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1027 - f1: 0.9968 - val_loss: 0.3480 - val_f1: 0.9303\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1320 - f1: 0.9948 - val_loss: 0.0612 - val_f1: 0.9989\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.0812 - f1: 0.9974 - val_loss: 0.0702 - val_f1: 0.9970\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 9s 457us/sample - loss: 0.1987 - f1: 0.9916 - val_loss: 0.0643 - val_f1: 0.9992\n",
      "Running through fold 1\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 9s 455us/sample - loss: 1.0001 - f1: 0.7754 - val_loss: 0.4421 - val_f1: 0.9183\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 292us/sample - loss: 0.3642 - f1: 0.9406 - val_loss: 0.3167 - val_f1: 0.9493\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 293us/sample - loss: 0.3012 - f1: 0.9527 - val_loss: 0.2505 - val_f1: 0.9622\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2619 - f1: 0.9628 - val_loss: 0.2930 - val_f1: 0.9711\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2310 - f1: 0.9754 - val_loss: 0.1768 - val_f1: 0.9804\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.2062 - f1: 0.9805 - val_loss: 0.2476 - val_f1: 0.9883\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1783 - f1: 0.9887 - val_loss: 0.1234 - val_f1: 0.9983\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1557 - f1: 0.9920 - val_loss: 0.1488 - val_f1: 0.9965\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1555 - f1: 0.9921 - val_loss: 0.1306 - val_f1: 0.9982\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1423 - f1: 0.9933 - val_loss: 0.1116 - val_f1: 0.9943\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1773 - f1: 0.9895 - val_loss: 0.0856 - val_f1: 0.9993\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1261 - f1: 0.9938 - val_loss: 0.1498 - val_f1: 0.9963\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1240 - f1: 0.9950 - val_loss: 0.0885 - val_f1: 0.9968\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1817 - f1: 0.9893 - val_loss: 0.1553 - val_f1: 0.9953\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.0811 - f1: 0.9988 - val_loss: 0.0989 - val_f1: 0.9938\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1493 - f1: 0.9921 - val_loss: 0.0779 - val_f1: 0.9988\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 9s 466us/sample - loss: 0.0935 - f1: 0.9950 - val_loss: 0.3824 - val_f1: 0.9705\n",
      "Running through fold 2\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 9s 457us/sample - loss: 0.9542 - f1: 0.7969 - val_loss: 0.4088 - val_f1: 0.9413\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.3508 - f1: 0.9469 - val_loss: 0.3248 - val_f1: 0.9507\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.2783 - f1: 0.9581 - val_loss: 0.2677 - val_f1: 0.9575\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.2463 - f1: 0.9663 - val_loss: 0.2853 - val_f1: 0.9546\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.2127 - f1: 0.9840 - val_loss: 0.1700 - val_f1: 0.9854\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1822 - f1: 0.9890 - val_loss: 0.1262 - val_f1: 0.9987\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 291us/sample - loss: 0.1571 - f1: 0.9919 - val_loss: 0.1679 - val_f1: 0.9799\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 291us/sample - loss: 0.1418 - f1: 0.9946 - val_loss: 0.1067 - val_f1: 0.9973\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 291us/sample - loss: 0.1503 - f1: 0.9929 - val_loss: 0.0869 - val_f1: 0.9992\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1497 - f1: 0.9930 - val_loss: 0.1355 - val_f1: 0.9968\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 291us/sample - loss: 0.1566 - f1: 0.9917 - val_loss: 0.1390 - val_f1: 0.9983\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1076 - f1: 0.9960 - val_loss: 0.0657 - val_f1: 0.9987\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.0930 - f1: 0.9974 - val_loss: 0.1333 - val_f1: 0.9888\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1751 - f1: 0.9920 - val_loss: 0.0697 - val_f1: 1.0000\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1302 - f1: 0.9937 - val_loss: 0.1504 - val_f1: 0.9973\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 9s 473us/sample - loss: 0.1244 - f1: 0.9950 - val_loss: 0.1006 - val_f1: 0.9964\n",
      "Running through fold 3\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 9s 466us/sample - loss: 0.9082 - f1: 0.8108 - val_loss: 0.4170 - val_f1: 0.9382\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 301us/sample - loss: 0.3646 - f1: 0.9398 - val_loss: 0.3088 - val_f1: 0.9513\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.3076 - f1: 0.9489 - val_loss: 0.2602 - val_f1: 0.9553\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2835 - f1: 0.9544 - val_loss: 0.3179 - val_f1: 0.9478\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2525 - f1: 0.9604 - val_loss: 0.1971 - val_f1: 0.9763\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.2484 - f1: 0.9656 - val_loss: 0.2238 - val_f1: 0.9705\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1965 - f1: 0.9805 - val_loss: 0.2357 - val_f1: 0.9839\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1896 - f1: 0.9831 - val_loss: 0.2609 - val_f1: 0.9808\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1746 - f1: 0.9885 - val_loss: 0.1102 - val_f1: 0.9973\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1754 - f1: 0.9880 - val_loss: 0.1103 - val_f1: 0.9967\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1702 - f1: 0.9896 - val_loss: 0.1064 - val_f1: 0.9983\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1346 - f1: 0.9922 - val_loss: 0.2390 - val_f1: 0.9811\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1390 - f1: 0.9932 - val_loss: 0.0813 - val_f1: 0.9983\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1312 - f1: 0.9939 - val_loss: 0.1423 - val_f1: 0.9982\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1766 - f1: 0.9893 - val_loss: 0.1626 - val_f1: 0.9968\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1131 - f1: 0.9955 - val_loss: 0.0867 - val_f1: 0.9990\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1767 - f1: 0.9894 - val_loss: 0.2657 - val_f1: 0.9960\n",
      "Epoch 18/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1187 - f1: 0.9968 - val_loss: 0.0594 - val_f1: 1.0000\n",
      "Epoch 19/2000\n",
      "20000/20000 [==============================] - 9s 474us/sample - loss: 0.1183 - f1: 0.9939 - val_loss: 0.1509 - val_f1: 0.9987\n",
      "Running through fold 4\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 9s 461us/sample - loss: 1.0201 - f1: 0.7666 - val_loss: 0.4674 - val_f1: 0.9063\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 293us/sample - loss: 0.4341 - f1: 0.9167 - val_loss: 0.4197 - val_f1: 0.9328\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.3539 - f1: 0.9328 - val_loss: 0.3641 - val_f1: 0.9367\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.3011 - f1: 0.9506 - val_loss: 0.2941 - val_f1: 0.9463\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.2815 - f1: 0.9539 - val_loss: 0.2575 - val_f1: 0.9513\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 291us/sample - loss: 0.2358 - f1: 0.9655 - val_loss: 0.2259 - val_f1: 0.9704\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2319 - f1: 0.9744 - val_loss: 0.1940 - val_f1: 0.9857\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.2039 - f1: 0.9869 - val_loss: 0.1206 - val_f1: 0.9975\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1615 - f1: 0.9917 - val_loss: 0.1265 - val_f1: 0.9993\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1614 - f1: 0.9913 - val_loss: 0.1188 - val_f1: 0.9977\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1431 - f1: 0.9924 - val_loss: 0.1053 - val_f1: 0.9987\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1610 - f1: 0.9908 - val_loss: 0.1478 - val_f1: 0.9934\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 290us/sample - loss: 0.1410 - f1: 0.9938 - val_loss: 0.1331 - val_f1: 0.9955\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.1632 - f1: 0.9912 - val_loss: 0.1203 - val_f1: 0.9980\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 291us/sample - loss: 0.1282 - f1: 0.9923 - val_loss: 0.3506 - val_f1: 0.9746\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 288us/sample - loss: 0.1298 - f1: 0.9962 - val_loss: 0.1076 - val_f1: 0.9931\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.1468 - f1: 0.9908 - val_loss: 0.2996 - val_f1: 0.9841\n",
      "Epoch 18/2000\n",
      "20000/20000 [==============================] - 10s 476us/sample - loss: 0.1229 - f1: 0.9954 - val_loss: 0.0766 - val_f1: 0.9978\n"
     ]
    }
   ],
   "source": [
    "mlb=LabelBinarizer()\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    print('\\n\\nRunning through training size '+str(train_size))\n",
    "    k_folds_errors = []\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=5, train_size=train_size)\n",
    "    k = 0\n",
    "    for train_index, _ in sss.split(training_spectra, training_keys):\n",
    "        print('Running through fold '+str(k))\n",
    "        training_keys_binarized = mlb.fit_transform(training_keys.reshape([training_keys.shape[0],1]))\n",
    "        testing_keys_binarized = mlb.transform(testing_keys)\n",
    "        model = compile_model(\n",
    "            build_cnn_model,\n",
    "            model_features)\n",
    "\n",
    "        csv_logger = tf.keras.callbacks.CSVLogger('./final-models-keras/'+model_id_save_as+'_trainsize'+str(train_size)+'_fold'+str(k)+'.log')\n",
    "\n",
    "        output = model.fit(\n",
    "            x=training_spectra_scaled[train_index],\n",
    "            y=training_keys_binarized[train_index],\n",
    "            epochs=num_epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(testing_spectra_scaled,\n",
    "                             testing_keys_binarized),\n",
    "            shuffle=True,\n",
    "            callbacks=[earlystop_callback, csv_logger],\n",
    "        )\n",
    "        model.save('./final-models-keras/'+model_id_save_as+'_trainsize'+str(train_size)+'_fold'+str(k)+'.hdf5')\n",
    "        k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36_update)",
   "language": "python",
   "name": "conda_tensorflow_p36_update"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
