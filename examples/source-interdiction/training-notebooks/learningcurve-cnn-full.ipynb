{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_device_id = str(2)\n",
    "model_id_save_as = 'learningcurve-cnn-full-final-reluupdate'\n",
    "architecture_id = '../hyperparameter_search/hyperparameter-search-results/CNN-kfoldsfull-final-2-reluupdate_28'\n",
    "model_class_id = 'CNN1D'\n",
    "testing_dataset_id = '../../source-interdiction/dataset_generation/validation_dataset_full_200keV_log10time_100.npy'\n",
    "training_dataset_id = '../../source-interdiction/dataset_generation/training_dataset_full_200keV_log10time_10000.npy'\n",
    "difficulty_setting = 'full'\n",
    "\n",
    "train_sizes = [10000, 50, 100, 500, 1000, 5000, 15000, 20000, ]\n",
    "earlystop_patience = 10\n",
    "num_epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPU_device_id\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(5)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import model, training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from annsa.model_classes import build_cnn_model, compile_model, f1\n",
    "from annsa.load_dataset import load_easy, load_full, dataset_to_spectrakeys\n",
    "from annsa.load_pretrained_network import load_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = np.load(training_dataset_id)\n",
    "training_spectra, training_keys = dataset_to_spectrakeys(training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = np.load(testing_dataset_id)\n",
    "testing_spectra, testing_keys = dataset_to_spectrakeys(testing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features = load_features(architecture_id)\n",
    "model_features.output_function = tf.nn.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features.cnn_kernels = model_features.cnn_kernel\n",
    "model_features.pool_sizes = model_features.pool_size\n",
    "model_features.loss = tf.keras.losses.categorical_crossentropy\n",
    "model_features.optimizer = tf.keras.optimizers.Adam\n",
    "model_features.metrics = [f1]\n",
    "model_features.dropout_rate = model_features.dropout_probability\n",
    "model_features.output_function = tf.nn.softmax\n",
    "model_features.input_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = compile_model(\n",
    "            build_cnn_model,\n",
    "            model_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_spectra_scaled = model_features.scaler.transform(training_spectra)\n",
    "testing_spectra_scaled = model_features.scaler.transform(testing_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_f1',\n",
    "    patience=earlystop_patience,\n",
    "    mode='max',\n",
    "    min_delta=0.01,\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running through training size 10000\n",
      "Running through fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36_update/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 6s 632us/sample - loss: 3.3193 - f1: 0.0190 - val_loss: 2.6738 - val_f1: 0.0691\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 2.2701 - f1: 0.1299 - val_loss: 1.9334 - val_f1: 0.2116\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 1.7620 - f1: 0.3056 - val_loss: 1.5859 - val_f1: 0.3989\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 1.4928 - f1: 0.4555 - val_loss: 1.3830 - val_f1: 0.5273\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 1.3222 - f1: 0.5589 - val_loss: 1.2359 - val_f1: 0.6094\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 1.1954 - f1: 0.6266 - val_loss: 1.1310 - val_f1: 0.6763\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 1.0919 - f1: 0.6831 - val_loss: 1.0590 - val_f1: 0.7011\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 1.0115 - f1: 0.7246 - val_loss: 0.9764 - val_f1: 0.7400\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.9389 - f1: 0.7570 - val_loss: 0.9206 - val_f1: 0.7662\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.8805 - f1: 0.7848 - val_loss: 0.8548 - val_f1: 0.7884\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.8265 - f1: 0.8038 - val_loss: 0.8266 - val_f1: 0.8086\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.7836 - f1: 0.8222 - val_loss: 0.8089 - val_f1: 0.8066\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.7447 - f1: 0.8334 - val_loss: 0.7465 - val_f1: 0.8362\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.7082 - f1: 0.8474 - val_loss: 0.7250 - val_f1: 0.8403\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.6779 - f1: 0.8570 - val_loss: 0.7018 - val_f1: 0.8503\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.6525 - f1: 0.8688 - val_loss: 0.6740 - val_f1: 0.8590\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.6258 - f1: 0.8744 - val_loss: 0.6583 - val_f1: 0.8628\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.6048 - f1: 0.8808 - val_loss: 0.6296 - val_f1: 0.8740\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.5895 - f1: 0.8843 - val_loss: 0.6277 - val_f1: 0.8784\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.5635 - f1: 0.8941 - val_loss: 0.6036 - val_f1: 0.8821\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.5480 - f1: 0.8983 - val_loss: 0.5947 - val_f1: 0.8842\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.5298 - f1: 0.9031 - val_loss: 0.5684 - val_f1: 0.8854\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.5172 - f1: 0.9058 - val_loss: 0.5669 - val_f1: 0.8917\n",
      "Epoch 24/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.5002 - f1: 0.9111 - val_loss: 0.5478 - val_f1: 0.8911\n",
      "Epoch 25/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.4844 - f1: 0.9140 - val_loss: 0.5414 - val_f1: 0.8941\n",
      "Epoch 26/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.4708 - f1: 0.9192 - val_loss: 0.5282 - val_f1: 0.8994\n",
      "Epoch 27/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.4604 - f1: 0.9224 - val_loss: 0.5094 - val_f1: 0.9025\n",
      "Epoch 28/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.4519 - f1: 0.9228 - val_loss: 0.5195 - val_f1: 0.8996\n",
      "Epoch 29/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.4412 - f1: 0.9252 - val_loss: 0.4968 - val_f1: 0.9073\n",
      "Epoch 30/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.4303 - f1: 0.9278 - val_loss: 0.4940 - val_f1: 0.9021\n",
      "Epoch 31/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.4170 - f1: 0.9337 - val_loss: 0.4883 - val_f1: 0.9027\n",
      "Epoch 32/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.4073 - f1: 0.9348 - val_loss: 0.4655 - val_f1: 0.9149\n",
      "Epoch 33/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.4001 - f1: 0.9355 - val_loss: 0.4770 - val_f1: 0.9084\n",
      "Epoch 34/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.3907 - f1: 0.9374 - val_loss: 0.4629 - val_f1: 0.9105\n",
      "Epoch 35/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.3807 - f1: 0.9402 - val_loss: 0.4498 - val_f1: 0.9190\n",
      "Epoch 36/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.3726 - f1: 0.9428 - val_loss: 0.4485 - val_f1: 0.9103\n",
      "Epoch 37/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.3665 - f1: 0.9441 - val_loss: 0.4439 - val_f1: 0.9095\n",
      "Epoch 38/2000\n",
      "10000/10000 [==============================] - 2s 249us/sample - loss: 0.3587 - f1: 0.9456 - val_loss: 0.4330 - val_f1: 0.9166\n",
      "Epoch 39/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.3498 - f1: 0.9469 - val_loss: 0.4356 - val_f1: 0.9165\n",
      "Epoch 40/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.3443 - f1: 0.9508 - val_loss: 0.4357 - val_f1: 0.9134\n",
      "Epoch 41/2000\n",
      "10000/10000 [==============================] - 2s 250us/sample - loss: 0.3402 - f1: 0.9490 - val_loss: 0.4172 - val_f1: 0.9227\n",
      "Epoch 42/2000\n",
      "10000/10000 [==============================] - 3s 259us/sample - loss: 0.3348 - f1: 0.9494 - val_loss: 0.4295 - val_f1: 0.9125\n",
      "Running through fold 1\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 3s 320us/sample - loss: 3.3266 - f1: 0.0138 - val_loss: 2.7630 - val_f1: 0.0598\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 2.3589 - f1: 0.1094 - val_loss: 2.0346 - val_f1: 0.2102\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 1.8486 - f1: 0.2817 - val_loss: 1.6628 - val_f1: 0.3764\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 1.5642 - f1: 0.4252 - val_loss: 1.4458 - val_f1: 0.4858\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 1.3879 - f1: 0.5194 - val_loss: 1.2972 - val_f1: 0.5865\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 1.2506 - f1: 0.5971 - val_loss: 1.1733 - val_f1: 0.6378\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 1.1449 - f1: 0.6565 - val_loss: 1.0871 - val_f1: 0.6845\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 1.0602 - f1: 0.6990 - val_loss: 1.0162 - val_f1: 0.7228\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.9864 - f1: 0.7325 - val_loss: 0.9537 - val_f1: 0.7511\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.9200 - f1: 0.7651 - val_loss: 0.8827 - val_f1: 0.7786\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.8650 - f1: 0.7890 - val_loss: 0.8335 - val_f1: 0.8005\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.8170 - f1: 0.8055 - val_loss: 0.7928 - val_f1: 0.8158\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.7745 - f1: 0.8216 - val_loss: 0.7403 - val_f1: 0.8379\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.7346 - f1: 0.8365 - val_loss: 0.7181 - val_f1: 0.8434\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.7042 - f1: 0.8487 - val_loss: 0.7000 - val_f1: 0.8511\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.6696 - f1: 0.8577 - val_loss: 0.6647 - val_f1: 0.8657\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.6443 - f1: 0.8683 - val_loss: 0.6364 - val_f1: 0.8786\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.6168 - f1: 0.8762 - val_loss: 0.6113 - val_f1: 0.8834\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.5985 - f1: 0.8839 - val_loss: 0.6000 - val_f1: 0.8864\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.5752 - f1: 0.8900 - val_loss: 0.5890 - val_f1: 0.8828\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.5589 - f1: 0.8953 - val_loss: 0.5706 - val_f1: 0.8921\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.5433 - f1: 0.8986 - val_loss: 0.5540 - val_f1: 0.8956\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.5210 - f1: 0.9061 - val_loss: 0.5490 - val_f1: 0.8964\n",
      "Epoch 24/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.5099 - f1: 0.9100 - val_loss: 0.5450 - val_f1: 0.8979\n",
      "Epoch 25/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.4982 - f1: 0.9101 - val_loss: 0.5121 - val_f1: 0.9125\n",
      "Epoch 26/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.4821 - f1: 0.9185 - val_loss: 0.5018 - val_f1: 0.9099\n",
      "Epoch 27/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.4668 - f1: 0.9187 - val_loss: 0.4955 - val_f1: 0.9092\n",
      "Epoch 28/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.4565 - f1: 0.9230 - val_loss: 0.4903 - val_f1: 0.9064\n",
      "Epoch 29/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.4447 - f1: 0.9237 - val_loss: 0.4717 - val_f1: 0.9168\n",
      "Epoch 30/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.4334 - f1: 0.9292 - val_loss: 0.4772 - val_f1: 0.9126\n",
      "Epoch 31/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.4220 - f1: 0.9308 - val_loss: 0.4607 - val_f1: 0.9174\n",
      "Epoch 32/2000\n",
      "10000/10000 [==============================] - 3s 250us/sample - loss: 0.4196 - f1: 0.9316 - val_loss: 0.4671 - val_f1: 0.9108\n",
      "Epoch 33/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.4028 - f1: 0.9345 - val_loss: 0.4682 - val_f1: 0.9091\n",
      "Epoch 34/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.4000 - f1: 0.9346 - val_loss: 0.4367 - val_f1: 0.9213\n",
      "Epoch 35/2000\n",
      "10000/10000 [==============================] - 3s 265us/sample - loss: 0.3900 - f1: 0.9374 - val_loss: 0.4364 - val_f1: 0.9167\n",
      "Running through fold 2\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 3s 330us/sample - loss: 3.1541 - f1: 0.0239 - val_loss: 2.4277 - val_f1: 0.0903\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 2.1006 - f1: 0.1787 - val_loss: 1.8139 - val_f1: 0.2675\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 1.6708 - f1: 0.3497 - val_loss: 1.5025 - val_f1: 0.4486\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 1.4309 - f1: 0.4972 - val_loss: 1.3137 - val_f1: 0.5872\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 1.2653 - f1: 0.5949 - val_loss: 1.1831 - val_f1: 0.6509\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 1.1456 - f1: 0.6638 - val_loss: 1.0820 - val_f1: 0.7012\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 1.0509 - f1: 0.7096 - val_loss: 1.0080 - val_f1: 0.7351\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.9731 - f1: 0.7465 - val_loss: 0.9405 - val_f1: 0.7584\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.9099 - f1: 0.7707 - val_loss: 0.8913 - val_f1: 0.7767\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.8534 - f1: 0.7936 - val_loss: 0.8396 - val_f1: 0.7905\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.8083 - f1: 0.8084 - val_loss: 0.7986 - val_f1: 0.8108\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.7617 - f1: 0.8270 - val_loss: 0.7696 - val_f1: 0.8181\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.7267 - f1: 0.8396 - val_loss: 0.7316 - val_f1: 0.8338\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.6929 - f1: 0.8500 - val_loss: 0.6970 - val_f1: 0.8452\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.6609 - f1: 0.8622 - val_loss: 0.6782 - val_f1: 0.8509\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.6339 - f1: 0.8701 - val_loss: 0.6757 - val_f1: 0.8535\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.6116 - f1: 0.8779 - val_loss: 0.6231 - val_f1: 0.8722\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.5861 - f1: 0.8857 - val_loss: 0.6076 - val_f1: 0.8771\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.5662 - f1: 0.8925 - val_loss: 0.5896 - val_f1: 0.8825\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.5485 - f1: 0.8958 - val_loss: 0.5791 - val_f1: 0.8858\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.5216 - f1: 0.9055 - val_loss: 0.5636 - val_f1: 0.8917\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.5106 - f1: 0.9059 - val_loss: 0.5478 - val_f1: 0.8925\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.4959 - f1: 0.9084 - val_loss: 0.5343 - val_f1: 0.8961\n",
      "Epoch 24/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.4805 - f1: 0.9139 - val_loss: 0.5235 - val_f1: 0.8969\n",
      "Epoch 25/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.4655 - f1: 0.9182 - val_loss: 0.5174 - val_f1: 0.8973\n",
      "Epoch 26/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.4571 - f1: 0.9188 - val_loss: 0.4956 - val_f1: 0.9032\n",
      "Epoch 27/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.4409 - f1: 0.9230 - val_loss: 0.4996 - val_f1: 0.9042\n",
      "Epoch 28/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.4316 - f1: 0.9282 - val_loss: 0.4749 - val_f1: 0.9091\n",
      "Epoch 29/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.4217 - f1: 0.9284 - val_loss: 0.4795 - val_f1: 0.9068\n",
      "Epoch 30/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.4107 - f1: 0.9324 - val_loss: 0.4634 - val_f1: 0.9116\n",
      "Epoch 31/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.4008 - f1: 0.9310 - val_loss: 0.4610 - val_f1: 0.9109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.3896 - f1: 0.9352 - val_loss: 0.4580 - val_f1: 0.9073\n",
      "Epoch 33/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.3832 - f1: 0.9375 - val_loss: 0.4571 - val_f1: 0.9064\n",
      "Epoch 34/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.3784 - f1: 0.9368 - val_loss: 0.4539 - val_f1: 0.9059\n",
      "Epoch 35/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.3693 - f1: 0.9387 - val_loss: 0.4419 - val_f1: 0.9108\n",
      "Epoch 36/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.3585 - f1: 0.9406 - val_loss: 0.4270 - val_f1: 0.9147\n",
      "Epoch 37/2000\n",
      "10000/10000 [==============================] - 3s 251us/sample - loss: 0.3515 - f1: 0.9420 - val_loss: 0.4289 - val_f1: 0.9137\n",
      "Epoch 38/2000\n",
      "10000/10000 [==============================] - 3s 271us/sample - loss: 0.3497 - f1: 0.9412 - val_loss: 0.4258 - val_f1: 0.9117\n",
      "Running through fold 3\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 3s 334us/sample - loss: 3.2071 - f1: 0.0264 - val_loss: 2.5507 - val_f1: 0.0992\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 2.2285 - f1: 0.1684 - val_loss: 1.9359 - val_f1: 0.2418\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 1.7776 - f1: 0.3124 - val_loss: 1.6035 - val_f1: 0.3652\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 1.5184 - f1: 0.4322 - val_loss: 1.4018 - val_f1: 0.5117\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 1.3372 - f1: 0.5495 - val_loss: 1.2485 - val_f1: 0.6175\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 1.2043 - f1: 0.6358 - val_loss: 1.1350 - val_f1: 0.6782\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 1.1056 - f1: 0.6876 - val_loss: 1.0440 - val_f1: 0.7207\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 1.0271 - f1: 0.7197 - val_loss: 0.9796 - val_f1: 0.7343\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.9580 - f1: 0.7525 - val_loss: 0.9276 - val_f1: 0.7601\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.9005 - f1: 0.7743 - val_loss: 0.8779 - val_f1: 0.7750\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.8578 - f1: 0.7909 - val_loss: 0.8379 - val_f1: 0.7887\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.8103 - f1: 0.8047 - val_loss: 0.7970 - val_f1: 0.8021\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.7750 - f1: 0.8161 - val_loss: 0.7634 - val_f1: 0.8190\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.7385 - f1: 0.8321 - val_loss: 0.7373 - val_f1: 0.8278\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.7096 - f1: 0.8443 - val_loss: 0.6959 - val_f1: 0.8457\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.6790 - f1: 0.8554 - val_loss: 0.6863 - val_f1: 0.8439\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.6568 - f1: 0.8629 - val_loss: 0.6698 - val_f1: 0.8527\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.6335 - f1: 0.8686 - val_loss: 0.6376 - val_f1: 0.8664\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.6079 - f1: 0.8801 - val_loss: 0.6206 - val_f1: 0.8737\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.5873 - f1: 0.8861 - val_loss: 0.5953 - val_f1: 0.8794\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.5708 - f1: 0.8925 - val_loss: 0.5806 - val_f1: 0.8858\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 3s 252us/sample - loss: 0.5546 - f1: 0.8953 - val_loss: 0.5764 - val_f1: 0.8881\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.5394 - f1: 0.8998 - val_loss: 0.5482 - val_f1: 0.8934\n",
      "Epoch 24/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.5212 - f1: 0.9058 - val_loss: 0.5400 - val_f1: 0.8924\n",
      "Epoch 25/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.5088 - f1: 0.9073 - val_loss: 0.5310 - val_f1: 0.8968\n",
      "Epoch 26/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.4955 - f1: 0.9104 - val_loss: 0.5184 - val_f1: 0.9003\n",
      "Epoch 27/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.4803 - f1: 0.9171 - val_loss: 0.5208 - val_f1: 0.9033\n",
      "Epoch 28/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.4714 - f1: 0.9197 - val_loss: 0.5115 - val_f1: 0.8995\n",
      "Epoch 29/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.4586 - f1: 0.9187 - val_loss: 0.4933 - val_f1: 0.9093\n",
      "Epoch 30/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.4490 - f1: 0.9244 - val_loss: 0.4885 - val_f1: 0.9034\n",
      "Epoch 31/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.4378 - f1: 0.9250 - val_loss: 0.4724 - val_f1: 0.9071\n",
      "Epoch 32/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.4329 - f1: 0.9251 - val_loss: 0.4946 - val_f1: 0.9069\n",
      "Epoch 33/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.4189 - f1: 0.9288 - val_loss: 0.4725 - val_f1: 0.9116\n",
      "Epoch 34/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.4136 - f1: 0.9319 - val_loss: 0.4596 - val_f1: 0.9097\n",
      "Epoch 35/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.4009 - f1: 0.9348 - val_loss: 0.4653 - val_f1: 0.9050\n",
      "Epoch 36/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.3920 - f1: 0.9336 - val_loss: 0.4438 - val_f1: 0.9137\n",
      "Epoch 37/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.3888 - f1: 0.9385 - val_loss: 0.4446 - val_f1: 0.9120\n",
      "Epoch 38/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.3795 - f1: 0.9389 - val_loss: 0.4514 - val_f1: 0.9099\n",
      "Epoch 39/2000\n",
      "10000/10000 [==============================] - 3s 279us/sample - loss: 0.3715 - f1: 0.9402 - val_loss: 0.4412 - val_f1: 0.9129\n",
      "Running through fold 4\n",
      "Train on 10000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "10000/10000 [==============================] - 3s 338us/sample - loss: 3.2126 - f1: 0.0227 - val_loss: 2.5147 - val_f1: 0.0795\n",
      "Epoch 2/2000\n",
      "10000/10000 [==============================] - 3s 255us/sample - loss: 2.1690 - f1: 0.1477 - val_loss: 1.8685 - val_f1: 0.2548\n",
      "Epoch 3/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 1.7098 - f1: 0.3284 - val_loss: 1.5579 - val_f1: 0.3960\n",
      "Epoch 4/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 1.4610 - f1: 0.4618 - val_loss: 1.3562 - val_f1: 0.5028\n",
      "Epoch 5/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 1.2870 - f1: 0.5598 - val_loss: 1.2148 - val_f1: 0.6112\n",
      "Epoch 6/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 1.1610 - f1: 0.6401 - val_loss: 1.1159 - val_f1: 0.6692\n",
      "Epoch 7/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 1.0610 - f1: 0.6969 - val_loss: 1.0204 - val_f1: 0.7166\n",
      "Epoch 8/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.9777 - f1: 0.7393 - val_loss: 0.9574 - val_f1: 0.7529\n",
      "Epoch 9/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.9101 - f1: 0.7716 - val_loss: 0.8912 - val_f1: 0.7711\n",
      "Epoch 10/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.8547 - f1: 0.7934 - val_loss: 0.8536 - val_f1: 0.7884\n",
      "Epoch 11/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.8085 - f1: 0.8094 - val_loss: 0.8162 - val_f1: 0.8084\n",
      "Epoch 12/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.7748 - f1: 0.8209 - val_loss: 0.7690 - val_f1: 0.8187\n",
      "Epoch 13/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.7298 - f1: 0.8392 - val_loss: 0.7476 - val_f1: 0.8291\n",
      "Epoch 14/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.7001 - f1: 0.8462 - val_loss: 0.7142 - val_f1: 0.8350\n",
      "Epoch 15/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.6729 - f1: 0.8562 - val_loss: 0.6892 - val_f1: 0.8508\n",
      "Epoch 16/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.6473 - f1: 0.8636 - val_loss: 0.6836 - val_f1: 0.8491\n",
      "Epoch 17/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.6226 - f1: 0.8703 - val_loss: 0.6558 - val_f1: 0.8588\n",
      "Epoch 18/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.6044 - f1: 0.8754 - val_loss: 0.6463 - val_f1: 0.8593\n",
      "Epoch 19/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.5865 - f1: 0.8805 - val_loss: 0.6158 - val_f1: 0.8692\n",
      "Epoch 20/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.5672 - f1: 0.8861 - val_loss: 0.6164 - val_f1: 0.8706\n",
      "Epoch 21/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.5453 - f1: 0.8937 - val_loss: 0.5884 - val_f1: 0.8757\n",
      "Epoch 22/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.5337 - f1: 0.8954 - val_loss: 0.5779 - val_f1: 0.8809\n",
      "Epoch 23/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.5182 - f1: 0.9012 - val_loss: 0.5665 - val_f1: 0.8818\n",
      "Epoch 24/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.5053 - f1: 0.9029 - val_loss: 0.5630 - val_f1: 0.8840\n",
      "Epoch 25/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.4953 - f1: 0.9069 - val_loss: 0.5413 - val_f1: 0.8848\n",
      "Epoch 26/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.4799 - f1: 0.9104 - val_loss: 0.5351 - val_f1: 0.8907\n",
      "Epoch 27/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.4678 - f1: 0.9132 - val_loss: 0.5385 - val_f1: 0.8835\n",
      "Epoch 28/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.4545 - f1: 0.9182 - val_loss: 0.5144 - val_f1: 0.8942\n",
      "Epoch 29/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.4460 - f1: 0.9192 - val_loss: 0.5038 - val_f1: 0.8952\n",
      "Epoch 30/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.4350 - f1: 0.9227 - val_loss: 0.5046 - val_f1: 0.8977\n",
      "Epoch 31/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.4246 - f1: 0.9249 - val_loss: 0.4812 - val_f1: 0.9040\n",
      "Epoch 32/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.4179 - f1: 0.9263 - val_loss: 0.4780 - val_f1: 0.9041\n",
      "Epoch 33/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.4074 - f1: 0.9286 - val_loss: 0.4854 - val_f1: 0.8982\n",
      "Epoch 34/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.4019 - f1: 0.9305 - val_loss: 0.4710 - val_f1: 0.9007\n",
      "Epoch 35/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.3903 - f1: 0.9331 - val_loss: 0.4627 - val_f1: 0.9071\n",
      "Epoch 36/2000\n",
      "10000/10000 [==============================] - 3s 255us/sample - loss: 0.3857 - f1: 0.9334 - val_loss: 0.4499 - val_f1: 0.9119\n",
      "Epoch 37/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.3762 - f1: 0.9370 - val_loss: 0.4477 - val_f1: 0.9057\n",
      "Epoch 38/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.3709 - f1: 0.9373 - val_loss: 0.4471 - val_f1: 0.9075\n",
      "Epoch 39/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.3623 - f1: 0.9389 - val_loss: 0.4413 - val_f1: 0.9075\n",
      "Epoch 40/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.3524 - f1: 0.9440 - val_loss: 0.4361 - val_f1: 0.9086\n",
      "Epoch 41/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.3520 - f1: 0.9406 - val_loss: 0.4405 - val_f1: 0.9040\n",
      "Epoch 42/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.3428 - f1: 0.9446 - val_loss: 0.4418 - val_f1: 0.9079\n",
      "Epoch 43/2000\n",
      "10000/10000 [==============================] - 3s 254us/sample - loss: 0.3385 - f1: 0.9452 - val_loss: 0.4191 - val_f1: 0.9130\n",
      "Epoch 44/2000\n",
      "10000/10000 [==============================] - 3s 253us/sample - loss: 0.3323 - f1: 0.9450 - val_loss: 0.4181 - val_f1: 0.9143\n",
      "Epoch 45/2000\n",
      "10000/10000 [==============================] - 3s 282us/sample - loss: 0.3233 - f1: 0.9504 - val_loss: 0.4123 - val_f1: 0.9109\n",
      "\n",
      "\n",
      "Running through training size 50\n",
      "Running through fold 0\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 22ms/sample - loss: 3.9077 - f1: 0.0000e+00 - val_loss: 3.8963 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8796 - f1: 0.0000e+00 - val_loss: 3.8860 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8619 - f1: 0.0000e+00 - val_loss: 3.8777 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8354 - f1: 0.0000e+00 - val_loss: 3.8713 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8273 - f1: 0.0000e+00 - val_loss: 3.8659 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8079 - f1: 0.0000e+00 - val_loss: 3.8604 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7817 - f1: 0.0000e+00 - val_loss: 3.8554 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7622 - f1: 0.0000e+00 - val_loss: 3.8510 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7663 - f1: 0.0000e+00 - val_loss: 3.8466 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7431 - f1: 0.0000e+00 - val_loss: 3.8426 - val_f1: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 1s 13ms/sample - loss: 3.7290 - f1: 0.0000e+00 - val_loss: 3.8394 - val_f1: 0.0000e+00\n",
      "Running through fold 1\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 23ms/sample - loss: 3.8910 - f1: 0.0000e+00 - val_loss: 3.8788 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8707 - f1: 0.0000e+00 - val_loss: 3.8740 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8585 - f1: 0.0000e+00 - val_loss: 3.8698 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8434 - f1: 0.0000e+00 - val_loss: 3.8655 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8324 - f1: 0.0000e+00 - val_loss: 3.8608 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8201 - f1: 0.0000e+00 - val_loss: 3.8566 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8143 - f1: 0.0000e+00 - val_loss: 3.8529 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7934 - f1: 0.0000e+00 - val_loss: 3.8495 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7863 - f1: 0.0000e+00 - val_loss: 3.8461 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7803 - f1: 0.0000e+00 - val_loss: 3.8430 - val_f1: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 1s 14ms/sample - loss: 3.7711 - f1: 0.0000e+00 - val_loss: 3.8401 - val_f1: 0.0000e+00\n",
      "Running through fold 2\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 25ms/sample - loss: 3.8930 - f1: 0.0000e+00 - val_loss: 3.8831 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8652 - f1: 0.0000e+00 - val_loss: 3.8736 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8420 - f1: 0.0000e+00 - val_loss: 3.8658 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8291 - f1: 0.0000e+00 - val_loss: 3.8594 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8044 - f1: 0.0000e+00 - val_loss: 3.8539 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7962 - f1: 0.0000e+00 - val_loss: 3.8483 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7838 - f1: 0.0000e+00 - val_loss: 3.8431 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7658 - f1: 0.0000e+00 - val_loss: 3.8380 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7526 - f1: 0.0000e+00 - val_loss: 3.8329 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7397 - f1: 0.0000e+00 - val_loss: 3.8278 - val_f1: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 1s 15ms/sample - loss: 3.7256 - f1: 0.0000e+00 - val_loss: 3.8229 - val_f1: 0.0000e+00\n",
      "Running through fold 3\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 25ms/sample - loss: 3.9088 - f1: 0.0000e+00 - val_loss: 3.8873 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8791 - f1: 0.0000e+00 - val_loss: 3.8793 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8593 - f1: 0.0000e+00 - val_loss: 3.8724 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8393 - f1: 0.0000e+00 - val_loss: 3.8663 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8252 - f1: 0.0000e+00 - val_loss: 3.8610 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8130 - f1: 0.0000e+00 - val_loss: 3.8565 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7897 - f1: 0.0000e+00 - val_loss: 3.8529 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7810 - f1: 0.0000e+00 - val_loss: 3.8495 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7613 - f1: 0.0000e+00 - val_loss: 3.8455 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7500 - f1: 0.0000e+00 - val_loss: 3.8413 - val_f1: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 1s 17ms/sample - loss: 3.7384 - f1: 0.0000e+00 - val_loss: 3.8376 - val_f1: 0.0000e+00\n",
      "Running through fold 4\n",
      "Train on 50 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "50/50 [==============================] - 1s 27ms/sample - loss: 3.9066 - f1: 0.0000e+00 - val_loss: 3.8823 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8773 - f1: 0.0000e+00 - val_loss: 3.8728 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8615 - f1: 0.0000e+00 - val_loss: 3.8647 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8414 - f1: 0.0000e+00 - val_loss: 3.8579 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8239 - f1: 0.0000e+00 - val_loss: 3.8515 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8132 - f1: 0.0000e+00 - val_loss: 3.8454 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.8062 - f1: 0.0000e+00 - val_loss: 3.8399 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7825 - f1: 0.0000e+00 - val_loss: 3.8345 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7724 - f1: 0.0000e+00 - val_loss: 3.8296 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "50/50 [==============================] - 0s 6ms/sample - loss: 3.7562 - f1: 0.0000e+00 - val_loss: 3.8245 - val_f1: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "50/50 [==============================] - 1s 18ms/sample - loss: 3.7372 - f1: 0.0000e+00 - val_loss: 3.8201 - val_f1: 0.0000e+00\n",
      "\n",
      "\n",
      "Running through training size 100\n",
      "Running through fold 0\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 1s 14ms/sample - loss: 3.9013 - f1: 0.0000e+00 - val_loss: 3.8830 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8714 - f1: 0.0000e+00 - val_loss: 3.8718 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8514 - f1: 0.0000e+00 - val_loss: 3.8621 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8334 - f1: 0.0000e+00 - val_loss: 3.8539 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8230 - f1: 0.0000e+00 - val_loss: 3.8474 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8032 - f1: 0.0000e+00 - val_loss: 3.8417 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7968 - f1: 0.0000e+00 - val_loss: 3.8361 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7748 - f1: 0.0000e+00 - val_loss: 3.8301 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7673 - f1: 0.0000e+00 - val_loss: 3.8237 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7531 - f1: 0.0000e+00 - val_loss: 3.8170 - val_f1: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 1s 10ms/sample - loss: 3.7387 - f1: 0.0000e+00 - val_loss: 3.8082 - val_f1: 0.0000e+00\n",
      "Running through fold 1\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 1s 15ms/sample - loss: 3.8902 - f1: 0.0000e+00 - val_loss: 3.8776 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8691 - f1: 0.0000e+00 - val_loss: 3.8682 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8532 - f1: 0.0000e+00 - val_loss: 3.8609 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8338 - f1: 0.0000e+00 - val_loss: 3.8532 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8279 - f1: 0.0000e+00 - val_loss: 3.8437 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8201 - f1: 0.0000e+00 - val_loss: 3.8356 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8015 - f1: 0.0000e+00 - val_loss: 3.8272 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7912 - f1: 0.0000e+00 - val_loss: 3.8186 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7797 - f1: 0.0000e+00 - val_loss: 3.8102 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7644 - f1: 0.0000e+00 - val_loss: 3.8038 - val_f1: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 1s 11ms/sample - loss: 3.7536 - f1: 0.0000e+00 - val_loss: 3.7957 - val_f1: 0.0000e+00\n",
      "Running through fold 2\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 2s 16ms/sample - loss: 3.9040 - f1: 0.0000e+00 - val_loss: 3.8759 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8765 - f1: 0.0000e+00 - val_loss: 3.8639 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8556 - f1: 0.0000e+00 - val_loss: 3.8528 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8321 - f1: 0.0000e+00 - val_loss: 3.8432 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8208 - f1: 0.0000e+00 - val_loss: 3.8353 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.8108 - f1: 0.0000e+00 - val_loss: 3.8269 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.7949 - f1: 0.0000e+00 - val_loss: 3.8191 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7816 - f1: 0.0000e+00 - val_loss: 3.8115 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7706 - f1: 0.0000e+00 - val_loss: 3.8030 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7548 - f1: 0.0000e+00 - val_loss: 3.7938 - val_f1: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 1s 11ms/sample - loss: 3.7412 - f1: 0.0000e+00 - val_loss: 3.7843 - val_f1: 0.0000e+00\n",
      "Running through fold 3\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 2s 16ms/sample - loss: 3.9047 - f1: 0.0000e+00 - val_loss: 3.8809 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8813 - f1: 0.0000e+00 - val_loss: 3.8707 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8625 - f1: 0.0000e+00 - val_loss: 3.8634 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8387 - f1: 0.0000e+00 - val_loss: 3.8569 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8357 - f1: 0.0000e+00 - val_loss: 3.8514 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8271 - f1: 0.0000e+00 - val_loss: 3.8451 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8187 - f1: 0.0000e+00 - val_loss: 3.8373 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8069 - f1: 0.0000e+00 - val_loss: 3.8292 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.7989 - f1: 0.0000e+00 - val_loss: 3.8210 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 3ms/sample - loss: 3.7889 - f1: 0.0000e+00 - val_loss: 3.8125 - val_f1: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 1s 12ms/sample - loss: 3.7651 - f1: 0.0000e+00 - val_loss: 3.8039 - val_f1: 0.0000e+00\n",
      "Running through fold 4\n",
      "Train on 100 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "100/100 [==============================] - 2s 17ms/sample - loss: 3.9011 - f1: 0.0000e+00 - val_loss: 3.8832 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8697 - f1: 0.0000e+00 - val_loss: 3.8746 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8593 - f1: 0.0000e+00 - val_loss: 3.8658 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8494 - f1: 0.0000e+00 - val_loss: 3.8576 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8351 - f1: 0.0000e+00 - val_loss: 3.8499 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8302 - f1: 0.0000e+00 - val_loss: 3.8422 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8113 - f1: 0.0000e+00 - val_loss: 3.8345 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.8035 - f1: 0.0000e+00 - val_loss: 3.8262 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.7898 - f1: 0.0000e+00 - val_loss: 3.8173 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "100/100 [==============================] - 0s 4ms/sample - loss: 3.7726 - f1: 0.0000e+00 - val_loss: 3.8090 - val_f1: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "100/100 [==============================] - 1s 13ms/sample - loss: 3.7642 - f1: 0.0000e+00 - val_loss: 3.8010 - val_f1: 0.0000e+00\n",
      "\n",
      "\n",
      "Running through training size 500\n",
      "Running through fold 0\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 3.8838 - f1: 0.0000e+00 - val_loss: 3.8446 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 934us/sample - loss: 3.8269 - f1: 0.0000e+00 - val_loss: 3.8007 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 899us/sample - loss: 3.7804 - f1: 0.0000e+00 - val_loss: 3.7523 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 874us/sample - loss: 3.7311 - f1: 0.0000e+00 - val_loss: 3.6938 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 868us/sample - loss: 3.6585 - f1: 0.0000e+00 - val_loss: 3.6115 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 3.5620 - f1: 0.0000e+00 - val_loss: 3.5017 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 855us/sample - loss: 3.4365 - f1: 0.0000e+00 - val_loss: 3.3919 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 856us/sample - loss: 3.3257 - f1: 0.0000e+00 - val_loss: 3.2908 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 855us/sample - loss: 3.2420 - f1: 0.0000e+00 - val_loss: 3.2090 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 3.1593 - f1: 0.0000e+00 - val_loss: 3.1390 - val_f1: 6.4475e-04\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 1s 3ms/sample - loss: 3.0946 - f1: 0.0114 - val_loss: 3.0830 - val_f1: 0.0064\n",
      "Running through fold 1\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 3.8772 - f1: 0.0000e+00 - val_loss: 3.8337 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 3.8108 - f1: 0.0000e+00 - val_loss: 3.7782 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 3.7561 - f1: 0.0000e+00 - val_loss: 3.7164 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 3.6931 - f1: 0.0000e+00 - val_loss: 3.6416 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 841us/sample - loss: 3.6012 - f1: 0.0000e+00 - val_loss: 3.5507 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 839us/sample - loss: 3.4984 - f1: 0.0000e+00 - val_loss: 3.4497 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 838us/sample - loss: 3.4009 - f1: 0.0000e+00 - val_loss: 3.3744 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 833us/sample - loss: 3.3277 - f1: 0.0000e+00 - val_loss: 3.2997 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 828us/sample - loss: 3.2504 - f1: 0.0000e+00 - val_loss: 3.2309 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 831us/sample - loss: 3.1939 - f1: 0.0000e+00 - val_loss: 3.1738 - val_f1: 0.0071\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 3.1133 - f1: 0.0114 - val_loss: 3.1289 - val_f1: 0.0096\n",
      "Running through fold 2\n",
      "Train on 500 samples, validate on 3000 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 3.8780 - f1: 0.0000e+00 - val_loss: 3.8362 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 939us/sample - loss: 3.8227 - f1: 0.0000e+00 - val_loss: 3.7958 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 908us/sample - loss: 3.7701 - f1: 0.0000e+00 - val_loss: 3.7486 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 903us/sample - loss: 3.7138 - f1: 0.0000e+00 - val_loss: 3.6886 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 880us/sample - loss: 3.6370 - f1: 0.0000e+00 - val_loss: 3.6147 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 867us/sample - loss: 3.5594 - f1: 0.0000e+00 - val_loss: 3.5193 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 868us/sample - loss: 3.4487 - f1: 0.0000e+00 - val_loss: 3.4227 - val_f1: 0.0026\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 864us/sample - loss: 3.3337 - f1: 0.0038 - val_loss: 3.3252 - val_f1: 0.0131\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 857us/sample - loss: 3.2428 - f1: 0.0114 - val_loss: 3.2420 - val_f1: 0.0162\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 3.1715 - f1: 0.0189 - val_loss: 3.1741 - val_f1: 0.0299\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 0s 858us/sample - loss: 3.0815 - f1: 0.0394 - val_loss: 3.1017 - val_f1: 0.0465\n",
      "Epoch 12/2000\n",
      "500/500 [==============================] - 0s 855us/sample - loss: 3.0139 - f1: 0.0406 - val_loss: 3.0368 - val_f1: 0.0387\n",
      "Epoch 13/2000\n",
      "500/500 [==============================] - 0s 856us/sample - loss: 2.9367 - f1: 0.0508 - val_loss: 2.9727 - val_f1: 0.0679\n",
      "Epoch 14/2000\n",
      "500/500 [==============================] - 0s 849us/sample - loss: 2.8678 - f1: 0.0756 - val_loss: 2.9144 - val_f1: 0.0778\n",
      "Epoch 15/2000\n",
      "500/500 [==============================] - 0s 856us/sample - loss: 2.8073 - f1: 0.0767 - val_loss: 2.8643 - val_f1: 0.0671\n",
      "Epoch 16/2000\n",
      "500/500 [==============================] - 0s 856us/sample - loss: 2.7331 - f1: 0.0831 - val_loss: 2.8093 - val_f1: 0.0797\n",
      "Epoch 17/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 2.6835 - f1: 0.0835 - val_loss: 2.7601 - val_f1: 0.0829\n",
      "Epoch 18/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 2.6351 - f1: 0.0940 - val_loss: 2.7295 - val_f1: 0.0804\n",
      "Epoch 19/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 2.5772 - f1: 0.1134 - val_loss: 2.6827 - val_f1: 0.1090\n",
      "Epoch 20/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 2.5393 - f1: 0.1151 - val_loss: 2.6430 - val_f1: 0.1222\n",
      "Epoch 21/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 2.4901 - f1: 0.1244 - val_loss: 2.6035 - val_f1: 0.1267\n",
      "Epoch 22/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 2.4428 - f1: 0.1459 - val_loss: 2.5680 - val_f1: 0.1344\n",
      "Epoch 23/2000\n",
      "500/500 [==============================] - 0s 853us/sample - loss: 2.4055 - f1: 0.1527 - val_loss: 2.5365 - val_f1: 0.1343\n",
      "Epoch 24/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 2.3668 - f1: 0.1805 - val_loss: 2.5098 - val_f1: 0.1400\n",
      "Epoch 25/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 2.3341 - f1: 0.1738 - val_loss: 2.4737 - val_f1: 0.1506\n",
      "Epoch 26/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 2.2862 - f1: 0.1760 - val_loss: 2.4429 - val_f1: 0.1548\n",
      "Epoch 27/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 2.2589 - f1: 0.1805 - val_loss: 2.4168 - val_f1: 0.1558\n",
      "Epoch 28/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 2.2170 - f1: 0.1750 - val_loss: 2.3884 - val_f1: 0.1547\n",
      "Epoch 29/2000\n",
      "500/500 [==============================] - 0s 853us/sample - loss: 2.1884 - f1: 0.2067 - val_loss: 2.3657 - val_f1: 0.1632\n",
      "Epoch 30/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 2.1597 - f1: 0.1991 - val_loss: 2.3414 - val_f1: 0.1628\n",
      "Epoch 31/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 2.1292 - f1: 0.1990 - val_loss: 2.3152 - val_f1: 0.1707\n",
      "Epoch 32/2000\n",
      "500/500 [==============================] - 0s 857us/sample - loss: 2.0847 - f1: 0.2171 - val_loss: 2.2861 - val_f1: 0.1746\n",
      "Epoch 33/2000\n",
      "500/500 [==============================] - 0s 849us/sample - loss: 2.0569 - f1: 0.2071 - val_loss: 2.2662 - val_f1: 0.1743\n",
      "Epoch 34/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 2.0335 - f1: 0.2222 - val_loss: 2.2396 - val_f1: 0.1866\n",
      "Epoch 35/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 2.0018 - f1: 0.2409 - val_loss: 2.2242 - val_f1: 0.1833\n",
      "Epoch 36/2000\n",
      "500/500 [==============================] - 0s 849us/sample - loss: 1.9870 - f1: 0.2184 - val_loss: 2.2002 - val_f1: 0.1859\n",
      "Epoch 37/2000\n",
      "500/500 [==============================] - 0s 853us/sample - loss: 1.9621 - f1: 0.2263 - val_loss: 2.1736 - val_f1: 0.1931\n",
      "Epoch 38/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 1.9336 - f1: 0.2462 - val_loss: 2.1581 - val_f1: 0.1942\n",
      "Epoch 39/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 1.8914 - f1: 0.2523 - val_loss: 2.1341 - val_f1: 0.1960\n",
      "Epoch 40/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 1.8910 - f1: 0.2291 - val_loss: 2.1165 - val_f1: 0.1974\n",
      "Epoch 41/2000\n",
      "500/500 [==============================] - 0s 855us/sample - loss: 1.8641 - f1: 0.2683 - val_loss: 2.0955 - val_f1: 0.2114\n",
      "Epoch 42/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 1.8525 - f1: 0.2578 - val_loss: 2.0830 - val_f1: 0.2207\n",
      "Epoch 43/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 1.8108 - f1: 0.2789 - val_loss: 2.0562 - val_f1: 0.2251\n",
      "Epoch 44/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 1.7763 - f1: 0.2958 - val_loss: 2.0377 - val_f1: 0.2313\n",
      "Epoch 45/2000\n",
      "500/500 [==============================] - 0s 853us/sample - loss: 1.7662 - f1: 0.2840 - val_loss: 2.0194 - val_f1: 0.2478\n",
      "Epoch 46/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 1.7656 - f1: 0.3050 - val_loss: 2.0148 - val_f1: 0.2351\n",
      "Epoch 47/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 1.7270 - f1: 0.3025 - val_loss: 1.9908 - val_f1: 0.2547\n",
      "Epoch 48/2000\n",
      "500/500 [==============================] - 0s 854us/sample - loss: 1.7060 - f1: 0.3224 - val_loss: 1.9745 - val_f1: 0.2582\n",
      "Epoch 49/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 1.6823 - f1: 0.3416 - val_loss: 1.9578 - val_f1: 0.2564\n",
      "Epoch 50/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 1.6714 - f1: 0.3207 - val_loss: 1.9533 - val_f1: 0.2813\n",
      "Epoch 51/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 1.6511 - f1: 0.3341 - val_loss: 1.9284 - val_f1: 0.2741\n",
      "Epoch 52/2000\n",
      "500/500 [==============================] - 0s 841us/sample - loss: 1.6262 - f1: 0.3781 - val_loss: 1.9154 - val_f1: 0.2844\n",
      "Epoch 53/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 1.6046 - f1: 0.3716 - val_loss: 1.9019 - val_f1: 0.2847\n",
      "Epoch 54/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 1.5886 - f1: 0.3721 - val_loss: 1.8828 - val_f1: 0.2973\n",
      "Epoch 55/2000\n",
      "500/500 [==============================] - 0s 841us/sample - loss: 1.5794 - f1: 0.3802 - val_loss: 1.8724 - val_f1: 0.3027\n",
      "Epoch 56/2000\n",
      "500/500 [==============================] - 0s 847us/sample - loss: 1.5544 - f1: 0.4008 - val_loss: 1.8582 - val_f1: 0.3095\n",
      "Epoch 57/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 1.5394 - f1: 0.3959 - val_loss: 1.8476 - val_f1: 0.3203\n",
      "Epoch 58/2000\n",
      "500/500 [==============================] - 0s 840us/sample - loss: 1.5129 - f1: 0.4306 - val_loss: 1.8328 - val_f1: 0.3282\n",
      "Epoch 59/2000\n",
      "500/500 [==============================] - 0s 837us/sample - loss: 1.5127 - f1: 0.4348 - val_loss: 1.8300 - val_f1: 0.3213\n",
      "Epoch 60/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 1.4907 - f1: 0.4374 - val_loss: 1.8118 - val_f1: 0.3308\n",
      "Epoch 61/2000\n",
      "500/500 [==============================] - 0s 840us/sample - loss: 1.4872 - f1: 0.4407 - val_loss: 1.8021 - val_f1: 0.3417\n",
      "Epoch 62/2000\n",
      "500/500 [==============================] - 0s 836us/sample - loss: 1.4655 - f1: 0.4455 - val_loss: 1.7891 - val_f1: 0.3435\n",
      "Epoch 63/2000\n",
      "500/500 [==============================] - 0s 840us/sample - loss: 1.4484 - f1: 0.4668 - val_loss: 1.7830 - val_f1: 0.3486\n",
      "Epoch 64/2000\n",
      "500/500 [==============================] - 0s 840us/sample - loss: 1.4353 - f1: 0.4732 - val_loss: 1.7671 - val_f1: 0.3486\n",
      "Epoch 65/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 1.4047 - f1: 0.4843 - val_loss: 1.7553 - val_f1: 0.3603\n",
      "Epoch 66/2000\n",
      "500/500 [==============================] - 0s 843us/sample - loss: 1.3991 - f1: 0.4897 - val_loss: 1.7541 - val_f1: 0.3547\n",
      "Epoch 67/2000\n",
      "500/500 [==============================] - 0s 837us/sample - loss: 1.3892 - f1: 0.5046 - val_loss: 1.7345 - val_f1: 0.3653\n",
      "Epoch 68/2000\n",
      "500/500 [==============================] - 0s 839us/sample - loss: 1.3722 - f1: 0.5075 - val_loss: 1.7290 - val_f1: 0.3675\n",
      "Epoch 69/2000\n",
      "500/500 [==============================] - 0s 847us/sample - loss: 1.3493 - f1: 0.4972 - val_loss: 1.7216 - val_f1: 0.3731\n",
      "Epoch 70/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 1.3526 - f1: 0.5122 - val_loss: 1.7130 - val_f1: 0.3788\n",
      "Epoch 71/2000\n",
      "500/500 [==============================] - 0s 843us/sample - loss: 1.3263 - f1: 0.5281 - val_loss: 1.7025 - val_f1: 0.3841\n",
      "Epoch 72/2000\n",
      "500/500 [==============================] - 0s 836us/sample - loss: 1.3143 - f1: 0.5382 - val_loss: 1.6938 - val_f1: 0.3960\n",
      "Epoch 73/2000\n",
      "500/500 [==============================] - 0s 836us/sample - loss: 1.3151 - f1: 0.5395 - val_loss: 1.6899 - val_f1: 0.3845\n",
      "Epoch 74/2000\n",
      "500/500 [==============================] - 0s 841us/sample - loss: 1.2905 - f1: 0.5654 - val_loss: 1.6703 - val_f1: 0.4000\n",
      "Epoch 75/2000\n",
      "500/500 [==============================] - 0s 841us/sample - loss: 1.2786 - f1: 0.5713 - val_loss: 1.6627 - val_f1: 0.3976\n",
      "Epoch 76/2000\n",
      "500/500 [==============================] - 0s 844us/sample - loss: 1.2540 - f1: 0.5796 - val_loss: 1.6567 - val_f1: 0.4020\n",
      "Epoch 77/2000\n",
      "500/500 [==============================] - 0s 849us/sample - loss: 1.2630 - f1: 0.5877 - val_loss: 1.6565 - val_f1: 0.4187\n",
      "Epoch 78/2000\n",
      "500/500 [==============================] - 0s 840us/sample - loss: 1.2529 - f1: 0.5860 - val_loss: 1.6385 - val_f1: 0.4114\n",
      "Epoch 79/2000\n",
      "500/500 [==============================] - 0s 839us/sample - loss: 1.2425 - f1: 0.6110 - val_loss: 1.6377 - val_f1: 0.4105\n",
      "Epoch 80/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 1.2411 - f1: 0.6126 - val_loss: 1.6259 - val_f1: 0.4266\n",
      "Epoch 81/2000\n",
      "500/500 [==============================] - 0s 839us/sample - loss: 1.2245 - f1: 0.6133 - val_loss: 1.6266 - val_f1: 0.4217\n",
      "Epoch 82/2000\n",
      "500/500 [==============================] - 0s 842us/sample - loss: 1.2056 - f1: 0.6210 - val_loss: 1.6331 - val_f1: 0.4353\n",
      "Epoch 83/2000\n",
      "500/500 [==============================] - 0s 842us/sample - loss: 1.1968 - f1: 0.6298 - val_loss: 1.6095 - val_f1: 0.4410\n",
      "Epoch 84/2000\n",
      "500/500 [==============================] - 0s 843us/sample - loss: 1.1769 - f1: 0.6403 - val_loss: 1.6064 - val_f1: 0.4481\n",
      "Epoch 85/2000\n",
      "500/500 [==============================] - 0s 843us/sample - loss: 1.1696 - f1: 0.6376 - val_loss: 1.5997 - val_f1: 0.4474\n",
      "Epoch 86/2000\n",
      "500/500 [==============================] - 0s 837us/sample - loss: 1.1538 - f1: 0.6373 - val_loss: 1.5889 - val_f1: 0.4475\n",
      "Epoch 87/2000\n",
      "500/500 [==============================] - 0s 838us/sample - loss: 1.1598 - f1: 0.6443 - val_loss: 1.5826 - val_f1: 0.4505\n",
      "Epoch 88/2000\n",
      "500/500 [==============================] - 0s 840us/sample - loss: 1.1485 - f1: 0.6588 - val_loss: 1.5743 - val_f1: 0.4662\n",
      "Epoch 89/2000\n",
      "500/500 [==============================] - 0s 839us/sample - loss: 1.1319 - f1: 0.6592 - val_loss: 1.5670 - val_f1: 0.4690\n",
      "Epoch 90/2000\n",
      "500/500 [==============================] - 0s 836us/sample - loss: 1.1170 - f1: 0.6870 - val_loss: 1.5663 - val_f1: 0.4752\n",
      "Epoch 91/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 1.1028 - f1: 0.6895 - val_loss: 1.5536 - val_f1: 0.4717\n",
      "Epoch 92/2000\n",
      "500/500 [==============================] - 0s 842us/sample - loss: 1.1047 - f1: 0.6701 - val_loss: 1.5466 - val_f1: 0.4846\n",
      "Epoch 93/2000\n",
      "500/500 [==============================] - 0s 844us/sample - loss: 1.0898 - f1: 0.7046 - val_loss: 1.5405 - val_f1: 0.4842\n",
      "Epoch 94/2000\n",
      "500/500 [==============================] - 0s 847us/sample - loss: 1.0908 - f1: 0.6954 - val_loss: 1.5411 - val_f1: 0.5045\n",
      "Epoch 95/2000\n",
      "500/500 [==============================] - 0s 842us/sample - loss: 1.0875 - f1: 0.6959 - val_loss: 1.5292 - val_f1: 0.4993\n",
      "Epoch 96/2000\n",
      "500/500 [==============================] - 0s 843us/sample - loss: 1.0645 - f1: 0.6924 - val_loss: 1.5341 - val_f1: 0.4916\n",
      "Epoch 97/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 1.0503 - f1: 0.7229 - val_loss: 1.5212 - val_f1: 0.4952\n",
      "Epoch 98/2000\n",
      "500/500 [==============================] - 0s 840us/sample - loss: 1.0387 - f1: 0.7401 - val_loss: 1.5137 - val_f1: 0.5077\n",
      "Epoch 99/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 1.0375 - f1: 0.7226 - val_loss: 1.5047 - val_f1: 0.5113\n",
      "Epoch 100/2000\n",
      "500/500 [==============================] - 0s 849us/sample - loss: 1.0347 - f1: 0.7361 - val_loss: 1.4969 - val_f1: 0.5194\n",
      "Epoch 101/2000\n",
      "500/500 [==============================] - 0s 844us/sample - loss: 1.0180 - f1: 0.7495 - val_loss: 1.5088 - val_f1: 0.5165\n",
      "Epoch 102/2000\n",
      "500/500 [==============================] - 0s 840us/sample - loss: 1.0070 - f1: 0.7558 - val_loss: 1.4891 - val_f1: 0.5238\n",
      "Epoch 103/2000\n",
      "500/500 [==============================] - 0s 841us/sample - loss: 1.0083 - f1: 0.7298 - val_loss: 1.5007 - val_f1: 0.5203\n",
      "Epoch 104/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 0.9884 - f1: 0.7752 - val_loss: 1.4753 - val_f1: 0.5276\n",
      "Epoch 105/2000\n",
      "500/500 [==============================] - 0s 861us/sample - loss: 0.9957 - f1: 0.7445 - val_loss: 1.4780 - val_f1: 0.5284\n",
      "Epoch 106/2000\n",
      "500/500 [==============================] - 0s 863us/sample - loss: 0.9824 - f1: 0.7404 - val_loss: 1.4745 - val_f1: 0.5346\n",
      "Epoch 107/2000\n",
      "500/500 [==============================] - 0s 861us/sample - loss: 0.9705 - f1: 0.7808 - val_loss: 1.4621 - val_f1: 0.5403\n",
      "Epoch 108/2000\n",
      "500/500 [==============================] - 0s 864us/sample - loss: 0.9763 - f1: 0.7698 - val_loss: 1.4648 - val_f1: 0.5478\n",
      "Epoch 109/2000\n",
      "500/500 [==============================] - 0s 859us/sample - loss: 0.9627 - f1: 0.7859 - val_loss: 1.4530 - val_f1: 0.5501\n",
      "Epoch 110/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 0.9466 - f1: 0.7940 - val_loss: 1.4446 - val_f1: 0.5456\n",
      "Epoch 111/2000\n",
      "500/500 [==============================] - 0s 864us/sample - loss: 0.9374 - f1: 0.7849 - val_loss: 1.4454 - val_f1: 0.5498\n",
      "Epoch 112/2000\n",
      "500/500 [==============================] - 0s 867us/sample - loss: 0.9283 - f1: 0.8022 - val_loss: 1.4364 - val_f1: 0.5565\n",
      "Epoch 113/2000\n",
      "500/500 [==============================] - 0s 867us/sample - loss: 0.9198 - f1: 0.8145 - val_loss: 1.4374 - val_f1: 0.5587\n",
      "Epoch 114/2000\n",
      "500/500 [==============================] - 0s 863us/sample - loss: 0.9248 - f1: 0.8047 - val_loss: 1.4304 - val_f1: 0.5596\n",
      "Epoch 115/2000\n",
      "500/500 [==============================] - 0s 856us/sample - loss: 0.9183 - f1: 0.7952 - val_loss: 1.4286 - val_f1: 0.5651\n",
      "Epoch 116/2000\n",
      "500/500 [==============================] - 0s 857us/sample - loss: 0.9059 - f1: 0.8129 - val_loss: 1.4218 - val_f1: 0.5677\n",
      "Epoch 117/2000\n",
      "500/500 [==============================] - 0s 857us/sample - loss: 0.9042 - f1: 0.8203 - val_loss: 1.4282 - val_f1: 0.5682\n",
      "Epoch 118/2000\n",
      "500/500 [==============================] - 0s 864us/sample - loss: 0.9056 - f1: 0.8274 - val_loss: 1.4124 - val_f1: 0.5719\n",
      "Epoch 119/2000\n",
      "500/500 [==============================] - 0s 868us/sample - loss: 0.8938 - f1: 0.8200 - val_loss: 1.4109 - val_f1: 0.5710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/2000\n",
      "500/500 [==============================] - 0s 863us/sample - loss: 0.8750 - f1: 0.8412 - val_loss: 1.4028 - val_f1: 0.5850\n",
      "Epoch 121/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 0.8696 - f1: 0.8328 - val_loss: 1.4068 - val_f1: 0.5830\n",
      "Epoch 122/2000\n",
      "500/500 [==============================] - 0s 865us/sample - loss: 0.8642 - f1: 0.8406 - val_loss: 1.3973 - val_f1: 0.5752\n",
      "Epoch 123/2000\n",
      "500/500 [==============================] - 0s 860us/sample - loss: 0.8601 - f1: 0.8418 - val_loss: 1.3960 - val_f1: 0.5874\n",
      "Epoch 124/2000\n",
      "500/500 [==============================] - 0s 863us/sample - loss: 0.8512 - f1: 0.8350 - val_loss: 1.3972 - val_f1: 0.5894\n",
      "Epoch 125/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 0.8556 - f1: 0.8454 - val_loss: 1.3863 - val_f1: 0.5921\n",
      "Epoch 126/2000\n",
      "500/500 [==============================] - 0s 865us/sample - loss: 0.8521 - f1: 0.8400 - val_loss: 1.3835 - val_f1: 0.5877\n",
      "Epoch 127/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 0.8360 - f1: 0.8546 - val_loss: 1.3807 - val_f1: 0.5946\n",
      "Epoch 128/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 0.8201 - f1: 0.8583 - val_loss: 1.3741 - val_f1: 0.6001\n",
      "Epoch 129/2000\n",
      "500/500 [==============================] - 0s 860us/sample - loss: 0.8252 - f1: 0.8638 - val_loss: 1.3903 - val_f1: 0.5917\n",
      "Epoch 130/2000\n",
      "500/500 [==============================] - 0s 858us/sample - loss: 0.8184 - f1: 0.8669 - val_loss: 1.3724 - val_f1: 0.6057\n",
      "Epoch 131/2000\n",
      "500/500 [==============================] - 0s 860us/sample - loss: 0.8115 - f1: 0.8620 - val_loss: 1.3627 - val_f1: 0.6030\n",
      "Epoch 132/2000\n",
      "500/500 [==============================] - 0s 863us/sample - loss: 0.8086 - f1: 0.8602 - val_loss: 1.3592 - val_f1: 0.6121\n",
      "Epoch 133/2000\n",
      "500/500 [==============================] - 0s 865us/sample - loss: 0.7960 - f1: 0.8669 - val_loss: 1.3528 - val_f1: 0.6087\n",
      "Epoch 134/2000\n",
      "500/500 [==============================] - 0s 860us/sample - loss: 0.7980 - f1: 0.8700 - val_loss: 1.3662 - val_f1: 0.6065\n",
      "Epoch 135/2000\n",
      "500/500 [==============================] - 0s 861us/sample - loss: 0.8039 - f1: 0.8672 - val_loss: 1.3484 - val_f1: 0.6060\n",
      "Epoch 136/2000\n",
      "500/500 [==============================] - 0s 861us/sample - loss: 0.7805 - f1: 0.8854 - val_loss: 1.3482 - val_f1: 0.6154\n",
      "Epoch 137/2000\n",
      "500/500 [==============================] - 0s 868us/sample - loss: 0.7795 - f1: 0.8765 - val_loss: 1.3390 - val_f1: 0.6160\n",
      "Epoch 138/2000\n",
      "500/500 [==============================] - 0s 842us/sample - loss: 0.7639 - f1: 0.8868 - val_loss: 1.3434 - val_f1: 0.6218\n",
      "Epoch 139/2000\n",
      "500/500 [==============================] - 0s 865us/sample - loss: 0.7720 - f1: 0.8725 - val_loss: 1.3365 - val_f1: 0.6193\n",
      "Epoch 140/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 0.7650 - f1: 0.8935 - val_loss: 1.3422 - val_f1: 0.6118\n",
      "Epoch 141/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 0.7667 - f1: 0.8961 - val_loss: 1.3327 - val_f1: 0.6216\n",
      "Epoch 142/2000\n",
      "500/500 [==============================] - 0s 870us/sample - loss: 0.7557 - f1: 0.8792 - val_loss: 1.3416 - val_f1: 0.6240\n",
      "Epoch 143/2000\n",
      "500/500 [==============================] - 0s 860us/sample - loss: 0.7649 - f1: 0.8776 - val_loss: 1.3395 - val_f1: 0.6240\n",
      "Epoch 144/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 0.7577 - f1: 0.8821 - val_loss: 1.3276 - val_f1: 0.6246\n",
      "Epoch 145/2000\n",
      "500/500 [==============================] - 0s 860us/sample - loss: 0.7426 - f1: 0.8922 - val_loss: 1.3322 - val_f1: 0.6271\n",
      "Epoch 146/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 0.7406 - f1: 0.8881 - val_loss: 1.3247 - val_f1: 0.6239\n",
      "Epoch 147/2000\n",
      "500/500 [==============================] - 0s 840us/sample - loss: 0.7360 - f1: 0.8889 - val_loss: 1.3159 - val_f1: 0.6314\n",
      "Epoch 148/2000\n",
      "500/500 [==============================] - 0s 841us/sample - loss: 0.7329 - f1: 0.8969 - val_loss: 1.3166 - val_f1: 0.6315\n",
      "Epoch 149/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 0.7168 - f1: 0.8985 - val_loss: 1.3132 - val_f1: 0.6314\n",
      "Epoch 150/2000\n",
      "500/500 [==============================] - 0s 840us/sample - loss: 0.7110 - f1: 0.9112 - val_loss: 1.3125 - val_f1: 0.6303\n",
      "Epoch 151/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 0.7129 - f1: 0.9112 - val_loss: 1.3064 - val_f1: 0.6363\n",
      "Epoch 152/2000\n",
      "500/500 [==============================] - 0s 842us/sample - loss: 0.6970 - f1: 0.9134 - val_loss: 1.3033 - val_f1: 0.6366\n",
      "Epoch 153/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 0.7097 - f1: 0.8954 - val_loss: 1.3006 - val_f1: 0.6362\n",
      "Epoch 154/2000\n",
      "500/500 [==============================] - 0s 840us/sample - loss: 0.6957 - f1: 0.9143 - val_loss: 1.2983 - val_f1: 0.6385\n",
      "Epoch 155/2000\n",
      "500/500 [==============================] - 0s 839us/sample - loss: 0.6961 - f1: 0.9071 - val_loss: 1.3072 - val_f1: 0.6358\n",
      "Epoch 156/2000\n",
      "500/500 [==============================] - 0s 837us/sample - loss: 0.6916 - f1: 0.9095 - val_loss: 1.3023 - val_f1: 0.6356\n",
      "Epoch 157/2000\n",
      "500/500 [==============================] - 0s 839us/sample - loss: 0.6810 - f1: 0.9149 - val_loss: 1.2992 - val_f1: 0.6479\n",
      "Epoch 158/2000\n",
      "500/500 [==============================] - 0s 841us/sample - loss: 0.6806 - f1: 0.9169 - val_loss: 1.2916 - val_f1: 0.6441\n",
      "Epoch 159/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 0.6771 - f1: 0.9198 - val_loss: 1.2824 - val_f1: 0.6432\n",
      "Epoch 160/2000\n",
      "500/500 [==============================] - 0s 844us/sample - loss: 0.6868 - f1: 0.9164 - val_loss: 1.2772 - val_f1: 0.6440\n",
      "Epoch 161/2000\n",
      "500/500 [==============================] - 0s 841us/sample - loss: 0.6664 - f1: 0.9297 - val_loss: 1.2843 - val_f1: 0.6482\n",
      "Epoch 162/2000\n",
      "500/500 [==============================] - 0s 837us/sample - loss: 0.6679 - f1: 0.9207 - val_loss: 1.2738 - val_f1: 0.6441\n",
      "Epoch 163/2000\n",
      "500/500 [==============================] - 0s 841us/sample - loss: 0.6715 - f1: 0.9202 - val_loss: 1.2779 - val_f1: 0.6433\n",
      "Epoch 164/2000\n",
      "500/500 [==============================] - 0s 838us/sample - loss: 0.6510 - f1: 0.9286 - val_loss: 1.2930 - val_f1: 0.6450\n",
      "Epoch 165/2000\n",
      "500/500 [==============================] - 0s 840us/sample - loss: 0.6567 - f1: 0.9227 - val_loss: 1.2900 - val_f1: 0.6411\n",
      "Epoch 166/2000\n",
      "500/500 [==============================] - 0s 842us/sample - loss: 0.6485 - f1: 0.9294 - val_loss: 1.2716 - val_f1: 0.6455\n",
      "Epoch 167/2000\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 0.6497 - f1: 0.9233 - val_loss: 1.2720 - val_f1: 0.6531\n",
      "Running through fold 3\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 3.9041 - f1: 0.0000e+00 - val_loss: 3.8396 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 981us/sample - loss: 3.8211 - f1: 0.0000e+00 - val_loss: 3.7887 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 950us/sample - loss: 3.7621 - f1: 0.0000e+00 - val_loss: 3.7266 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 912us/sample - loss: 3.6935 - f1: 0.0000e+00 - val_loss: 3.6492 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 886us/sample - loss: 3.6147 - f1: 0.0000e+00 - val_loss: 3.5511 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 873us/sample - loss: 3.5009 - f1: 0.0000e+00 - val_loss: 3.4356 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 871us/sample - loss: 3.3723 - f1: 0.0000e+00 - val_loss: 3.3261 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 868us/sample - loss: 3.2612 - f1: 0.0000e+00 - val_loss: 3.2205 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 871us/sample - loss: 3.1617 - f1: 0.0074 - val_loss: 3.1387 - val_f1: 0.0167\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 870us/sample - loss: 3.0654 - f1: 0.0341 - val_loss: 3.0497 - val_f1: 0.0205\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 0s 872us/sample - loss: 2.9781 - f1: 0.0189 - val_loss: 2.9753 - val_f1: 0.0230\n",
      "Epoch 12/2000\n",
      "500/500 [==============================] - 0s 869us/sample - loss: 2.8921 - f1: 0.0299 - val_loss: 2.9047 - val_f1: 0.0364\n",
      "Epoch 13/2000\n",
      "500/500 [==============================] - 0s 870us/sample - loss: 2.8042 - f1: 0.0475 - val_loss: 2.8336 - val_f1: 0.0405\n",
      "Epoch 14/2000\n",
      "500/500 [==============================] - 0s 865us/sample - loss: 2.7439 - f1: 0.0398 - val_loss: 2.7708 - val_f1: 0.0691\n",
      "Epoch 15/2000\n",
      "500/500 [==============================] - 0s 858us/sample - loss: 2.6767 - f1: 0.0636 - val_loss: 2.7120 - val_f1: 0.0756\n",
      "Epoch 16/2000\n",
      "500/500 [==============================] - 0s 872us/sample - loss: 2.6038 - f1: 0.0729 - val_loss: 2.6554 - val_f1: 0.0811\n",
      "Epoch 17/2000\n",
      "500/500 [==============================] - 0s 856us/sample - loss: 2.5513 - f1: 0.0922 - val_loss: 2.5977 - val_f1: 0.0819\n",
      "Epoch 18/2000\n",
      "500/500 [==============================] - 0s 861us/sample - loss: 2.4728 - f1: 0.1045 - val_loss: 2.5508 - val_f1: 0.0904\n",
      "Epoch 19/2000\n",
      "500/500 [==============================] - 0s 864us/sample - loss: 2.4275 - f1: 0.1031 - val_loss: 2.4977 - val_f1: 0.0974\n",
      "Epoch 20/2000\n",
      "500/500 [==============================] - 0s 857us/sample - loss: 2.3769 - f1: 0.1232 - val_loss: 2.4591 - val_f1: 0.1039\n",
      "Epoch 21/2000\n",
      "500/500 [==============================] - 0s 864us/sample - loss: 2.3226 - f1: 0.1158 - val_loss: 2.4139 - val_f1: 0.1148\n",
      "Epoch 22/2000\n",
      "500/500 [==============================] - 0s 860us/sample - loss: 2.2586 - f1: 0.1304 - val_loss: 2.3718 - val_f1: 0.1121\n",
      "Epoch 23/2000\n",
      "500/500 [==============================] - 0s 865us/sample - loss: 2.2234 - f1: 0.1380 - val_loss: 2.3312 - val_f1: 0.1282\n",
      "Epoch 24/2000\n",
      "500/500 [==============================] - 0s 868us/sample - loss: 2.1689 - f1: 0.1476 - val_loss: 2.2926 - val_f1: 0.1534\n",
      "Epoch 25/2000\n",
      "500/500 [==============================] - 0s 863us/sample - loss: 2.1346 - f1: 0.1849 - val_loss: 2.2593 - val_f1: 0.1737\n",
      "Epoch 26/2000\n",
      "500/500 [==============================] - 0s 866us/sample - loss: 2.0927 - f1: 0.1859 - val_loss: 2.2273 - val_f1: 0.1840\n",
      "Epoch 27/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 2.0520 - f1: 0.1983 - val_loss: 2.1946 - val_f1: 0.1903\n",
      "Epoch 28/2000\n",
      "500/500 [==============================] - 0s 865us/sample - loss: 2.0246 - f1: 0.2078 - val_loss: 2.1704 - val_f1: 0.1986\n",
      "Epoch 29/2000\n",
      "500/500 [==============================] - 0s 866us/sample - loss: 1.9865 - f1: 0.2391 - val_loss: 2.1391 - val_f1: 0.2113\n",
      "Epoch 30/2000\n",
      "500/500 [==============================] - 0s 865us/sample - loss: 1.9447 - f1: 0.2289 - val_loss: 2.1084 - val_f1: 0.2187\n",
      "Epoch 31/2000\n",
      "500/500 [==============================] - 0s 875us/sample - loss: 1.9105 - f1: 0.2690 - val_loss: 2.0847 - val_f1: 0.2230\n",
      "Epoch 32/2000\n",
      "500/500 [==============================] - 0s 865us/sample - loss: 1.8877 - f1: 0.2804 - val_loss: 2.0572 - val_f1: 0.2398\n",
      "Epoch 33/2000\n",
      "500/500 [==============================] - 0s 867us/sample - loss: 1.8563 - f1: 0.2959 - val_loss: 2.0412 - val_f1: 0.2444\n",
      "Epoch 34/2000\n",
      "500/500 [==============================] - 0s 867us/sample - loss: 1.8239 - f1: 0.2964 - val_loss: 2.0169 - val_f1: 0.2481\n",
      "Epoch 35/2000\n",
      "500/500 [==============================] - 0s 865us/sample - loss: 1.8003 - f1: 0.3034 - val_loss: 1.9878 - val_f1: 0.2634\n",
      "Epoch 36/2000\n",
      "500/500 [==============================] - 0s 865us/sample - loss: 1.7674 - f1: 0.3316 - val_loss: 1.9673 - val_f1: 0.2701\n",
      "Epoch 37/2000\n",
      "500/500 [==============================] - 0s 871us/sample - loss: 1.7434 - f1: 0.3422 - val_loss: 1.9446 - val_f1: 0.2759\n",
      "Epoch 38/2000\n",
      "500/500 [==============================] - 0s 858us/sample - loss: 1.7097 - f1: 0.3482 - val_loss: 1.9263 - val_f1: 0.2840\n",
      "Epoch 39/2000\n",
      "500/500 [==============================] - 0s 859us/sample - loss: 1.6985 - f1: 0.3669 - val_loss: 1.9117 - val_f1: 0.2900\n",
      "Epoch 40/2000\n",
      "500/500 [==============================] - 0s 862us/sample - loss: 1.6756 - f1: 0.3912 - val_loss: 1.8939 - val_f1: 0.2986\n",
      "Epoch 41/2000\n",
      "500/500 [==============================] - 0s 867us/sample - loss: 1.6567 - f1: 0.3822 - val_loss: 1.8763 - val_f1: 0.3012\n",
      "Epoch 42/2000\n",
      "500/500 [==============================] - 0s 867us/sample - loss: 1.6195 - f1: 0.3895 - val_loss: 1.8609 - val_f1: 0.3126\n",
      "Epoch 43/2000\n",
      "500/500 [==============================] - 0s 860us/sample - loss: 1.5927 - f1: 0.4128 - val_loss: 1.8425 - val_f1: 0.3139\n",
      "Epoch 44/2000\n",
      "500/500 [==============================] - 0s 864us/sample - loss: 1.5666 - f1: 0.4253 - val_loss: 1.8247 - val_f1: 0.3243\n",
      "Epoch 45/2000\n",
      "500/500 [==============================] - 0s 865us/sample - loss: 1.5574 - f1: 0.4479 - val_loss: 1.8111 - val_f1: 0.3400\n",
      "Epoch 46/2000\n",
      "500/500 [==============================] - 0s 866us/sample - loss: 1.5265 - f1: 0.4583 - val_loss: 1.7947 - val_f1: 0.3311\n",
      "Epoch 47/2000\n",
      "500/500 [==============================] - 0s 867us/sample - loss: 1.5237 - f1: 0.4483 - val_loss: 1.7793 - val_f1: 0.3418\n",
      "Epoch 48/2000\n",
      "500/500 [==============================] - 0s 861us/sample - loss: 1.4855 - f1: 0.4672 - val_loss: 1.7687 - val_f1: 0.3380\n",
      "Epoch 49/2000\n",
      "500/500 [==============================] - 0s 859us/sample - loss: 1.4753 - f1: 0.4652 - val_loss: 1.7513 - val_f1: 0.3466\n",
      "Epoch 50/2000\n",
      "500/500 [==============================] - 0s 861us/sample - loss: 1.4760 - f1: 0.4736 - val_loss: 1.7368 - val_f1: 0.3592\n",
      "Epoch 51/2000\n",
      "500/500 [==============================] - 0s 853us/sample - loss: 1.4319 - f1: 0.4983 - val_loss: 1.7297 - val_f1: 0.3612\n",
      "Epoch 52/2000\n",
      "500/500 [==============================] - 0s 858us/sample - loss: 1.4244 - f1: 0.5120 - val_loss: 1.7192 - val_f1: 0.3584\n",
      "Epoch 53/2000\n",
      "500/500 [==============================] - 0s 859us/sample - loss: 1.4062 - f1: 0.5147 - val_loss: 1.7103 - val_f1: 0.3719\n",
      "Epoch 54/2000\n",
      "500/500 [==============================] - 0s 858us/sample - loss: 1.3792 - f1: 0.5198 - val_loss: 1.6897 - val_f1: 0.3777\n",
      "Epoch 55/2000\n",
      "500/500 [==============================] - 0s 856us/sample - loss: 1.3725 - f1: 0.5268 - val_loss: 1.6803 - val_f1: 0.3909\n",
      "Epoch 56/2000\n",
      "500/500 [==============================] - 0s 861us/sample - loss: 1.3426 - f1: 0.5398 - val_loss: 1.6685 - val_f1: 0.3914\n",
      "Epoch 57/2000\n",
      "500/500 [==============================] - 0s 863us/sample - loss: 1.3469 - f1: 0.5411 - val_loss: 1.6603 - val_f1: 0.4046\n",
      "Epoch 58/2000\n",
      "500/500 [==============================] - 0s 857us/sample - loss: 1.3189 - f1: 0.5625 - val_loss: 1.6465 - val_f1: 0.4054\n",
      "Epoch 59/2000\n",
      "500/500 [==============================] - 0s 853us/sample - loss: 1.3132 - f1: 0.5546 - val_loss: 1.6332 - val_f1: 0.4129\n",
      "Epoch 60/2000\n",
      "500/500 [==============================] - 0s 857us/sample - loss: 1.2802 - f1: 0.5879 - val_loss: 1.6270 - val_f1: 0.4159\n",
      "Epoch 61/2000\n",
      "500/500 [==============================] - 0s 856us/sample - loss: 1.2696 - f1: 0.5553 - val_loss: 1.6140 - val_f1: 0.4289\n",
      "Epoch 62/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 1.2579 - f1: 0.5878 - val_loss: 1.6079 - val_f1: 0.4289\n",
      "Epoch 63/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 1.2290 - f1: 0.6005 - val_loss: 1.6016 - val_f1: 0.4405\n",
      "Epoch 64/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 1.2145 - f1: 0.6127 - val_loss: 1.5901 - val_f1: 0.4420\n",
      "Epoch 65/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 1.2051 - f1: 0.6329 - val_loss: 1.5784 - val_f1: 0.4622\n",
      "Epoch 66/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 1.1976 - f1: 0.6215 - val_loss: 1.5741 - val_f1: 0.4589\n",
      "Epoch 67/2000\n",
      "500/500 [==============================] - 0s 849us/sample - loss: 1.1796 - f1: 0.6476 - val_loss: 1.5597 - val_f1: 0.4665\n",
      "Epoch 68/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 1.1588 - f1: 0.6572 - val_loss: 1.5578 - val_f1: 0.4715\n",
      "Epoch 69/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 1.1585 - f1: 0.6646 - val_loss: 1.5518 - val_f1: 0.4639\n",
      "Epoch 70/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 1.1481 - f1: 0.6473 - val_loss: 1.5419 - val_f1: 0.4841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/2000\n",
      "500/500 [==============================] - 0s 847us/sample - loss: 1.1349 - f1: 0.6718 - val_loss: 1.5275 - val_f1: 0.4936\n",
      "Epoch 72/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 1.1189 - f1: 0.6891 - val_loss: 1.5252 - val_f1: 0.4933\n",
      "Epoch 73/2000\n",
      "500/500 [==============================] - 0s 853us/sample - loss: 1.1086 - f1: 0.6969 - val_loss: 1.5235 - val_f1: 0.4983\n",
      "Epoch 74/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 1.0863 - f1: 0.7028 - val_loss: 1.5076 - val_f1: 0.5071\n",
      "Epoch 75/2000\n",
      "500/500 [==============================] - 0s 849us/sample - loss: 1.0796 - f1: 0.6997 - val_loss: 1.5133 - val_f1: 0.5089\n",
      "Epoch 76/2000\n",
      "500/500 [==============================] - 0s 849us/sample - loss: 1.0752 - f1: 0.7160 - val_loss: 1.4934 - val_f1: 0.5135\n",
      "Epoch 77/2000\n",
      "500/500 [==============================] - 0s 855us/sample - loss: 1.0608 - f1: 0.7123 - val_loss: 1.4854 - val_f1: 0.5234\n",
      "Epoch 78/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 1.0472 - f1: 0.7288 - val_loss: 1.4822 - val_f1: 0.5240\n",
      "Epoch 79/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 1.0502 - f1: 0.7351 - val_loss: 1.4775 - val_f1: 0.5319\n",
      "Epoch 80/2000\n",
      "500/500 [==============================] - 0s 844us/sample - loss: 1.0298 - f1: 0.7354 - val_loss: 1.4711 - val_f1: 0.5282\n",
      "Epoch 81/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 1.0027 - f1: 0.7510 - val_loss: 1.4627 - val_f1: 0.5385\n",
      "Epoch 82/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 1.0091 - f1: 0.7454 - val_loss: 1.4566 - val_f1: 0.5458\n",
      "Epoch 83/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 0.9981 - f1: 0.7463 - val_loss: 1.4490 - val_f1: 0.5442\n",
      "Epoch 84/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 0.9828 - f1: 0.7653 - val_loss: 1.4454 - val_f1: 0.5480\n",
      "Epoch 85/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 0.9769 - f1: 0.7590 - val_loss: 1.4405 - val_f1: 0.5536\n",
      "Epoch 86/2000\n",
      "500/500 [==============================] - 0s 847us/sample - loss: 0.9662 - f1: 0.7776 - val_loss: 1.4330 - val_f1: 0.5476\n",
      "Epoch 87/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 0.9613 - f1: 0.7844 - val_loss: 1.4340 - val_f1: 0.5649\n",
      "Epoch 88/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 0.9472 - f1: 0.7843 - val_loss: 1.4205 - val_f1: 0.5667\n",
      "Epoch 89/2000\n",
      "500/500 [==============================] - 0s 856us/sample - loss: 0.9405 - f1: 0.7842 - val_loss: 1.4174 - val_f1: 0.5668\n",
      "Epoch 90/2000\n",
      "500/500 [==============================] - 0s 853us/sample - loss: 0.9265 - f1: 0.7937 - val_loss: 1.4138 - val_f1: 0.5697\n",
      "Epoch 91/2000\n",
      "500/500 [==============================] - 0s 849us/sample - loss: 0.9202 - f1: 0.7984 - val_loss: 1.4078 - val_f1: 0.5785\n",
      "Epoch 92/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 0.9032 - f1: 0.7990 - val_loss: 1.4005 - val_f1: 0.5710\n",
      "Epoch 93/2000\n",
      "500/500 [==============================] - 0s 854us/sample - loss: 0.8975 - f1: 0.8113 - val_loss: 1.3930 - val_f1: 0.5858\n",
      "Epoch 94/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 0.8966 - f1: 0.8027 - val_loss: 1.3949 - val_f1: 0.5869\n",
      "Epoch 95/2000\n",
      "500/500 [==============================] - 0s 860us/sample - loss: 0.8815 - f1: 0.8086 - val_loss: 1.3834 - val_f1: 0.5901\n",
      "Epoch 96/2000\n",
      "500/500 [==============================] - 0s 858us/sample - loss: 0.8689 - f1: 0.8215 - val_loss: 1.3800 - val_f1: 0.6002\n",
      "Epoch 97/2000\n",
      "500/500 [==============================] - 0s 857us/sample - loss: 0.8640 - f1: 0.8153 - val_loss: 1.3755 - val_f1: 0.5943\n",
      "Epoch 98/2000\n",
      "500/500 [==============================] - 0s 856us/sample - loss: 0.8504 - f1: 0.8363 - val_loss: 1.3731 - val_f1: 0.6011\n",
      "Epoch 99/2000\n",
      "500/500 [==============================] - 0s 858us/sample - loss: 0.8497 - f1: 0.8439 - val_loss: 1.3717 - val_f1: 0.5966\n",
      "Epoch 100/2000\n",
      "500/500 [==============================] - 0s 856us/sample - loss: 0.8456 - f1: 0.8343 - val_loss: 1.3664 - val_f1: 0.6067\n",
      "Epoch 101/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 0.8491 - f1: 0.8286 - val_loss: 1.3602 - val_f1: 0.6073\n",
      "Epoch 102/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 0.8310 - f1: 0.8377 - val_loss: 1.3558 - val_f1: 0.6063\n",
      "Epoch 103/2000\n",
      "500/500 [==============================] - 0s 853us/sample - loss: 0.8237 - f1: 0.8462 - val_loss: 1.3480 - val_f1: 0.6139\n",
      "Epoch 104/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 0.8121 - f1: 0.8526 - val_loss: 1.3398 - val_f1: 0.6205\n",
      "Epoch 105/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 0.8116 - f1: 0.8539 - val_loss: 1.3434 - val_f1: 0.6198\n",
      "Epoch 106/2000\n",
      "500/500 [==============================] - 0s 858us/sample - loss: 0.7997 - f1: 0.8546 - val_loss: 1.3421 - val_f1: 0.6257\n",
      "Epoch 107/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 0.7897 - f1: 0.8749 - val_loss: 1.3325 - val_f1: 0.6213\n",
      "Epoch 108/2000\n",
      "500/500 [==============================] - 0s 847us/sample - loss: 0.7887 - f1: 0.8557 - val_loss: 1.3243 - val_f1: 0.6280\n",
      "Epoch 109/2000\n",
      "500/500 [==============================] - 0s 847us/sample - loss: 0.7746 - f1: 0.8676 - val_loss: 1.3255 - val_f1: 0.6247\n",
      "Epoch 110/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 0.7761 - f1: 0.8687 - val_loss: 1.3270 - val_f1: 0.6254\n",
      "Epoch 111/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 0.7682 - f1: 0.8750 - val_loss: 1.3200 - val_f1: 0.6343\n",
      "Epoch 112/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 0.7621 - f1: 0.8689 - val_loss: 1.3148 - val_f1: 0.6306\n",
      "Epoch 113/2000\n",
      "500/500 [==============================] - 0s 849us/sample - loss: 0.7526 - f1: 0.8810 - val_loss: 1.3104 - val_f1: 0.6361\n",
      "Epoch 114/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 0.7484 - f1: 0.8891 - val_loss: 1.3099 - val_f1: 0.6327\n",
      "Epoch 115/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 0.7394 - f1: 0.8833 - val_loss: 1.3070 - val_f1: 0.6334\n",
      "Epoch 116/2000\n",
      "500/500 [==============================] - 0s 849us/sample - loss: 0.7379 - f1: 0.8935 - val_loss: 1.2984 - val_f1: 0.6382\n",
      "Epoch 117/2000\n",
      "500/500 [==============================] - 0s 844us/sample - loss: 0.7348 - f1: 0.8883 - val_loss: 1.3011 - val_f1: 0.6393\n",
      "Epoch 118/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 0.7179 - f1: 0.8916 - val_loss: 1.3024 - val_f1: 0.6389\n",
      "Epoch 119/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 0.7239 - f1: 0.8920 - val_loss: 1.2911 - val_f1: 0.6418\n",
      "Epoch 120/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 0.6987 - f1: 0.9118 - val_loss: 1.2902 - val_f1: 0.6477\n",
      "Epoch 121/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 0.7052 - f1: 0.9114 - val_loss: 1.2826 - val_f1: 0.6473\n",
      "Epoch 122/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 0.7024 - f1: 0.8983 - val_loss: 1.2838 - val_f1: 0.6519\n",
      "Epoch 123/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 0.7003 - f1: 0.9012 - val_loss: 1.2821 - val_f1: 0.6515\n",
      "Epoch 124/2000\n",
      "500/500 [==============================] - 0s 854us/sample - loss: 0.7010 - f1: 0.9078 - val_loss: 1.2867 - val_f1: 0.6508\n",
      "Epoch 125/2000\n",
      "500/500 [==============================] - 0s 854us/sample - loss: 0.6858 - f1: 0.9018 - val_loss: 1.2697 - val_f1: 0.6565\n",
      "Epoch 126/2000\n",
      "500/500 [==============================] - 0s 853us/sample - loss: 0.6786 - f1: 0.9176 - val_loss: 1.2693 - val_f1: 0.6492\n",
      "Epoch 127/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 0.6738 - f1: 0.9128 - val_loss: 1.2727 - val_f1: 0.6528\n",
      "Epoch 128/2000\n",
      "500/500 [==============================] - 0s 850us/sample - loss: 0.6717 - f1: 0.9223 - val_loss: 1.2643 - val_f1: 0.6592\n",
      "Epoch 129/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 0.6670 - f1: 0.9066 - val_loss: 1.2673 - val_f1: 0.6571\n",
      "Epoch 130/2000\n",
      "500/500 [==============================] - 0s 855us/sample - loss: 0.6536 - f1: 0.9224 - val_loss: 1.2567 - val_f1: 0.6618\n",
      "Epoch 131/2000\n",
      "500/500 [==============================] - 0s 847us/sample - loss: 0.6588 - f1: 0.9179 - val_loss: 1.2576 - val_f1: 0.6632\n",
      "Epoch 132/2000\n",
      "500/500 [==============================] - 0s 844us/sample - loss: 0.6493 - f1: 0.9150 - val_loss: 1.2553 - val_f1: 0.6551\n",
      "Epoch 133/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 0.6426 - f1: 0.9280 - val_loss: 1.2538 - val_f1: 0.6608\n",
      "Epoch 134/2000\n",
      "500/500 [==============================] - 0s 846us/sample - loss: 0.6375 - f1: 0.9238 - val_loss: 1.2503 - val_f1: 0.6683\n",
      "Epoch 135/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 0.6364 - f1: 0.9313 - val_loss: 1.2473 - val_f1: 0.6681\n",
      "Epoch 136/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 0.6403 - f1: 0.9227 - val_loss: 1.2474 - val_f1: 0.6623\n",
      "Epoch 137/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 0.6259 - f1: 0.9424 - val_loss: 1.2444 - val_f1: 0.6701\n",
      "Epoch 138/2000\n",
      "500/500 [==============================] - 0s 847us/sample - loss: 0.6213 - f1: 0.9304 - val_loss: 1.2414 - val_f1: 0.6607\n",
      "Epoch 139/2000\n",
      "500/500 [==============================] - 0s 847us/sample - loss: 0.6139 - f1: 0.9413 - val_loss: 1.2422 - val_f1: 0.6699\n",
      "Epoch 140/2000\n",
      "500/500 [==============================] - 0s 848us/sample - loss: 0.6101 - f1: 0.9401 - val_loss: 1.2331 - val_f1: 0.6666\n",
      "Epoch 141/2000\n",
      "500/500 [==============================] - 0s 851us/sample - loss: 0.6112 - f1: 0.9360 - val_loss: 1.2344 - val_f1: 0.6713\n",
      "Epoch 142/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 0.6135 - f1: 0.9370 - val_loss: 1.2429 - val_f1: 0.6681\n",
      "Epoch 143/2000\n",
      "500/500 [==============================] - 0s 842us/sample - loss: 0.6068 - f1: 0.9386 - val_loss: 1.2283 - val_f1: 0.6739\n",
      "Epoch 144/2000\n",
      "500/500 [==============================] - 0s 852us/sample - loss: 0.5962 - f1: 0.9393 - val_loss: 1.2255 - val_f1: 0.6740\n",
      "Epoch 145/2000\n",
      "500/500 [==============================] - 0s 847us/sample - loss: 0.5925 - f1: 0.9420 - val_loss: 1.2228 - val_f1: 0.6733\n",
      "Epoch 146/2000\n",
      "500/500 [==============================] - 0s 845us/sample - loss: 0.5923 - f1: 0.9461 - val_loss: 1.2224 - val_f1: 0.6766\n",
      "Epoch 147/2000\n",
      "500/500 [==============================] - 2s 3ms/sample - loss: 0.5834 - f1: 0.9476 - val_loss: 1.2214 - val_f1: 0.6742\n",
      "Running through fold 4\n",
      "Train on 500 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 3.8845 - f1: 0.0000e+00 - val_loss: 3.8361 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "500/500 [==============================] - 0s 981us/sample - loss: 3.8186 - f1: 0.0000e+00 - val_loss: 3.7899 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "500/500 [==============================] - 0s 946us/sample - loss: 3.7652 - f1: 0.0000e+00 - val_loss: 3.7349 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "500/500 [==============================] - 0s 914us/sample - loss: 3.7040 - f1: 0.0000e+00 - val_loss: 3.6697 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "500/500 [==============================] - 0s 905us/sample - loss: 3.6212 - f1: 0.0000e+00 - val_loss: 3.5831 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "500/500 [==============================] - 0s 901us/sample - loss: 3.5255 - f1: 0.0000e+00 - val_loss: 3.4752 - val_f1: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "500/500 [==============================] - 0s 888us/sample - loss: 3.4017 - f1: 0.0000e+00 - val_loss: 3.3628 - val_f1: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "500/500 [==============================] - 0s 897us/sample - loss: 3.2838 - f1: 0.0000e+00 - val_loss: 3.2553 - val_f1: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "500/500 [==============================] - 0s 889us/sample - loss: 3.1571 - f1: 0.0000e+00 - val_loss: 3.1475 - val_f1: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "500/500 [==============================] - 0s 885us/sample - loss: 3.0445 - f1: 0.0000e+00 - val_loss: 3.0504 - val_f1: 0.0032\n",
      "Epoch 11/2000\n",
      "500/500 [==============================] - 2s 4ms/sample - loss: 2.9418 - f1: 0.0038 - val_loss: 2.9538 - val_f1: 0.0096\n",
      "\n",
      "\n",
      "Running through training size 1000\n",
      "Running through fold 0\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 3.8546 - f1: 0.0000e+00 - val_loss: 3.7903 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 582us/sample - loss: 3.7525 - f1: 0.0000e+00 - val_loss: 3.6785 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 566us/sample - loss: 3.6113 - f1: 0.0000e+00 - val_loss: 3.4974 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 547us/sample - loss: 3.4095 - f1: 0.0000e+00 - val_loss: 3.2920 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 547us/sample - loss: 3.2207 - f1: 0.0000e+00 - val_loss: 3.1330 - val_f1: 0.0154\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 542us/sample - loss: 3.0726 - f1: 0.0149 - val_loss: 2.9968 - val_f1: 0.0266\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 2.9250 - f1: 0.0403 - val_loss: 2.8629 - val_f1: 0.0506\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 2.7823 - f1: 0.0581 - val_loss: 2.7398 - val_f1: 0.0717\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 2.6723 - f1: 0.0766 - val_loss: 2.6208 - val_f1: 0.0796\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 2.5528 - f1: 0.0795 - val_loss: 2.5198 - val_f1: 0.0805\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 2.4573 - f1: 0.0952 - val_loss: 2.4302 - val_f1: 0.0824\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 2.3594 - f1: 0.0994 - val_loss: 2.3440 - val_f1: 0.1219\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 2.2747 - f1: 0.1289 - val_loss: 2.2744 - val_f1: 0.1485\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 2.2005 - f1: 0.1492 - val_loss: 2.2002 - val_f1: 0.1616\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 2.1360 - f1: 0.1680 - val_loss: 2.1436 - val_f1: 0.1709\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 2.0750 - f1: 0.1930 - val_loss: 2.0843 - val_f1: 0.1945\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.9989 - f1: 0.2192 - val_loss: 2.0303 - val_f1: 0.2264\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.9584 - f1: 0.2401 - val_loss: 1.9816 - val_f1: 0.2395\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 1.8958 - f1: 0.2649 - val_loss: 1.9405 - val_f1: 0.2583\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.8596 - f1: 0.2909 - val_loss: 1.8916 - val_f1: 0.2601\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.8031 - f1: 0.2856 - val_loss: 1.8545 - val_f1: 0.2892\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 1.7574 - f1: 0.3251 - val_loss: 1.8131 - val_f1: 0.3016\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.7190 - f1: 0.3433 - val_loss: 1.7822 - val_f1: 0.3147\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 1.6763 - f1: 0.3638 - val_loss: 1.7468 - val_f1: 0.3419\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 1.6305 - f1: 0.3758 - val_loss: 1.7151 - val_f1: 0.3641\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 1.6184 - f1: 0.3942 - val_loss: 1.6968 - val_f1: 0.3649\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.5819 - f1: 0.4019 - val_loss: 1.6841 - val_f1: 0.3781\n",
      "Epoch 28/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.5523 - f1: 0.4123 - val_loss: 1.6453 - val_f1: 0.3965\n",
      "Epoch 29/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.5266 - f1: 0.4485 - val_loss: 1.6225 - val_f1: 0.4006\n",
      "Epoch 30/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 1.4851 - f1: 0.4642 - val_loss: 1.5889 - val_f1: 0.4076\n",
      "Epoch 31/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 1.4599 - f1: 0.4741 - val_loss: 1.5740 - val_f1: 0.4159\n",
      "Epoch 32/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.4335 - f1: 0.4876 - val_loss: 1.5460 - val_f1: 0.4235\n",
      "Epoch 33/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 1.4013 - f1: 0.5112 - val_loss: 1.5309 - val_f1: 0.4617\n",
      "Epoch 34/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.3844 - f1: 0.5125 - val_loss: 1.5045 - val_f1: 0.4649\n",
      "Epoch 35/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 1.3446 - f1: 0.5152 - val_loss: 1.4814 - val_f1: 0.4648\n",
      "Epoch 36/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.3267 - f1: 0.5407 - val_loss: 1.4692 - val_f1: 0.4732\n",
      "Epoch 37/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.3030 - f1: 0.5458 - val_loss: 1.4485 - val_f1: 0.4976\n",
      "Epoch 38/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.2916 - f1: 0.5488 - val_loss: 1.4322 - val_f1: 0.4975\n",
      "Epoch 39/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 1.2670 - f1: 0.5746 - val_loss: 1.4309 - val_f1: 0.5202\n",
      "Epoch 40/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 1.2479 - f1: 0.5898 - val_loss: 1.4105 - val_f1: 0.5333\n",
      "Epoch 41/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.2259 - f1: 0.5945 - val_loss: 1.3930 - val_f1: 0.5362\n",
      "Epoch 42/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 1.2094 - f1: 0.6076 - val_loss: 1.3736 - val_f1: 0.5431\n",
      "Epoch 43/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 1.1857 - f1: 0.6296 - val_loss: 1.3689 - val_f1: 0.5625\n",
      "Epoch 44/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.1748 - f1: 0.6170 - val_loss: 1.3492 - val_f1: 0.5700\n",
      "Epoch 45/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.1535 - f1: 0.6462 - val_loss: 1.3295 - val_f1: 0.5790\n",
      "Epoch 46/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.1232 - f1: 0.6627 - val_loss: 1.3345 - val_f1: 0.5814\n",
      "Epoch 47/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.1177 - f1: 0.6658 - val_loss: 1.3049 - val_f1: 0.5950\n",
      "Epoch 48/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 1.0900 - f1: 0.6865 - val_loss: 1.3122 - val_f1: 0.5897\n",
      "Epoch 49/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 1.0881 - f1: 0.6768 - val_loss: 1.2969 - val_f1: 0.6017\n",
      "Epoch 50/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.0718 - f1: 0.6964 - val_loss: 1.2820 - val_f1: 0.6046\n",
      "Epoch 51/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.0462 - f1: 0.7048 - val_loss: 1.2694 - val_f1: 0.6194\n",
      "Epoch 52/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 1.0331 - f1: 0.7109 - val_loss: 1.2535 - val_f1: 0.6209\n",
      "Epoch 53/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 1.0226 - f1: 0.7048 - val_loss: 1.2455 - val_f1: 0.6291\n",
      "Epoch 54/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.0213 - f1: 0.7258 - val_loss: 1.2330 - val_f1: 0.6330\n",
      "Epoch 55/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.9982 - f1: 0.7301 - val_loss: 1.2280 - val_f1: 0.6436\n",
      "Epoch 56/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.9739 - f1: 0.7396 - val_loss: 1.2207 - val_f1: 0.6482\n",
      "Epoch 57/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.9597 - f1: 0.7680 - val_loss: 1.2123 - val_f1: 0.6482\n",
      "Epoch 58/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 0.9490 - f1: 0.7561 - val_loss: 1.2033 - val_f1: 0.6519\n",
      "Epoch 59/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.9447 - f1: 0.7551 - val_loss: 1.1923 - val_f1: 0.6593\n",
      "Epoch 60/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.9390 - f1: 0.7666 - val_loss: 1.1905 - val_f1: 0.6648\n",
      "Epoch 61/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.9230 - f1: 0.7696 - val_loss: 1.1780 - val_f1: 0.6612\n",
      "Epoch 62/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.9170 - f1: 0.7793 - val_loss: 1.1752 - val_f1: 0.6612\n",
      "Epoch 63/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.8973 - f1: 0.7949 - val_loss: 1.1654 - val_f1: 0.6757\n",
      "Epoch 64/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.8794 - f1: 0.7976 - val_loss: 1.1609 - val_f1: 0.6728\n",
      "Epoch 65/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.8772 - f1: 0.7951 - val_loss: 1.1460 - val_f1: 0.6794\n",
      "Epoch 66/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 0.8667 - f1: 0.8112 - val_loss: 1.1403 - val_f1: 0.6842\n",
      "Epoch 67/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.8549 - f1: 0.8207 - val_loss: 1.1371 - val_f1: 0.6875\n",
      "Epoch 68/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.8407 - f1: 0.8241 - val_loss: 1.1262 - val_f1: 0.6849\n",
      "Epoch 69/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.8375 - f1: 0.8155 - val_loss: 1.1233 - val_f1: 0.6880\n",
      "Epoch 70/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.8224 - f1: 0.8321 - val_loss: 1.1123 - val_f1: 0.6980\n",
      "Epoch 71/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.8057 - f1: 0.8386 - val_loss: 1.1071 - val_f1: 0.6991\n",
      "Epoch 72/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.8023 - f1: 0.8302 - val_loss: 1.0983 - val_f1: 0.7025\n",
      "Epoch 73/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.7948 - f1: 0.8455 - val_loss: 1.0970 - val_f1: 0.7013\n",
      "Epoch 74/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.7829 - f1: 0.8421 - val_loss: 1.1052 - val_f1: 0.7037\n",
      "Epoch 75/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.7921 - f1: 0.8426 - val_loss: 1.0866 - val_f1: 0.7111\n",
      "Epoch 76/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 0.7573 - f1: 0.8643 - val_loss: 1.0956 - val_f1: 0.7152\n",
      "Epoch 77/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.7570 - f1: 0.8512 - val_loss: 1.0715 - val_f1: 0.7161\n",
      "Epoch 78/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.7574 - f1: 0.8699 - val_loss: 1.0798 - val_f1: 0.7156\n",
      "Epoch 79/2000\n",
      "1000/1000 [==============================] - 1s 522us/sample - loss: 0.7491 - f1: 0.8566 - val_loss: 1.0711 - val_f1: 0.7135\n",
      "Epoch 80/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.7374 - f1: 0.8732 - val_loss: 1.0565 - val_f1: 0.7311\n",
      "Epoch 81/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 0.7278 - f1: 0.8641 - val_loss: 1.0511 - val_f1: 0.7225\n",
      "Epoch 82/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.7271 - f1: 0.8753 - val_loss: 1.0505 - val_f1: 0.7239\n",
      "Epoch 83/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.7040 - f1: 0.8841 - val_loss: 1.0439 - val_f1: 0.7259\n",
      "Epoch 84/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 0.7011 - f1: 0.8904 - val_loss: 1.0405 - val_f1: 0.7298\n",
      "Epoch 85/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.6913 - f1: 0.8871 - val_loss: 1.0311 - val_f1: 0.7316\n",
      "Epoch 86/2000\n",
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.6977 - f1: 0.8895 - val_loss: 1.0349 - val_f1: 0.7356\n",
      "Epoch 87/2000\n",
      "1000/1000 [==============================] - 1s 525us/sample - loss: 0.6818 - f1: 0.8962 - val_loss: 1.0254 - val_f1: 0.7382\n",
      "Epoch 88/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 523us/sample - loss: 0.6747 - f1: 0.8956 - val_loss: 1.0216 - val_f1: 0.7380\n",
      "Epoch 89/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.6666 - f1: 0.8977 - val_loss: 1.0204 - val_f1: 0.7376\n",
      "Epoch 90/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.6634 - f1: 0.9020 - val_loss: 1.0176 - val_f1: 0.7396\n",
      "Running through fold 1\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 3.8523 - f1: 0.0000e+00 - val_loss: 3.7954 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 589us/sample - loss: 3.7450 - f1: 0.0000e+00 - val_loss: 3.6713 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 564us/sample - loss: 3.5844 - f1: 0.0000e+00 - val_loss: 3.4611 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 550us/sample - loss: 3.3442 - f1: 0.0057 - val_loss: 3.2008 - val_f1: 0.0026\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 548us/sample - loss: 3.1056 - f1: 0.0150 - val_loss: 3.0077 - val_f1: 0.0314\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 545us/sample - loss: 2.9292 - f1: 0.0518 - val_loss: 2.8404 - val_f1: 0.0526\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 546us/sample - loss: 2.7714 - f1: 0.0659 - val_loss: 2.6958 - val_f1: 0.0665\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 2.6409 - f1: 0.0781 - val_loss: 2.5782 - val_f1: 0.0834\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 2.5138 - f1: 0.0823 - val_loss: 2.4739 - val_f1: 0.0848\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 2.3939 - f1: 0.0936 - val_loss: 2.3708 - val_f1: 0.0839\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 2.3076 - f1: 0.1067 - val_loss: 2.2783 - val_f1: 0.1092\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 2.2099 - f1: 0.1322 - val_loss: 2.1976 - val_f1: 0.1395\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 2.1342 - f1: 0.1399 - val_loss: 2.1296 - val_f1: 0.1771\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 2.0674 - f1: 0.1663 - val_loss: 2.0729 - val_f1: 0.1866\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 2.0046 - f1: 0.1961 - val_loss: 2.0069 - val_f1: 0.2078\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 1.9443 - f1: 0.2250 - val_loss: 1.9553 - val_f1: 0.2279\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.8723 - f1: 0.2378 - val_loss: 1.9064 - val_f1: 0.2470\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 1.8302 - f1: 0.2575 - val_loss: 1.8694 - val_f1: 0.2637\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.7928 - f1: 0.2878 - val_loss: 1.8239 - val_f1: 0.2770\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 1.7383 - f1: 0.3065 - val_loss: 1.7877 - val_f1: 0.2936\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 1.6954 - f1: 0.3300 - val_loss: 1.7608 - val_f1: 0.3085\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 1.6613 - f1: 0.3536 - val_loss: 1.7268 - val_f1: 0.3141\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.6281 - f1: 0.3639 - val_loss: 1.6976 - val_f1: 0.3386\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.5967 - f1: 0.3589 - val_loss: 1.6593 - val_f1: 0.3445\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.5610 - f1: 0.3955 - val_loss: 1.6424 - val_f1: 0.3810\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.5337 - f1: 0.4041 - val_loss: 1.6126 - val_f1: 0.3807\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.4951 - f1: 0.4176 - val_loss: 1.5957 - val_f1: 0.3840\n",
      "Epoch 28/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.4714 - f1: 0.4337 - val_loss: 1.5674 - val_f1: 0.4061\n",
      "Epoch 29/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.4342 - f1: 0.4659 - val_loss: 1.5414 - val_f1: 0.4354\n",
      "Epoch 30/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.4228 - f1: 0.4876 - val_loss: 1.5254 - val_f1: 0.4356\n",
      "Epoch 31/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 1.3808 - f1: 0.4961 - val_loss: 1.5148 - val_f1: 0.4349\n",
      "Epoch 32/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 1.3666 - f1: 0.5226 - val_loss: 1.4915 - val_f1: 0.4548\n",
      "Epoch 33/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.3354 - f1: 0.5048 - val_loss: 1.4691 - val_f1: 0.4729\n",
      "Epoch 34/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 1.3160 - f1: 0.5545 - val_loss: 1.4461 - val_f1: 0.4824\n",
      "Epoch 35/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 1.3017 - f1: 0.5534 - val_loss: 1.4295 - val_f1: 0.5007\n",
      "Epoch 36/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.2757 - f1: 0.5608 - val_loss: 1.4193 - val_f1: 0.5088\n",
      "Epoch 37/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.2478 - f1: 0.5930 - val_loss: 1.3977 - val_f1: 0.5202\n",
      "Epoch 38/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 1.2347 - f1: 0.5991 - val_loss: 1.3820 - val_f1: 0.5271\n",
      "Epoch 39/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 1.2090 - f1: 0.6071 - val_loss: 1.3685 - val_f1: 0.5414\n",
      "Epoch 40/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 1.1874 - f1: 0.6241 - val_loss: 1.3619 - val_f1: 0.5586\n",
      "Epoch 41/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 1.1727 - f1: 0.6394 - val_loss: 1.3484 - val_f1: 0.5654\n",
      "Epoch 42/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.1506 - f1: 0.6327 - val_loss: 1.3360 - val_f1: 0.5660\n",
      "Epoch 43/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.1270 - f1: 0.6617 - val_loss: 1.3174 - val_f1: 0.5789\n",
      "Epoch 44/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 1.1178 - f1: 0.6742 - val_loss: 1.3086 - val_f1: 0.5754\n",
      "Epoch 45/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.1024 - f1: 0.6794 - val_loss: 1.3055 - val_f1: 0.5934\n",
      "Epoch 46/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 1.0883 - f1: 0.6775 - val_loss: 1.2860 - val_f1: 0.6065\n",
      "Epoch 47/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 1.0803 - f1: 0.6947 - val_loss: 1.2746 - val_f1: 0.5972\n",
      "Epoch 48/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 1.0545 - f1: 0.7087 - val_loss: 1.2640 - val_f1: 0.6094\n",
      "Epoch 49/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.0361 - f1: 0.7161 - val_loss: 1.2497 - val_f1: 0.6195\n",
      "Epoch 50/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.0255 - f1: 0.7146 - val_loss: 1.2447 - val_f1: 0.6239\n",
      "Epoch 51/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 1.0086 - f1: 0.7244 - val_loss: 1.2286 - val_f1: 0.6253\n",
      "Epoch 52/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.9954 - f1: 0.7392 - val_loss: 1.2225 - val_f1: 0.6398\n",
      "Epoch 53/2000\n",
      "1000/1000 [==============================] - 1s 524us/sample - loss: 0.9822 - f1: 0.7532 - val_loss: 1.2108 - val_f1: 0.6394\n",
      "Epoch 54/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.9677 - f1: 0.7532 - val_loss: 1.1993 - val_f1: 0.6538\n",
      "Epoch 55/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.9496 - f1: 0.7591 - val_loss: 1.1935 - val_f1: 0.6626\n",
      "Epoch 56/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.9415 - f1: 0.7664 - val_loss: 1.1941 - val_f1: 0.6468\n",
      "Epoch 57/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.9336 - f1: 0.7720 - val_loss: 1.1817 - val_f1: 0.6617\n",
      "Epoch 58/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.9224 - f1: 0.7910 - val_loss: 1.1715 - val_f1: 0.6695\n",
      "Epoch 59/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.9017 - f1: 0.7859 - val_loss: 1.1607 - val_f1: 0.6752\n",
      "Epoch 60/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.8930 - f1: 0.7820 - val_loss: 1.1551 - val_f1: 0.6792\n",
      "Epoch 61/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.8843 - f1: 0.7897 - val_loss: 1.1450 - val_f1: 0.6826\n",
      "Epoch 62/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.8648 - f1: 0.8041 - val_loss: 1.1467 - val_f1: 0.6828\n",
      "Epoch 63/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.8627 - f1: 0.8081 - val_loss: 1.1368 - val_f1: 0.6867\n",
      "Epoch 64/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.8421 - f1: 0.8198 - val_loss: 1.1208 - val_f1: 0.6914\n",
      "Epoch 65/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.8296 - f1: 0.8271 - val_loss: 1.1218 - val_f1: 0.6897\n",
      "Epoch 66/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.8271 - f1: 0.8274 - val_loss: 1.1147 - val_f1: 0.6948\n",
      "Epoch 67/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.8172 - f1: 0.8228 - val_loss: 1.0999 - val_f1: 0.7049\n",
      "Epoch 68/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 0.8018 - f1: 0.8398 - val_loss: 1.0974 - val_f1: 0.7041\n",
      "Epoch 69/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.7942 - f1: 0.8433 - val_loss: 1.0875 - val_f1: 0.7071\n",
      "Epoch 70/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.7942 - f1: 0.8312 - val_loss: 1.0943 - val_f1: 0.7063\n",
      "Epoch 71/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.7920 - f1: 0.8412 - val_loss: 1.0891 - val_f1: 0.7103\n",
      "Epoch 72/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.7756 - f1: 0.8483 - val_loss: 1.0719 - val_f1: 0.7134\n",
      "Epoch 73/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.7568 - f1: 0.8594 - val_loss: 1.0722 - val_f1: 0.7150\n",
      "Epoch 74/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.7556 - f1: 0.8608 - val_loss: 1.0627 - val_f1: 0.7164\n",
      "Epoch 75/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.7384 - f1: 0.8628 - val_loss: 1.0653 - val_f1: 0.7159\n",
      "Epoch 76/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.7262 - f1: 0.8723 - val_loss: 1.0545 - val_f1: 0.7210\n",
      "Epoch 77/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.7281 - f1: 0.8610 - val_loss: 1.0511 - val_f1: 0.7246\n",
      "Epoch 78/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 0.7158 - f1: 0.8775 - val_loss: 1.0374 - val_f1: 0.7287\n",
      "Epoch 79/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 0.7110 - f1: 0.8642 - val_loss: 1.0473 - val_f1: 0.7300\n",
      "Epoch 80/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.7070 - f1: 0.8753 - val_loss: 1.0385 - val_f1: 0.7242\n",
      "Epoch 81/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.6912 - f1: 0.8863 - val_loss: 1.0257 - val_f1: 0.7361\n",
      "Epoch 82/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.6877 - f1: 0.8855 - val_loss: 1.0309 - val_f1: 0.7322\n",
      "Epoch 83/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.6754 - f1: 0.8973 - val_loss: 1.0219 - val_f1: 0.7325\n",
      "Epoch 84/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.6740 - f1: 0.8979 - val_loss: 1.0253 - val_f1: 0.7330\n",
      "Epoch 85/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.6721 - f1: 0.8918 - val_loss: 1.0164 - val_f1: 0.7348\n",
      "Epoch 86/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.6549 - f1: 0.9026 - val_loss: 1.0072 - val_f1: 0.7387\n",
      "Epoch 87/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.6506 - f1: 0.8933 - val_loss: 1.0119 - val_f1: 0.7402\n",
      "Epoch 88/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.6448 - f1: 0.9079 - val_loss: 0.9953 - val_f1: 0.7440\n",
      "Epoch 89/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.6377 - f1: 0.9080 - val_loss: 1.0030 - val_f1: 0.7433\n",
      "Epoch 90/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 0.6379 - f1: 0.9066 - val_loss: 1.0018 - val_f1: 0.7462\n",
      "Epoch 91/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.6318 - f1: 0.9044 - val_loss: 0.9919 - val_f1: 0.7483\n",
      "Epoch 92/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.6248 - f1: 0.9080 - val_loss: 0.9890 - val_f1: 0.7514\n",
      "Epoch 93/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.6125 - f1: 0.9196 - val_loss: 0.9799 - val_f1: 0.7517\n",
      "Epoch 94/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.5990 - f1: 0.9197 - val_loss: 0.9857 - val_f1: 0.7491\n",
      "Epoch 95/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.6011 - f1: 0.9221 - val_loss: 0.9903 - val_f1: 0.7466\n",
      "Epoch 96/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 0.5947 - f1: 0.9195 - val_loss: 0.9690 - val_f1: 0.7559\n",
      "Epoch 97/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.5886 - f1: 0.9246 - val_loss: 0.9713 - val_f1: 0.7503\n",
      "Epoch 98/2000\n",
      "1000/1000 [==============================] - 1s 527us/sample - loss: 0.5813 - f1: 0.9255 - val_loss: 0.9634 - val_f1: 0.7549\n",
      "Epoch 99/2000\n",
      "1000/1000 [==============================] - 1s 526us/sample - loss: 0.5725 - f1: 0.9332 - val_loss: 0.9695 - val_f1: 0.7559\n",
      "Epoch 100/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 0.5730 - f1: 0.9306 - val_loss: 0.9632 - val_f1: 0.7571\n",
      "Epoch 101/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.5710 - f1: 0.9236 - val_loss: 0.9538 - val_f1: 0.7564\n",
      "Epoch 102/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.5686 - f1: 0.9277 - val_loss: 0.9623 - val_f1: 0.7601\n",
      "Running through fold 2\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 3.8650 - f1: 0.0000e+00 - val_loss: 3.8131 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 590us/sample - loss: 3.7720 - f1: 0.0000e+00 - val_loss: 3.7201 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 570us/sample - loss: 3.6538 - f1: 0.0000e+00 - val_loss: 3.5812 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 547us/sample - loss: 3.4707 - f1: 0.0000e+00 - val_loss: 3.3735 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 546us/sample - loss: 3.2689 - f1: 0.0076 - val_loss: 3.1914 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 544us/sample - loss: 3.1005 - f1: 0.0095 - val_loss: 3.0338 - val_f1: 0.0219\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 2.9400 - f1: 0.0334 - val_loss: 2.9130 - val_f1: 0.0303\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 2.8146 - f1: 0.0458 - val_loss: 2.7753 - val_f1: 0.0488\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 2.6834 - f1: 0.0536 - val_loss: 2.6633 - val_f1: 0.0833\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 2.5664 - f1: 0.0712 - val_loss: 2.5493 - val_f1: 0.0867\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 2.4494 - f1: 0.0763 - val_loss: 2.4473 - val_f1: 0.0930\n",
      "Epoch 12/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 533us/sample - loss: 2.3600 - f1: 0.0892 - val_loss: 2.3629 - val_f1: 0.1091\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 2.2815 - f1: 0.1271 - val_loss: 2.2902 - val_f1: 0.1367\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 2.1948 - f1: 0.1319 - val_loss: 2.2113 - val_f1: 0.1348\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 2.1034 - f1: 0.1371 - val_loss: 2.1372 - val_f1: 0.1693\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 2.0463 - f1: 0.1729 - val_loss: 2.0788 - val_f1: 0.1720\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.9921 - f1: 0.1745 - val_loss: 2.0235 - val_f1: 0.1950\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.9213 - f1: 0.2089 - val_loss: 1.9852 - val_f1: 0.2233\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 1.8817 - f1: 0.2180 - val_loss: 1.9377 - val_f1: 0.2295\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.8361 - f1: 0.2689 - val_loss: 1.8920 - val_f1: 0.2545\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.7892 - f1: 0.2815 - val_loss: 1.8640 - val_f1: 0.2645\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 1.7607 - f1: 0.2779 - val_loss: 1.8234 - val_f1: 0.2838\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 1.6979 - f1: 0.3061 - val_loss: 1.7908 - val_f1: 0.3083\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.6723 - f1: 0.3370 - val_loss: 1.7462 - val_f1: 0.3224\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 1.6206 - f1: 0.3657 - val_loss: 1.7152 - val_f1: 0.3276\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.6041 - f1: 0.3693 - val_loss: 1.6851 - val_f1: 0.3612\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 1s 528us/sample - loss: 1.5644 - f1: 0.4049 - val_loss: 1.6588 - val_f1: 0.3621\n",
      "Epoch 28/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.5275 - f1: 0.3988 - val_loss: 1.6324 - val_f1: 0.3712\n",
      "Epoch 29/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 1.4957 - f1: 0.4229 - val_loss: 1.6042 - val_f1: 0.3990\n",
      "Epoch 30/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 1.4799 - f1: 0.4476 - val_loss: 1.5874 - val_f1: 0.4149\n",
      "Epoch 31/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 1.4534 - f1: 0.4662 - val_loss: 1.5579 - val_f1: 0.4138\n",
      "Epoch 32/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 1.4230 - f1: 0.4657 - val_loss: 1.5516 - val_f1: 0.4062\n",
      "Epoch 33/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.3923 - f1: 0.5071 - val_loss: 1.5167 - val_f1: 0.4436\n",
      "Epoch 34/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.3671 - f1: 0.5064 - val_loss: 1.4925 - val_f1: 0.4558\n",
      "Epoch 35/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 1.3379 - f1: 0.5313 - val_loss: 1.4743 - val_f1: 0.4685\n",
      "Epoch 36/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 1.3044 - f1: 0.5662 - val_loss: 1.4577 - val_f1: 0.4740\n",
      "Epoch 37/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 1.2939 - f1: 0.5529 - val_loss: 1.4364 - val_f1: 0.4964\n",
      "Epoch 38/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 1.2722 - f1: 0.5750 - val_loss: 1.4179 - val_f1: 0.5220\n",
      "Epoch 39/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 1.2540 - f1: 0.5824 - val_loss: 1.4053 - val_f1: 0.5112\n",
      "Epoch 40/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.2374 - f1: 0.5821 - val_loss: 1.3891 - val_f1: 0.5352\n",
      "Epoch 41/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 1.2109 - f1: 0.6170 - val_loss: 1.3721 - val_f1: 0.5382\n",
      "Epoch 42/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.1885 - f1: 0.6211 - val_loss: 1.3642 - val_f1: 0.5404\n",
      "Epoch 43/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.1677 - f1: 0.6400 - val_loss: 1.3438 - val_f1: 0.5739\n",
      "Epoch 44/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.1508 - f1: 0.6435 - val_loss: 1.3326 - val_f1: 0.5783\n",
      "Epoch 45/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 1.1492 - f1: 0.6441 - val_loss: 1.3181 - val_f1: 0.5879\n",
      "Epoch 46/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 1.1166 - f1: 0.6736 - val_loss: 1.3041 - val_f1: 0.6016\n",
      "Epoch 47/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.1020 - f1: 0.6691 - val_loss: 1.3007 - val_f1: 0.6117\n",
      "Epoch 48/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 1.0936 - f1: 0.6902 - val_loss: 1.2731 - val_f1: 0.6069\n",
      "Epoch 49/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.0696 - f1: 0.6935 - val_loss: 1.2633 - val_f1: 0.6219\n",
      "Epoch 50/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 1.0494 - f1: 0.7017 - val_loss: 1.2584 - val_f1: 0.6213\n",
      "Epoch 51/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.0329 - f1: 0.7105 - val_loss: 1.2505 - val_f1: 0.6287\n",
      "Epoch 52/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.0222 - f1: 0.7320 - val_loss: 1.2375 - val_f1: 0.6423\n",
      "Epoch 53/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 1.0062 - f1: 0.7369 - val_loss: 1.2383 - val_f1: 0.6445\n",
      "Epoch 54/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.9992 - f1: 0.7412 - val_loss: 1.2113 - val_f1: 0.6412\n",
      "Epoch 55/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.9781 - f1: 0.7484 - val_loss: 1.2124 - val_f1: 0.6612\n",
      "Epoch 56/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.9638 - f1: 0.7638 - val_loss: 1.2014 - val_f1: 0.6631\n",
      "Epoch 57/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.9590 - f1: 0.7657 - val_loss: 1.1831 - val_f1: 0.6684\n",
      "Epoch 58/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.9415 - f1: 0.7675 - val_loss: 1.1769 - val_f1: 0.6707\n",
      "Epoch 59/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.9298 - f1: 0.7857 - val_loss: 1.1699 - val_f1: 0.6768\n",
      "Epoch 60/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.9171 - f1: 0.7787 - val_loss: 1.1612 - val_f1: 0.6774\n",
      "Epoch 61/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.9083 - f1: 0.7743 - val_loss: 1.1522 - val_f1: 0.6834\n",
      "Epoch 62/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.8900 - f1: 0.7993 - val_loss: 1.1453 - val_f1: 0.6827\n",
      "Epoch 63/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.8807 - f1: 0.7992 - val_loss: 1.1370 - val_f1: 0.6829\n",
      "Epoch 64/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.8703 - f1: 0.8114 - val_loss: 1.1236 - val_f1: 0.6959\n",
      "Epoch 65/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.8571 - f1: 0.8064 - val_loss: 1.1203 - val_f1: 0.6958\n",
      "Epoch 66/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.8544 - f1: 0.8112 - val_loss: 1.1067 - val_f1: 0.7065\n",
      "Epoch 67/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.8331 - f1: 0.8319 - val_loss: 1.1027 - val_f1: 0.7011\n",
      "Epoch 68/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.8291 - f1: 0.8191 - val_loss: 1.0937 - val_f1: 0.7096\n",
      "Epoch 69/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.8200 - f1: 0.8379 - val_loss: 1.0847 - val_f1: 0.7103\n",
      "Epoch 70/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.8159 - f1: 0.8392 - val_loss: 1.0830 - val_f1: 0.7162\n",
      "Epoch 71/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.7991 - f1: 0.8467 - val_loss: 1.0744 - val_f1: 0.7158\n",
      "Epoch 72/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.7968 - f1: 0.8478 - val_loss: 1.0620 - val_f1: 0.7201\n",
      "Epoch 73/2000\n",
      "1000/1000 [==============================] - 1s 529us/sample - loss: 0.7740 - f1: 0.8516 - val_loss: 1.0658 - val_f1: 0.7212\n",
      "Epoch 74/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.7659 - f1: 0.8610 - val_loss: 1.0560 - val_f1: 0.7182\n",
      "Epoch 75/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 0.7604 - f1: 0.8564 - val_loss: 1.0486 - val_f1: 0.7278\n",
      "Epoch 76/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.7522 - f1: 0.8670 - val_loss: 1.0462 - val_f1: 0.7316\n",
      "Epoch 77/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.7594 - f1: 0.8615 - val_loss: 1.0436 - val_f1: 0.7249\n",
      "Epoch 78/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 0.7382 - f1: 0.8755 - val_loss: 1.0322 - val_f1: 0.7379\n",
      "Epoch 79/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.7265 - f1: 0.8791 - val_loss: 1.0236 - val_f1: 0.7357\n",
      "Epoch 80/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.7251 - f1: 0.8757 - val_loss: 1.0213 - val_f1: 0.7390\n",
      "Epoch 81/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.7125 - f1: 0.8772 - val_loss: 1.0164 - val_f1: 0.7403\n",
      "Epoch 82/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.7018 - f1: 0.8849 - val_loss: 1.0042 - val_f1: 0.7426\n",
      "Epoch 83/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.6957 - f1: 0.8909 - val_loss: 1.0074 - val_f1: 0.7486\n",
      "Epoch 84/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.6900 - f1: 0.8880 - val_loss: 1.0008 - val_f1: 0.7473\n",
      "Epoch 85/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.6809 - f1: 0.8920 - val_loss: 0.9974 - val_f1: 0.7488\n",
      "Epoch 86/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.6806 - f1: 0.8898 - val_loss: 0.9966 - val_f1: 0.7530\n",
      "Epoch 87/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.6740 - f1: 0.8926 - val_loss: 0.9968 - val_f1: 0.7500\n",
      "Epoch 88/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.6669 - f1: 0.9074 - val_loss: 0.9878 - val_f1: 0.7495\n",
      "Epoch 89/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.6573 - f1: 0.8990 - val_loss: 0.9837 - val_f1: 0.7534\n",
      "Epoch 90/2000\n",
      "1000/1000 [==============================] - 1s 530us/sample - loss: 0.6485 - f1: 0.9081 - val_loss: 0.9785 - val_f1: 0.7561\n",
      "Epoch 91/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.6446 - f1: 0.9110 - val_loss: 0.9734 - val_f1: 0.7582\n",
      "Epoch 92/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.6360 - f1: 0.9089 - val_loss: 0.9665 - val_f1: 0.7584\n",
      "Epoch 93/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.6389 - f1: 0.9045 - val_loss: 0.9690 - val_f1: 0.7545\n",
      "Epoch 94/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.6273 - f1: 0.9131 - val_loss: 0.9580 - val_f1: 0.7610\n",
      "Epoch 95/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.6150 - f1: 0.9190 - val_loss: 0.9600 - val_f1: 0.7694\n",
      "Epoch 96/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 0.6120 - f1: 0.9242 - val_loss: 0.9521 - val_f1: 0.7677\n",
      "Epoch 97/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.5995 - f1: 0.9200 - val_loss: 0.9538 - val_f1: 0.7640\n",
      "Epoch 98/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.6007 - f1: 0.9202 - val_loss: 0.9403 - val_f1: 0.7659\n",
      "Epoch 99/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.5945 - f1: 0.9273 - val_loss: 0.9425 - val_f1: 0.7724\n",
      "Epoch 100/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.5894 - f1: 0.9311 - val_loss: 0.9363 - val_f1: 0.7704\n",
      "Epoch 101/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.5814 - f1: 0.9330 - val_loss: 0.9309 - val_f1: 0.7731\n",
      "Epoch 102/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.5810 - f1: 0.9271 - val_loss: 0.9255 - val_f1: 0.7718\n",
      "Epoch 103/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.5693 - f1: 0.9313 - val_loss: 0.9364 - val_f1: 0.7697\n",
      "Epoch 104/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.5717 - f1: 0.9313 - val_loss: 0.9339 - val_f1: 0.7734\n",
      "Epoch 105/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.5684 - f1: 0.9304 - val_loss: 0.9173 - val_f1: 0.7775\n",
      "Running through fold 3\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 3.8500 - f1: 0.0000e+00 - val_loss: 3.7878 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 606us/sample - loss: 3.7417 - f1: 0.0000e+00 - val_loss: 3.6686 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 571us/sample - loss: 3.5861 - f1: 0.0000e+00 - val_loss: 3.4704 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 564us/sample - loss: 3.3686 - f1: 0.0000e+00 - val_loss: 3.2560 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 561us/sample - loss: 3.1680 - f1: 0.0038 - val_loss: 3.0737 - val_f1: 0.0019\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 551us/sample - loss: 2.9948 - f1: 0.0038 - val_loss: 2.9260 - val_f1: 0.0207\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 547us/sample - loss: 2.8374 - f1: 0.0368 - val_loss: 2.7765 - val_f1: 0.0656\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 543us/sample - loss: 2.7062 - f1: 0.0486 - val_loss: 2.6553 - val_f1: 0.0673\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 543us/sample - loss: 2.5714 - f1: 0.0782 - val_loss: 2.5433 - val_f1: 0.0932\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 2.4625 - f1: 0.0922 - val_loss: 2.4456 - val_f1: 0.1038\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 543us/sample - loss: 2.3695 - f1: 0.1232 - val_loss: 2.3584 - val_f1: 0.1265\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 2.2713 - f1: 0.1347 - val_loss: 2.2728 - val_f1: 0.1460\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 2.1967 - f1: 0.1569 - val_loss: 2.2081 - val_f1: 0.1744\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 2.1204 - f1: 0.1845 - val_loss: 2.1363 - val_f1: 0.1857\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 2.0570 - f1: 0.1927 - val_loss: 2.0706 - val_f1: 0.1916\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 1.9933 - f1: 0.2077 - val_loss: 2.0172 - val_f1: 0.2072\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 1.9360 - f1: 0.2240 - val_loss: 1.9704 - val_f1: 0.2221\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.8796 - f1: 0.2516 - val_loss: 1.9225 - val_f1: 0.2441\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 1.8144 - f1: 0.2603 - val_loss: 1.8743 - val_f1: 0.2558\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.7824 - f1: 0.2739 - val_loss: 1.8417 - val_f1: 0.2806\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.7320 - f1: 0.3141 - val_loss: 1.8011 - val_f1: 0.2791\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 1.6917 - f1: 0.3255 - val_loss: 1.7651 - val_f1: 0.2892\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 1.6406 - f1: 0.3422 - val_loss: 1.7373 - val_f1: 0.3379\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.6063 - f1: 0.3742 - val_loss: 1.7022 - val_f1: 0.3442\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 1.5704 - f1: 0.3742 - val_loss: 1.6616 - val_f1: 0.3542\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 1.5463 - f1: 0.3954 - val_loss: 1.6393 - val_f1: 0.3789\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 1.5088 - f1: 0.4299 - val_loss: 1.6134 - val_f1: 0.3881\n",
      "Epoch 28/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.4808 - f1: 0.4335 - val_loss: 1.5905 - val_f1: 0.4269\n",
      "Epoch 29/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 1.4451 - f1: 0.4796 - val_loss: 1.5560 - val_f1: 0.4172\n",
      "Epoch 30/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.4112 - f1: 0.4776 - val_loss: 1.5345 - val_f1: 0.4373\n",
      "Epoch 31/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 1.3881 - f1: 0.4929 - val_loss: 1.5354 - val_f1: 0.4646\n",
      "Epoch 32/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.3725 - f1: 0.5228 - val_loss: 1.4957 - val_f1: 0.4776\n",
      "Epoch 33/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 1.3422 - f1: 0.5189 - val_loss: 1.4739 - val_f1: 0.4887\n",
      "Epoch 34/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 1.3098 - f1: 0.5605 - val_loss: 1.4603 - val_f1: 0.4754\n",
      "Epoch 35/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.2844 - f1: 0.5768 - val_loss: 1.4380 - val_f1: 0.5063\n",
      "Epoch 36/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 1.2699 - f1: 0.5626 - val_loss: 1.4185 - val_f1: 0.5146\n",
      "Epoch 37/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.2455 - f1: 0.5991 - val_loss: 1.4059 - val_f1: 0.5352\n",
      "Epoch 38/2000\n",
      "1000/1000 [==============================] - 1s 542us/sample - loss: 1.2243 - f1: 0.6012 - val_loss: 1.3884 - val_f1: 0.5553\n",
      "Epoch 39/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 1.2130 - f1: 0.6147 - val_loss: 1.3799 - val_f1: 0.5601\n",
      "Epoch 40/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.1912 - f1: 0.6254 - val_loss: 1.3658 - val_f1: 0.5507\n",
      "Epoch 41/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.1668 - f1: 0.6426 - val_loss: 1.3451 - val_f1: 0.5760\n",
      "Epoch 42/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.1449 - f1: 0.6560 - val_loss: 1.3267 - val_f1: 0.5881\n",
      "Epoch 43/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 1.1299 - f1: 0.6529 - val_loss: 1.3144 - val_f1: 0.5854\n",
      "Epoch 44/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 1.1127 - f1: 0.6714 - val_loss: 1.3005 - val_f1: 0.6001\n",
      "Epoch 45/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 1.0942 - f1: 0.6873 - val_loss: 1.2914 - val_f1: 0.6111\n",
      "Epoch 46/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 1.0866 - f1: 0.7081 - val_loss: 1.2762 - val_f1: 0.6158\n",
      "Epoch 47/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 1.0644 - f1: 0.6990 - val_loss: 1.2743 - val_f1: 0.6083\n",
      "Epoch 48/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 1.0462 - f1: 0.7079 - val_loss: 1.2569 - val_f1: 0.6258\n",
      "Epoch 49/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.0275 - f1: 0.7214 - val_loss: 1.2466 - val_f1: 0.6374\n",
      "Epoch 50/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 1.0274 - f1: 0.7326 - val_loss: 1.2333 - val_f1: 0.6452\n",
      "Epoch 51/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 1.0079 - f1: 0.7341 - val_loss: 1.2234 - val_f1: 0.6531\n",
      "Epoch 52/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.9990 - f1: 0.7422 - val_loss: 1.2091 - val_f1: 0.6506\n",
      "Epoch 53/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.9773 - f1: 0.7511 - val_loss: 1.2056 - val_f1: 0.6533\n",
      "Epoch 54/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.9772 - f1: 0.7463 - val_loss: 1.1884 - val_f1: 0.6651\n",
      "Epoch 55/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.9519 - f1: 0.7709 - val_loss: 1.1755 - val_f1: 0.6703\n",
      "Epoch 56/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.9387 - f1: 0.7781 - val_loss: 1.1708 - val_f1: 0.6809\n",
      "Epoch 57/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.9285 - f1: 0.7858 - val_loss: 1.1755 - val_f1: 0.6752\n",
      "Epoch 58/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.9183 - f1: 0.7873 - val_loss: 1.1555 - val_f1: 0.6800\n",
      "Epoch 59/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.9000 - f1: 0.8002 - val_loss: 1.1468 - val_f1: 0.6886\n",
      "Epoch 60/2000\n",
      "1000/1000 [==============================] - 1s 543us/sample - loss: 0.8885 - f1: 0.7994 - val_loss: 1.1416 - val_f1: 0.6934\n",
      "Epoch 61/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.8784 - f1: 0.8078 - val_loss: 1.1330 - val_f1: 0.6993\n",
      "Epoch 62/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.8656 - f1: 0.8107 - val_loss: 1.1281 - val_f1: 0.7011\n",
      "Epoch 63/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.8513 - f1: 0.8228 - val_loss: 1.1221 - val_f1: 0.6990\n",
      "Epoch 64/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.8533 - f1: 0.8234 - val_loss: 1.1091 - val_f1: 0.7060\n",
      "Epoch 65/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.8445 - f1: 0.8220 - val_loss: 1.1086 - val_f1: 0.6983\n",
      "Epoch 66/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.8375 - f1: 0.8293 - val_loss: 1.1003 - val_f1: 0.7122\n",
      "Epoch 67/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 0.8255 - f1: 0.8275 - val_loss: 1.0922 - val_f1: 0.7138\n",
      "Epoch 68/2000\n",
      "1000/1000 [==============================] - 1s 544us/sample - loss: 0.8103 - f1: 0.8352 - val_loss: 1.0915 - val_f1: 0.7200\n",
      "Epoch 69/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.7986 - f1: 0.8514 - val_loss: 1.0778 - val_f1: 0.7222\n",
      "Epoch 70/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.7957 - f1: 0.8447 - val_loss: 1.0743 - val_f1: 0.7252\n",
      "Epoch 71/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.7749 - f1: 0.8517 - val_loss: 1.0598 - val_f1: 0.7293\n",
      "Epoch 72/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.7688 - f1: 0.8659 - val_loss: 1.0657 - val_f1: 0.7249\n",
      "Epoch 73/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.7629 - f1: 0.8579 - val_loss: 1.0545 - val_f1: 0.7346\n",
      "Epoch 74/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.7609 - f1: 0.8555 - val_loss: 1.0413 - val_f1: 0.7409\n",
      "Epoch 75/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.7569 - f1: 0.8633 - val_loss: 1.0419 - val_f1: 0.7412\n",
      "Epoch 76/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.7470 - f1: 0.8664 - val_loss: 1.0323 - val_f1: 0.7416\n",
      "Epoch 77/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.7293 - f1: 0.8814 - val_loss: 1.0263 - val_f1: 0.7436\n",
      "Epoch 78/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 0.7234 - f1: 0.8794 - val_loss: 1.0219 - val_f1: 0.7489\n",
      "Epoch 79/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.7221 - f1: 0.8677 - val_loss: 1.0134 - val_f1: 0.7479\n",
      "Epoch 80/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.7099 - f1: 0.8914 - val_loss: 1.0177 - val_f1: 0.7479\n",
      "Epoch 81/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.7059 - f1: 0.8866 - val_loss: 1.0009 - val_f1: 0.7546\n",
      "Epoch 82/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.6917 - f1: 0.8869 - val_loss: 1.0028 - val_f1: 0.7527\n",
      "Epoch 83/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.6838 - f1: 0.8996 - val_loss: 0.9999 - val_f1: 0.7556\n",
      "Epoch 84/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.6834 - f1: 0.8905 - val_loss: 0.9847 - val_f1: 0.7607\n",
      "Epoch 85/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 0.6698 - f1: 0.9059 - val_loss: 0.9891 - val_f1: 0.7595\n",
      "Epoch 86/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.6645 - f1: 0.8979 - val_loss: 0.9906 - val_f1: 0.7579\n",
      "Epoch 87/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 0.6529 - f1: 0.9084 - val_loss: 0.9808 - val_f1: 0.7608\n",
      "Epoch 88/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 0.6622 - f1: 0.9047 - val_loss: 0.9715 - val_f1: 0.7660\n",
      "Epoch 89/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.6441 - f1: 0.9110 - val_loss: 0.9788 - val_f1: 0.7674\n",
      "Epoch 90/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.6421 - f1: 0.9068 - val_loss: 0.9616 - val_f1: 0.7730\n",
      "Epoch 91/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.6315 - f1: 0.9062 - val_loss: 0.9625 - val_f1: 0.7727\n",
      "Epoch 92/2000\n",
      "1000/1000 [==============================] - 1s 535us/sample - loss: 0.6269 - f1: 0.9128 - val_loss: 0.9617 - val_f1: 0.7710\n",
      "Epoch 93/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.6291 - f1: 0.9157 - val_loss: 0.9608 - val_f1: 0.7711\n",
      "Epoch 94/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.6245 - f1: 0.9184 - val_loss: 0.9480 - val_f1: 0.7710\n",
      "Epoch 95/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.6126 - f1: 0.9232 - val_loss: 0.9475 - val_f1: 0.7743\n",
      "Epoch 96/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.6109 - f1: 0.9219 - val_loss: 0.9403 - val_f1: 0.7775\n",
      "Epoch 97/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.5975 - f1: 0.9348 - val_loss: 0.9387 - val_f1: 0.7769\n",
      "Epoch 98/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.5946 - f1: 0.9252 - val_loss: 0.9294 - val_f1: 0.7820\n",
      "Epoch 99/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.5901 - f1: 0.9264 - val_loss: 0.9397 - val_f1: 0.7809\n",
      "Epoch 100/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.5910 - f1: 0.9234 - val_loss: 0.9270 - val_f1: 0.7833\n",
      "Epoch 101/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.5766 - f1: 0.9291 - val_loss: 0.9223 - val_f1: 0.7884\n",
      "Epoch 102/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.5793 - f1: 0.9308 - val_loss: 0.9228 - val_f1: 0.7855\n",
      "Epoch 103/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.5760 - f1: 0.9312 - val_loss: 0.9179 - val_f1: 0.7830\n",
      "Epoch 104/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.5634 - f1: 0.9313 - val_loss: 0.9077 - val_f1: 0.7866\n",
      "Epoch 105/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.5602 - f1: 0.9387 - val_loss: 0.9061 - val_f1: 0.7891\n",
      "Epoch 106/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.5540 - f1: 0.9433 - val_loss: 0.9023 - val_f1: 0.7904\n",
      "Epoch 107/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.5491 - f1: 0.9420 - val_loss: 0.9116 - val_f1: 0.7879\n",
      "Epoch 108/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.5461 - f1: 0.9465 - val_loss: 0.9017 - val_f1: 0.7933\n",
      "Epoch 109/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.5435 - f1: 0.9401 - val_loss: 0.9057 - val_f1: 0.7911\n",
      "Epoch 110/2000\n",
      "1000/1000 [==============================] - 1s 533us/sample - loss: 0.5412 - f1: 0.9438 - val_loss: 0.8904 - val_f1: 0.7977\n",
      "Epoch 111/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.5357 - f1: 0.9459 - val_loss: 0.9122 - val_f1: 0.7856\n",
      "Epoch 112/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.5288 - f1: 0.9487 - val_loss: 0.8966 - val_f1: 0.7911\n",
      "Epoch 113/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 0.5241 - f1: 0.9488 - val_loss: 0.8810 - val_f1: 0.8003\n",
      "Epoch 114/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.5178 - f1: 0.9572 - val_loss: 0.8801 - val_f1: 0.7983\n",
      "Epoch 115/2000\n",
      "1000/1000 [==============================] - 1s 534us/sample - loss: 0.5103 - f1: 0.9573 - val_loss: 0.8789 - val_f1: 0.8021\n",
      "Epoch 116/2000\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 0.5080 - f1: 0.9533 - val_loss: 0.8825 - val_f1: 0.7937\n",
      "Epoch 117/2000\n",
      "1000/1000 [==============================] - 1s 532us/sample - loss: 0.5024 - f1: 0.9592 - val_loss: 0.8814 - val_f1: 0.7982\n",
      "Epoch 118/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.4982 - f1: 0.9601 - val_loss: 0.8851 - val_f1: 0.7997\n",
      "Running through fold 4\n",
      "Train on 1000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 3.8539 - f1: 0.0000e+00 - val_loss: 3.7851 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "1000/1000 [==============================] - 1s 608us/sample - loss: 3.7414 - f1: 0.0000e+00 - val_loss: 3.6607 - val_f1: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "1000/1000 [==============================] - 1s 582us/sample - loss: 3.5701 - f1: 0.0000e+00 - val_loss: 3.4482 - val_f1: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "1000/1000 [==============================] - 1s 563us/sample - loss: 3.3509 - f1: 0.0000e+00 - val_loss: 3.2510 - val_f1: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "1000/1000 [==============================] - 1s 561us/sample - loss: 3.1732 - f1: 0.0000e+00 - val_loss: 3.1189 - val_f1: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "1000/1000 [==============================] - 1s 557us/sample - loss: 3.0249 - f1: 0.0114 - val_loss: 2.9844 - val_f1: 0.0058\n",
      "Epoch 7/2000\n",
      "1000/1000 [==============================] - 1s 549us/sample - loss: 2.9021 - f1: 0.0114 - val_loss: 2.8653 - val_f1: 0.0287\n",
      "Epoch 8/2000\n",
      "1000/1000 [==============================] - 1s 551us/sample - loss: 2.7790 - f1: 0.0445 - val_loss: 2.7473 - val_f1: 0.0404\n",
      "Epoch 9/2000\n",
      "1000/1000 [==============================] - 1s 547us/sample - loss: 2.6687 - f1: 0.0547 - val_loss: 2.6243 - val_f1: 0.0802\n",
      "Epoch 10/2000\n",
      "1000/1000 [==============================] - 1s 542us/sample - loss: 2.5468 - f1: 0.0634 - val_loss: 2.5284 - val_f1: 0.0882\n",
      "Epoch 11/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 2.4515 - f1: 0.0922 - val_loss: 2.4397 - val_f1: 0.0966\n",
      "Epoch 12/2000\n",
      "1000/1000 [==============================] - 1s 544us/sample - loss: 2.3537 - f1: 0.0946 - val_loss: 2.3653 - val_f1: 0.1040\n",
      "Epoch 13/2000\n",
      "1000/1000 [==============================] - 1s 543us/sample - loss: 2.2790 - f1: 0.1046 - val_loss: 2.3062 - val_f1: 0.1070\n",
      "Epoch 14/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 2.2018 - f1: 0.1178 - val_loss: 2.2203 - val_f1: 0.1285\n",
      "Epoch 15/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 2.1289 - f1: 0.1412 - val_loss: 2.1617 - val_f1: 0.1501\n",
      "Epoch 16/2000\n",
      "1000/1000 [==============================] - 1s 543us/sample - loss: 2.0585 - f1: 0.1566 - val_loss: 2.1030 - val_f1: 0.1574\n",
      "Epoch 17/2000\n",
      "1000/1000 [==============================] - 1s 548us/sample - loss: 2.0038 - f1: 0.1828 - val_loss: 2.0566 - val_f1: 0.2125\n",
      "Epoch 18/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 1.9371 - f1: 0.2412 - val_loss: 1.9972 - val_f1: 0.2182\n",
      "Epoch 19/2000\n",
      "1000/1000 [==============================] - 1s 546us/sample - loss: 1.8997 - f1: 0.2422 - val_loss: 1.9504 - val_f1: 0.2574\n",
      "Epoch 20/2000\n",
      "1000/1000 [==============================] - 1s 543us/sample - loss: 1.8331 - f1: 0.2845 - val_loss: 1.9184 - val_f1: 0.2648\n",
      "Epoch 21/2000\n",
      "1000/1000 [==============================] - 1s 547us/sample - loss: 1.7776 - f1: 0.2966 - val_loss: 1.8669 - val_f1: 0.2892\n",
      "Epoch 22/2000\n",
      "1000/1000 [==============================] - 1s 548us/sample - loss: 1.7332 - f1: 0.3174 - val_loss: 1.8358 - val_f1: 0.3186\n",
      "Epoch 23/2000\n",
      "1000/1000 [==============================] - 1s 546us/sample - loss: 1.6957 - f1: 0.3439 - val_loss: 1.7940 - val_f1: 0.3228\n",
      "Epoch 24/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 1.6681 - f1: 0.3627 - val_loss: 1.7625 - val_f1: 0.3391\n",
      "Epoch 25/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 1.6163 - f1: 0.4033 - val_loss: 1.7279 - val_f1: 0.3449\n",
      "Epoch 26/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.5713 - f1: 0.4009 - val_loss: 1.6882 - val_f1: 0.3772\n",
      "Epoch 27/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 1.5407 - f1: 0.4188 - val_loss: 1.6655 - val_f1: 0.3955\n",
      "Epoch 28/2000\n",
      "1000/1000 [==============================] - 1s 543us/sample - loss: 1.5176 - f1: 0.4265 - val_loss: 1.6313 - val_f1: 0.3996\n",
      "Epoch 29/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.4768 - f1: 0.4606 - val_loss: 1.6186 - val_f1: 0.4193\n",
      "Epoch 30/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.4588 - f1: 0.4707 - val_loss: 1.5841 - val_f1: 0.4221\n",
      "Epoch 31/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 1.4201 - f1: 0.4919 - val_loss: 1.5680 - val_f1: 0.4434\n",
      "Epoch 32/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 1.3946 - f1: 0.5041 - val_loss: 1.5396 - val_f1: 0.4491\n",
      "Epoch 33/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 1.3646 - f1: 0.5371 - val_loss: 1.5115 - val_f1: 0.4653\n",
      "Epoch 34/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 1.3429 - f1: 0.5362 - val_loss: 1.5062 - val_f1: 0.4691\n",
      "Epoch 35/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 1.3107 - f1: 0.5515 - val_loss: 1.4735 - val_f1: 0.4893\n",
      "Epoch 36/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.2856 - f1: 0.5658 - val_loss: 1.4563 - val_f1: 0.4981\n",
      "Epoch 37/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 1.2571 - f1: 0.5860 - val_loss: 1.4434 - val_f1: 0.5172\n",
      "Epoch 38/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 1.2331 - f1: 0.5971 - val_loss: 1.4218 - val_f1: 0.5318\n",
      "Epoch 39/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.2176 - f1: 0.6137 - val_loss: 1.4047 - val_f1: 0.5407\n",
      "Epoch 40/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 1.1926 - f1: 0.6403 - val_loss: 1.3916 - val_f1: 0.5429\n",
      "Epoch 41/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 1.1721 - f1: 0.6333 - val_loss: 1.3687 - val_f1: 0.5641\n",
      "Epoch 42/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 1.1426 - f1: 0.6435 - val_loss: 1.3480 - val_f1: 0.5756\n",
      "Epoch 43/2000\n",
      "1000/1000 [==============================] - 1s 536us/sample - loss: 1.1300 - f1: 0.6564 - val_loss: 1.3486 - val_f1: 0.5821\n",
      "Epoch 44/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 1.1158 - f1: 0.6617 - val_loss: 1.3212 - val_f1: 0.5937\n",
      "Epoch 45/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 1.0979 - f1: 0.6690 - val_loss: 1.3156 - val_f1: 0.6019\n",
      "Epoch 46/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 1.0667 - f1: 0.6938 - val_loss: 1.2975 - val_f1: 0.6132\n",
      "Epoch 47/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.0606 - f1: 0.7011 - val_loss: 1.2826 - val_f1: 0.6180\n",
      "Epoch 48/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 1.0439 - f1: 0.7085 - val_loss: 1.2743 - val_f1: 0.6239\n",
      "Epoch 49/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 1.0259 - f1: 0.7247 - val_loss: 1.2616 - val_f1: 0.6338\n",
      "Epoch 50/2000\n",
      "1000/1000 [==============================] - 1s 547us/sample - loss: 1.0082 - f1: 0.7382 - val_loss: 1.2457 - val_f1: 0.6477\n",
      "Epoch 51/2000\n",
      "1000/1000 [==============================] - 1s 548us/sample - loss: 0.9928 - f1: 0.7541 - val_loss: 1.2496 - val_f1: 0.6524\n",
      "Epoch 52/2000\n",
      "1000/1000 [==============================] - 1s 547us/sample - loss: 0.9776 - f1: 0.7292 - val_loss: 1.2213 - val_f1: 0.6528\n",
      "Epoch 53/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.9646 - f1: 0.7590 - val_loss: 1.2185 - val_f1: 0.6587\n",
      "Epoch 54/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.9529 - f1: 0.7629 - val_loss: 1.2088 - val_f1: 0.6708\n",
      "Epoch 55/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.9249 - f1: 0.7799 - val_loss: 1.1932 - val_f1: 0.6702\n",
      "Epoch 56/2000\n",
      "1000/1000 [==============================] - 1s 546us/sample - loss: 0.9172 - f1: 0.7762 - val_loss: 1.1803 - val_f1: 0.6813\n",
      "Epoch 57/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.9120 - f1: 0.7766 - val_loss: 1.1727 - val_f1: 0.6788\n",
      "Epoch 58/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.8974 - f1: 0.7914 - val_loss: 1.1613 - val_f1: 0.6901\n",
      "Epoch 59/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.8834 - f1: 0.7950 - val_loss: 1.1541 - val_f1: 0.6909\n",
      "Epoch 60/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.8788 - f1: 0.8010 - val_loss: 1.1633 - val_f1: 0.6958\n",
      "Epoch 61/2000\n",
      "1000/1000 [==============================] - 1s 544us/sample - loss: 0.8586 - f1: 0.8011 - val_loss: 1.1491 - val_f1: 0.7033\n",
      "Epoch 62/2000\n",
      "1000/1000 [==============================] - 1s 546us/sample - loss: 0.8477 - f1: 0.8164 - val_loss: 1.1297 - val_f1: 0.7044\n",
      "Epoch 63/2000\n",
      "1000/1000 [==============================] - 1s 542us/sample - loss: 0.8365 - f1: 0.8305 - val_loss: 1.1220 - val_f1: 0.7076\n",
      "Epoch 64/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.8194 - f1: 0.8298 - val_loss: 1.1142 - val_f1: 0.7149\n",
      "Epoch 65/2000\n",
      "1000/1000 [==============================] - 1s 543us/sample - loss: 0.8141 - f1: 0.8259 - val_loss: 1.1137 - val_f1: 0.7199\n",
      "Epoch 66/2000\n",
      "1000/1000 [==============================] - 1s 547us/sample - loss: 0.8090 - f1: 0.8373 - val_loss: 1.1175 - val_f1: 0.7163\n",
      "Epoch 67/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.7941 - f1: 0.8352 - val_loss: 1.0953 - val_f1: 0.7218\n",
      "Epoch 68/2000\n",
      "1000/1000 [==============================] - 1s 546us/sample - loss: 0.7864 - f1: 0.8410 - val_loss: 1.0905 - val_f1: 0.7227\n",
      "Epoch 69/2000\n",
      "1000/1000 [==============================] - 1s 547us/sample - loss: 0.7737 - f1: 0.8479 - val_loss: 1.0870 - val_f1: 0.7246\n",
      "Epoch 70/2000\n",
      "1000/1000 [==============================] - 1s 550us/sample - loss: 0.7659 - f1: 0.8446 - val_loss: 1.0737 - val_f1: 0.7338\n",
      "Epoch 71/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.7625 - f1: 0.8535 - val_loss: 1.0737 - val_f1: 0.7302\n",
      "Epoch 72/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.7408 - f1: 0.8644 - val_loss: 1.0618 - val_f1: 0.7401\n",
      "Epoch 73/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.7343 - f1: 0.8716 - val_loss: 1.0586 - val_f1: 0.7352\n",
      "Epoch 74/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.7328 - f1: 0.8707 - val_loss: 1.0523 - val_f1: 0.7431\n",
      "Epoch 75/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.7190 - f1: 0.8717 - val_loss: 1.0507 - val_f1: 0.7410\n",
      "Epoch 76/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.7104 - f1: 0.8750 - val_loss: 1.0432 - val_f1: 0.7457\n",
      "Epoch 77/2000\n",
      "1000/1000 [==============================] - 1s 549us/sample - loss: 0.7070 - f1: 0.8779 - val_loss: 1.0284 - val_f1: 0.7489\n",
      "Epoch 78/2000\n",
      "1000/1000 [==============================] - 1s 545us/sample - loss: 0.6984 - f1: 0.8865 - val_loss: 1.0374 - val_f1: 0.7469\n",
      "Epoch 79/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.6937 - f1: 0.8842 - val_loss: 1.0211 - val_f1: 0.7549\n",
      "Epoch 80/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.6776 - f1: 0.8883 - val_loss: 1.0207 - val_f1: 0.7604\n",
      "Epoch 81/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.6800 - f1: 0.8887 - val_loss: 1.0333 - val_f1: 0.7543\n",
      "Epoch 82/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.6658 - f1: 0.9016 - val_loss: 1.0182 - val_f1: 0.7571\n",
      "Epoch 83/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.6538 - f1: 0.9078 - val_loss: 1.0159 - val_f1: 0.7594\n",
      "Epoch 84/2000\n",
      "1000/1000 [==============================] - 1s 546us/sample - loss: 0.6563 - f1: 0.8927 - val_loss: 0.9990 - val_f1: 0.7634\n",
      "Epoch 85/2000\n",
      "1000/1000 [==============================] - 1s 545us/sample - loss: 0.6412 - f1: 0.9142 - val_loss: 1.0111 - val_f1: 0.7595\n",
      "Epoch 86/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.6404 - f1: 0.9024 - val_loss: 0.9981 - val_f1: 0.7687\n",
      "Epoch 87/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.6397 - f1: 0.9069 - val_loss: 0.9878 - val_f1: 0.7708\n",
      "Epoch 88/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.6279 - f1: 0.9183 - val_loss: 0.9834 - val_f1: 0.7719\n",
      "Epoch 89/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.6217 - f1: 0.9116 - val_loss: 0.9864 - val_f1: 0.7714\n",
      "Epoch 90/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.6137 - f1: 0.9181 - val_loss: 0.9765 - val_f1: 0.7746\n",
      "Epoch 91/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.6029 - f1: 0.9258 - val_loss: 0.9640 - val_f1: 0.7740\n",
      "Epoch 92/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.6001 - f1: 0.9193 - val_loss: 0.9668 - val_f1: 0.7739\n",
      "Epoch 93/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.5986 - f1: 0.9212 - val_loss: 0.9721 - val_f1: 0.7721\n",
      "Epoch 94/2000\n",
      "1000/1000 [==============================] - 1s 544us/sample - loss: 0.5912 - f1: 0.9339 - val_loss: 0.9603 - val_f1: 0.7798\n",
      "Epoch 95/2000\n",
      "1000/1000 [==============================] - 1s 542us/sample - loss: 0.5798 - f1: 0.9324 - val_loss: 0.9632 - val_f1: 0.7773\n",
      "Epoch 96/2000\n",
      "1000/1000 [==============================] - 1s 546us/sample - loss: 0.5758 - f1: 0.9358 - val_loss: 0.9526 - val_f1: 0.7789\n",
      "Epoch 97/2000\n",
      "1000/1000 [==============================] - 1s 545us/sample - loss: 0.5645 - f1: 0.9409 - val_loss: 0.9507 - val_f1: 0.7812\n",
      "Epoch 98/2000\n",
      "1000/1000 [==============================] - 1s 546us/sample - loss: 0.5654 - f1: 0.9359 - val_loss: 0.9459 - val_f1: 0.7844\n",
      "Epoch 99/2000\n",
      "1000/1000 [==============================] - 1s 544us/sample - loss: 0.5543 - f1: 0.9407 - val_loss: 0.9385 - val_f1: 0.7853\n",
      "Epoch 100/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.5507 - f1: 0.9444 - val_loss: 0.9362 - val_f1: 0.7864\n",
      "Epoch 101/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.5453 - f1: 0.9385 - val_loss: 0.9432 - val_f1: 0.7848\n",
      "Epoch 102/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.5459 - f1: 0.9423 - val_loss: 0.9350 - val_f1: 0.7879\n",
      "Epoch 103/2000\n",
      "1000/1000 [==============================] - 1s 542us/sample - loss: 0.5343 - f1: 0.9486 - val_loss: 0.9253 - val_f1: 0.7879\n",
      "Epoch 104/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.5355 - f1: 0.9423 - val_loss: 0.9265 - val_f1: 0.7868\n",
      "Epoch 105/2000\n",
      "1000/1000 [==============================] - 1s 539us/sample - loss: 0.5274 - f1: 0.9468 - val_loss: 0.9318 - val_f1: 0.7854\n",
      "Epoch 106/2000\n",
      "1000/1000 [==============================] - 1s 537us/sample - loss: 0.5342 - f1: 0.9454 - val_loss: 0.9150 - val_f1: 0.7952\n",
      "Epoch 107/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.5159 - f1: 0.9514 - val_loss: 0.9199 - val_f1: 0.7936\n",
      "Epoch 108/2000\n",
      "1000/1000 [==============================] - 1s 542us/sample - loss: 0.5127 - f1: 0.9570 - val_loss: 0.9080 - val_f1: 0.7948\n",
      "Epoch 109/2000\n",
      "1000/1000 [==============================] - 1s 542us/sample - loss: 0.5121 - f1: 0.9531 - val_loss: 0.9169 - val_f1: 0.7925\n",
      "Epoch 110/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.5070 - f1: 0.9574 - val_loss: 0.9092 - val_f1: 0.7901\n",
      "Epoch 111/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.5021 - f1: 0.9562 - val_loss: 0.9045 - val_f1: 0.7971\n",
      "Epoch 112/2000\n",
      "1000/1000 [==============================] - 1s 545us/sample - loss: 0.4988 - f1: 0.9564 - val_loss: 0.9040 - val_f1: 0.7971\n",
      "Epoch 113/2000\n",
      "1000/1000 [==============================] - 1s 540us/sample - loss: 0.4941 - f1: 0.9569 - val_loss: 0.8973 - val_f1: 0.7967\n",
      "Epoch 114/2000\n",
      "1000/1000 [==============================] - 1s 541us/sample - loss: 0.4848 - f1: 0.9632 - val_loss: 0.8963 - val_f1: 0.7990\n",
      "Epoch 115/2000\n",
      "1000/1000 [==============================] - 1s 538us/sample - loss: 0.4889 - f1: 0.9556 - val_loss: 0.8946 - val_f1: 0.7942\n",
      "Epoch 116/2000\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.4735 - f1: 0.9638 - val_loss: 0.9016 - val_f1: 0.7971\n",
      "\n",
      "\n",
      "Running through training size 5000\n",
      "Running through fold 0\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 4s 742us/sample - loss: 3.5845 - f1: 7.7205e-04 - val_loss: 3.1659 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 2.8363 - f1: 0.0484 - val_loss: 2.5012 - val_f1: 0.0833\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 2.3074 - f1: 0.1218 - val_loss: 2.1048 - val_f1: 0.1893\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 1.9923 - f1: 0.2172 - val_loss: 1.8704 - val_f1: 0.2536\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 1.7930 - f1: 0.2987 - val_loss: 1.6961 - val_f1: 0.3417\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 1.6346 - f1: 0.3722 - val_loss: 1.5439 - val_f1: 0.4255\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 1.5087 - f1: 0.4437 - val_loss: 1.4469 - val_f1: 0.4973\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 1.4119 - f1: 0.5026 - val_loss: 1.3595 - val_f1: 0.5452\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 1.3247 - f1: 0.5485 - val_loss: 1.2860 - val_f1: 0.5860\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 1.2502 - f1: 0.5984 - val_loss: 1.2211 - val_f1: 0.6192\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 1.1827 - f1: 0.6348 - val_loss: 1.1576 - val_f1: 0.6519\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 1.1295 - f1: 0.6649 - val_loss: 1.1117 - val_f1: 0.6795\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 1.0724 - f1: 0.7004 - val_loss: 1.0696 - val_f1: 0.7094\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 1.0276 - f1: 0.7178 - val_loss: 1.0318 - val_f1: 0.7180\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.9870 - f1: 0.7398 - val_loss: 0.9937 - val_f1: 0.7371\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.9450 - f1: 0.7615 - val_loss: 0.9691 - val_f1: 0.7507\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.9160 - f1: 0.7695 - val_loss: 0.9646 - val_f1: 0.7503\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.8863 - f1: 0.7803 - val_loss: 0.9050 - val_f1: 0.7743\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.8474 - f1: 0.7937 - val_loss: 0.8864 - val_f1: 0.7784\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.8203 - f1: 0.8056 - val_loss: 0.8683 - val_f1: 0.7866\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.7977 - f1: 0.8152 - val_loss: 0.8367 - val_f1: 0.7958\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.7700 - f1: 0.8262 - val_loss: 0.8136 - val_f1: 0.8078\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.7453 - f1: 0.8320 - val_loss: 0.7967 - val_f1: 0.8091\n",
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.7231 - f1: 0.8400 - val_loss: 0.7927 - val_f1: 0.8142\n",
      "Epoch 25/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.7064 - f1: 0.8468 - val_loss: 0.7615 - val_f1: 0.8222\n",
      "Epoch 26/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.6805 - f1: 0.8571 - val_loss: 0.7509 - val_f1: 0.8275\n",
      "Epoch 27/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.6742 - f1: 0.8596 - val_loss: 0.7334 - val_f1: 0.8321\n",
      "Epoch 28/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.6482 - f1: 0.8694 - val_loss: 0.7219 - val_f1: 0.8366\n",
      "Epoch 29/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.6351 - f1: 0.8725 - val_loss: 0.7016 - val_f1: 0.8458\n",
      "Epoch 30/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.6182 - f1: 0.8815 - val_loss: 0.7009 - val_f1: 0.8441\n",
      "Epoch 31/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.6072 - f1: 0.8829 - val_loss: 0.6843 - val_f1: 0.8544\n",
      "Epoch 32/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.5854 - f1: 0.8906 - val_loss: 0.6744 - val_f1: 0.8533\n",
      "Epoch 33/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.5748 - f1: 0.8953 - val_loss: 0.6743 - val_f1: 0.8529\n",
      "Epoch 34/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.5637 - f1: 0.8963 - val_loss: 0.6551 - val_f1: 0.8595\n",
      "Epoch 35/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.5555 - f1: 0.8987 - val_loss: 0.6437 - val_f1: 0.8651\n",
      "Epoch 36/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.5404 - f1: 0.9051 - val_loss: 0.6355 - val_f1: 0.8696\n",
      "Epoch 37/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.5279 - f1: 0.9084 - val_loss: 0.6210 - val_f1: 0.8700\n",
      "Epoch 38/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.5225 - f1: 0.9095 - val_loss: 0.6132 - val_f1: 0.8722\n",
      "Epoch 39/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.5061 - f1: 0.9165 - val_loss: 0.6204 - val_f1: 0.8715\n",
      "Epoch 40/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.5017 - f1: 0.9157 - val_loss: 0.6008 - val_f1: 0.8736\n",
      "Epoch 41/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.4880 - f1: 0.9221 - val_loss: 0.5901 - val_f1: 0.8800\n",
      "Epoch 42/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.4791 - f1: 0.9267 - val_loss: 0.6115 - val_f1: 0.8702\n",
      "Epoch 43/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.4685 - f1: 0.9267 - val_loss: 0.5858 - val_f1: 0.8766\n",
      "Epoch 44/2000\n",
      "5000/5000 [==============================] - 2s 304us/sample - loss: 0.4646 - f1: 0.9293 - val_loss: 0.5734 - val_f1: 0.8849\n",
      "Epoch 45/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.4558 - f1: 0.9340 - val_loss: 0.5653 - val_f1: 0.8844\n",
      "Epoch 46/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.4485 - f1: 0.9343 - val_loss: 0.5481 - val_f1: 0.8931\n",
      "Epoch 47/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.4423 - f1: 0.9335 - val_loss: 0.5584 - val_f1: 0.8888\n",
      "Epoch 48/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.4290 - f1: 0.9407 - val_loss: 0.5429 - val_f1: 0.8909\n",
      "Epoch 49/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.4208 - f1: 0.9430 - val_loss: 0.5472 - val_f1: 0.8893\n",
      "Epoch 50/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.4204 - f1: 0.9416 - val_loss: 0.5261 - val_f1: 0.8976\n",
      "Epoch 51/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.4073 - f1: 0.9452 - val_loss: 0.5226 - val_f1: 0.8972\n",
      "Epoch 52/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.4019 - f1: 0.9460 - val_loss: 0.5237 - val_f1: 0.8954\n",
      "Epoch 53/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.3923 - f1: 0.9471 - val_loss: 0.5421 - val_f1: 0.8896\n",
      "Epoch 54/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.3909 - f1: 0.9475 - val_loss: 0.5136 - val_f1: 0.8949\n",
      "Epoch 55/2000\n",
      "5000/5000 [==============================] - 2s 305us/sample - loss: 0.3860 - f1: 0.9478 - val_loss: 0.5054 - val_f1: 0.9003\n",
      "Epoch 56/2000\n",
      "5000/5000 [==============================] - 4s 797us/sample - loss: 0.3808 - f1: 0.9492 - val_loss: 0.4987 - val_f1: 0.8981\n",
      "Running through fold 1\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 4s 780us/sample - loss: 3.5342 - f1: 0.0069 - val_loss: 3.0760 - val_f1: 0.0380\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 2.7700 - f1: 0.0738 - val_loss: 2.4689 - val_f1: 0.1117\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 2.2869 - f1: 0.1399 - val_loss: 2.0915 - val_f1: 0.1962\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 1.9815 - f1: 0.2254 - val_loss: 1.8549 - val_f1: 0.2662\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 1.7701 - f1: 0.2918 - val_loss: 1.6804 - val_f1: 0.3370\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 1.6248 - f1: 0.3645 - val_loss: 1.5605 - val_f1: 0.3918\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 1.5017 - f1: 0.4328 - val_loss: 1.4561 - val_f1: 0.4456\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 1.4050 - f1: 0.5006 - val_loss: 1.3712 - val_f1: 0.5214\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 1.3284 - f1: 0.5467 - val_loss: 1.2949 - val_f1: 0.5808\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 1.2520 - f1: 0.5958 - val_loss: 1.2395 - val_f1: 0.6048\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 1.1892 - f1: 0.6325 - val_loss: 1.1879 - val_f1: 0.6529\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 1.1399 - f1: 0.6639 - val_loss: 1.1485 - val_f1: 0.6714\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 1.0870 - f1: 0.6912 - val_loss: 1.0945 - val_f1: 0.6981\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 1.0466 - f1: 0.7116 - val_loss: 1.0631 - val_f1: 0.7105\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 1.0095 - f1: 0.7249 - val_loss: 1.0357 - val_f1: 0.7225\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.9694 - f1: 0.7458 - val_loss: 0.9941 - val_f1: 0.7330\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.9324 - f1: 0.7628 - val_loss: 0.9677 - val_f1: 0.7401\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.9006 - f1: 0.7744 - val_loss: 0.9446 - val_f1: 0.7550\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.8734 - f1: 0.7865 - val_loss: 0.9069 - val_f1: 0.7758\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.8483 - f1: 0.7958 - val_loss: 0.8888 - val_f1: 0.7768\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.8225 - f1: 0.8035 - val_loss: 0.8652 - val_f1: 0.7908\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.7963 - f1: 0.8141 - val_loss: 0.8547 - val_f1: 0.7891\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.7731 - f1: 0.8240 - val_loss: 0.8340 - val_f1: 0.7991\n",
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.7550 - f1: 0.8285 - val_loss: 0.8127 - val_f1: 0.8009\n",
      "Epoch 25/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.7332 - f1: 0.8378 - val_loss: 0.8134 - val_f1: 0.8075\n",
      "Epoch 26/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.7166 - f1: 0.8449 - val_loss: 0.7786 - val_f1: 0.8194\n",
      "Epoch 27/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.6941 - f1: 0.8502 - val_loss: 0.7788 - val_f1: 0.8196\n",
      "Epoch 28/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.6759 - f1: 0.8607 - val_loss: 0.7542 - val_f1: 0.8237\n",
      "Epoch 29/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.6615 - f1: 0.8615 - val_loss: 0.7540 - val_f1: 0.8260\n",
      "Epoch 30/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.6483 - f1: 0.8681 - val_loss: 0.7376 - val_f1: 0.8314\n",
      "Epoch 31/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.6332 - f1: 0.8694 - val_loss: 0.7216 - val_f1: 0.8369\n",
      "Epoch 32/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.6199 - f1: 0.8754 - val_loss: 0.7187 - val_f1: 0.8350\n",
      "Epoch 33/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.6064 - f1: 0.8815 - val_loss: 0.7060 - val_f1: 0.8368\n",
      "Epoch 34/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.5949 - f1: 0.8864 - val_loss: 0.6992 - val_f1: 0.8374\n",
      "Epoch 35/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.5821 - f1: 0.8867 - val_loss: 0.6910 - val_f1: 0.8365\n",
      "Epoch 36/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.5688 - f1: 0.8921 - val_loss: 0.6750 - val_f1: 0.8447\n",
      "Epoch 37/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.5603 - f1: 0.8971 - val_loss: 0.6697 - val_f1: 0.8505\n",
      "Epoch 38/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.5468 - f1: 0.8989 - val_loss: 0.6593 - val_f1: 0.8493\n",
      "Epoch 39/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.5399 - f1: 0.9035 - val_loss: 0.6554 - val_f1: 0.8511\n",
      "Epoch 40/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.5251 - f1: 0.9078 - val_loss: 0.6543 - val_f1: 0.8532\n",
      "Epoch 41/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.5222 - f1: 0.9081 - val_loss: 0.6458 - val_f1: 0.8589\n",
      "Epoch 42/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.5060 - f1: 0.9128 - val_loss: 0.6436 - val_f1: 0.8520\n",
      "Epoch 43/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.4965 - f1: 0.9173 - val_loss: 0.6109 - val_f1: 0.8688\n",
      "Epoch 44/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.4888 - f1: 0.9191 - val_loss: 0.6178 - val_f1: 0.8639\n",
      "Epoch 45/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.4803 - f1: 0.9244 - val_loss: 0.6113 - val_f1: 0.8640\n",
      "Epoch 46/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.4720 - f1: 0.9218 - val_loss: 0.5936 - val_f1: 0.8674\n",
      "Epoch 47/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.4673 - f1: 0.9201 - val_loss: 0.6046 - val_f1: 0.8629\n",
      "Epoch 48/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.4539 - f1: 0.9289 - val_loss: 0.5968 - val_f1: 0.8678\n",
      "Epoch 49/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.4515 - f1: 0.9252 - val_loss: 0.5928 - val_f1: 0.8700\n",
      "Epoch 50/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.4439 - f1: 0.9327 - val_loss: 0.5853 - val_f1: 0.8658\n",
      "Epoch 51/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.4352 - f1: 0.9335 - val_loss: 0.5764 - val_f1: 0.8702\n",
      "Epoch 52/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.4277 - f1: 0.9333 - val_loss: 0.5886 - val_f1: 0.8720\n",
      "Epoch 53/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.4189 - f1: 0.9376 - val_loss: 0.5765 - val_f1: 0.8720\n",
      "Epoch 54/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.4115 - f1: 0.9410 - val_loss: 0.5634 - val_f1: 0.8746\n",
      "Epoch 55/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.4057 - f1: 0.9403 - val_loss: 0.5604 - val_f1: 0.8706\n",
      "Epoch 56/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.4062 - f1: 0.9399 - val_loss: 0.5533 - val_f1: 0.8741\n",
      "Epoch 57/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.3975 - f1: 0.9421 - val_loss: 0.5565 - val_f1: 0.8778\n",
      "Epoch 58/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.3890 - f1: 0.9453 - val_loss: 0.5472 - val_f1: 0.8753\n",
      "Epoch 59/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.3858 - f1: 0.9457 - val_loss: 0.5377 - val_f1: 0.8818\n",
      "Epoch 60/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.3792 - f1: 0.9474 - val_loss: 0.5409 - val_f1: 0.8795\n",
      "Epoch 61/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.3726 - f1: 0.9509 - val_loss: 0.5275 - val_f1: 0.8824\n",
      "Epoch 62/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.3649 - f1: 0.9471 - val_loss: 0.5251 - val_f1: 0.8792\n",
      "Epoch 63/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.3645 - f1: 0.9510 - val_loss: 0.5275 - val_f1: 0.8835\n",
      "Epoch 64/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.3576 - f1: 0.9520 - val_loss: 0.5218 - val_f1: 0.8861\n",
      "Epoch 65/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.3561 - f1: 0.9538 - val_loss: 0.5169 - val_f1: 0.8828\n",
      "Epoch 66/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.3468 - f1: 0.9532 - val_loss: 0.5143 - val_f1: 0.8830\n",
      "Epoch 67/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.3417 - f1: 0.9563 - val_loss: 0.5141 - val_f1: 0.8812\n",
      "Epoch 68/2000\n",
      "5000/5000 [==============================] - 2s 306us/sample - loss: 0.3372 - f1: 0.9566 - val_loss: 0.5159 - val_f1: 0.8831\n",
      "Epoch 69/2000\n",
      "5000/5000 [==============================] - 4s 721us/sample - loss: 0.3358 - f1: 0.9547 - val_loss: 0.5150 - val_f1: 0.8790\n",
      "Running through fold 2\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 4s 781us/sample - loss: 3.6263 - f1: 0.0012 - val_loss: 3.2219 - val_f1: 0.0122\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 2.9122 - f1: 0.0697 - val_loss: 2.6019 - val_f1: 0.0912\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 2.3889 - f1: 0.1081 - val_loss: 2.1962 - val_f1: 0.1473\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 2.0528 - f1: 0.1945 - val_loss: 1.9291 - val_f1: 0.2660\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 1.8300 - f1: 0.2855 - val_loss: 1.7450 - val_f1: 0.3126\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 1.6561 - f1: 0.3560 - val_loss: 1.5813 - val_f1: 0.4017\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 1.5176 - f1: 0.4276 - val_loss: 1.4662 - val_f1: 0.4513\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 1.4079 - f1: 0.4918 - val_loss: 1.3670 - val_f1: 0.5231\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 1.3188 - f1: 0.5456 - val_loss: 1.2883 - val_f1: 0.5737\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 1.2427 - f1: 0.5995 - val_loss: 1.2284 - val_f1: 0.6268\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 1.1793 - f1: 0.6376 - val_loss: 1.1662 - val_f1: 0.6620\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 1.1212 - f1: 0.6762 - val_loss: 1.1357 - val_f1: 0.6780\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 1.0754 - f1: 0.7057 - val_loss: 1.0792 - val_f1: 0.7062\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 1.0315 - f1: 0.7254 - val_loss: 1.0471 - val_f1: 0.7238\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.9922 - f1: 0.7408 - val_loss: 1.0105 - val_f1: 0.7385\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.9522 - f1: 0.7603 - val_loss: 0.9744 - val_f1: 0.7480\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.9185 - f1: 0.7778 - val_loss: 0.9496 - val_f1: 0.7620\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.8835 - f1: 0.7856 - val_loss: 0.9193 - val_f1: 0.7715\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.8579 - f1: 0.8017 - val_loss: 0.8890 - val_f1: 0.7817\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.8320 - f1: 0.8104 - val_loss: 0.8735 - val_f1: 0.7883\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.8058 - f1: 0.8197 - val_loss: 0.8555 - val_f1: 0.7946\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.7832 - f1: 0.8251 - val_loss: 0.8364 - val_f1: 0.8058\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.7665 - f1: 0.8333 - val_loss: 0.8181 - val_f1: 0.8091\n",
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.7356 - f1: 0.8431 - val_loss: 0.7956 - val_f1: 0.8199\n",
      "Epoch 25/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.7146 - f1: 0.8542 - val_loss: 0.7861 - val_f1: 0.8230\n",
      "Epoch 26/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.7019 - f1: 0.8574 - val_loss: 0.7721 - val_f1: 0.8292\n",
      "Epoch 27/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.6796 - f1: 0.8623 - val_loss: 0.7647 - val_f1: 0.8230\n",
      "Epoch 28/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.6689 - f1: 0.8662 - val_loss: 0.7403 - val_f1: 0.8363\n",
      "Epoch 29/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.6469 - f1: 0.8735 - val_loss: 0.7251 - val_f1: 0.8431\n",
      "Epoch 30/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.6295 - f1: 0.8802 - val_loss: 0.7215 - val_f1: 0.8475\n",
      "Epoch 31/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.6158 - f1: 0.8808 - val_loss: 0.6988 - val_f1: 0.8481\n",
      "Epoch 32/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.5983 - f1: 0.8920 - val_loss: 0.6845 - val_f1: 0.8579\n",
      "Epoch 33/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.5879 - f1: 0.8891 - val_loss: 0.6760 - val_f1: 0.8612\n",
      "Epoch 34/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.5760 - f1: 0.8985 - val_loss: 0.6670 - val_f1: 0.8601\n",
      "Epoch 35/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.5568 - f1: 0.9044 - val_loss: 0.6603 - val_f1: 0.8662\n",
      "Epoch 36/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.5516 - f1: 0.9061 - val_loss: 0.6563 - val_f1: 0.8660\n",
      "Epoch 37/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.5383 - f1: 0.9072 - val_loss: 0.6286 - val_f1: 0.8726\n",
      "Epoch 38/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.5221 - f1: 0.9157 - val_loss: 0.6255 - val_f1: 0.8793\n",
      "Epoch 39/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.5160 - f1: 0.9147 - val_loss: 0.6150 - val_f1: 0.8787\n",
      "Epoch 40/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.5030 - f1: 0.9229 - val_loss: 0.6203 - val_f1: 0.8714\n",
      "Epoch 41/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.4929 - f1: 0.9240 - val_loss: 0.6004 - val_f1: 0.8803\n",
      "Epoch 42/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.4835 - f1: 0.9268 - val_loss: 0.5992 - val_f1: 0.8788\n",
      "Epoch 43/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.4710 - f1: 0.9322 - val_loss: 0.5789 - val_f1: 0.8855\n",
      "Epoch 44/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.4656 - f1: 0.9294 - val_loss: 0.5720 - val_f1: 0.8850\n",
      "Epoch 45/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.4555 - f1: 0.9327 - val_loss: 0.5757 - val_f1: 0.8878\n",
      "Epoch 46/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.4500 - f1: 0.9342 - val_loss: 0.5963 - val_f1: 0.8858\n",
      "Epoch 47/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.4475 - f1: 0.9328 - val_loss: 0.5784 - val_f1: 0.8867\n",
      "Epoch 48/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.4287 - f1: 0.9439 - val_loss: 0.5717 - val_f1: 0.8840\n",
      "Epoch 49/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.4247 - f1: 0.9413 - val_loss: 0.5453 - val_f1: 0.8914\n",
      "Epoch 50/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.4114 - f1: 0.9469 - val_loss: 0.5479 - val_f1: 0.8891\n",
      "Epoch 51/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.4100 - f1: 0.9470 - val_loss: 0.5392 - val_f1: 0.8936\n",
      "Epoch 52/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3951 - f1: 0.9512 - val_loss: 0.5442 - val_f1: 0.8898\n",
      "Epoch 53/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3898 - f1: 0.9534 - val_loss: 0.5285 - val_f1: 0.8955\n",
      "Epoch 54/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.3860 - f1: 0.9524 - val_loss: 0.5216 - val_f1: 0.8997\n",
      "Epoch 55/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.3838 - f1: 0.9525 - val_loss: 0.5192 - val_f1: 0.8997\n",
      "Epoch 56/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.3723 - f1: 0.9568 - val_loss: 0.5010 - val_f1: 0.9046\n",
      "Epoch 57/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.3702 - f1: 0.9556 - val_loss: 0.5192 - val_f1: 0.8928\n",
      "Epoch 58/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.3626 - f1: 0.9586 - val_loss: 0.4961 - val_f1: 0.9031\n",
      "Epoch 59/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.3549 - f1: 0.9605 - val_loss: 0.4876 - val_f1: 0.9071\n",
      "Epoch 60/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3541 - f1: 0.9588 - val_loss: 0.4888 - val_f1: 0.9015\n",
      "Epoch 61/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.3459 - f1: 0.9591 - val_loss: 0.5016 - val_f1: 0.9006\n",
      "Epoch 62/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3396 - f1: 0.9618 - val_loss: 0.4840 - val_f1: 0.9043\n",
      "Epoch 63/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.3342 - f1: 0.9652 - val_loss: 0.4744 - val_f1: 0.9104\n",
      "Epoch 64/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.3232 - f1: 0.9688 - val_loss: 0.4761 - val_f1: 0.9093\n",
      "Epoch 65/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.3224 - f1: 0.9687 - val_loss: 0.4715 - val_f1: 0.9041\n",
      "Epoch 66/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3193 - f1: 0.9630 - val_loss: 0.4581 - val_f1: 0.9126\n",
      "Epoch 67/2000\n",
      "5000/5000 [==============================] - 2s 307us/sample - loss: 0.3161 - f1: 0.9693 - val_loss: 0.4695 - val_f1: 0.9082\n",
      "Epoch 68/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.3061 - f1: 0.9682 - val_loss: 0.4497 - val_f1: 0.9110\n",
      "Epoch 69/2000\n",
      "5000/5000 [==============================] - 4s 740us/sample - loss: 0.3037 - f1: 0.9717 - val_loss: 0.4471 - val_f1: 0.9107\n",
      "Running through fold 3\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 4s 791us/sample - loss: 3.5725 - f1: 3.8603e-04 - val_loss: 3.1853 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 3.0019 - f1: 0.0327 - val_loss: 2.7861 - val_f1: 0.0788\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 2.6207 - f1: 0.0956 - val_loss: 2.4174 - val_f1: 0.1371\n",
      "Epoch 4/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 2s 310us/sample - loss: 2.2833 - f1: 0.1469 - val_loss: 2.1191 - val_f1: 0.1862\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 2.0252 - f1: 0.1946 - val_loss: 1.9063 - val_f1: 0.2353\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 1.8369 - f1: 0.2601 - val_loss: 1.7236 - val_f1: 0.3111\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 1.6799 - f1: 0.3292 - val_loss: 1.6028 - val_f1: 0.3809\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 1.5591 - f1: 0.3936 - val_loss: 1.4798 - val_f1: 0.4317\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 1.4613 - f1: 0.4481 - val_loss: 1.3973 - val_f1: 0.4914\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 1.3777 - f1: 0.5075 - val_loss: 1.3139 - val_f1: 0.5377\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 1.3067 - f1: 0.5511 - val_loss: 1.2635 - val_f1: 0.5876\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 1.2415 - f1: 0.5938 - val_loss: 1.1988 - val_f1: 0.6089\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 1.1916 - f1: 0.6200 - val_loss: 1.1646 - val_f1: 0.6481\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 1.1385 - f1: 0.6499 - val_loss: 1.1116 - val_f1: 0.6690\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 1.0925 - f1: 0.6738 - val_loss: 1.0623 - val_f1: 0.6971\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 1.0526 - f1: 0.6918 - val_loss: 1.0303 - val_f1: 0.7104\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 1.0167 - f1: 0.7179 - val_loss: 1.0005 - val_f1: 0.7202\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.9749 - f1: 0.7329 - val_loss: 0.9733 - val_f1: 0.7373\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.9452 - f1: 0.7519 - val_loss: 0.9416 - val_f1: 0.7385\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.9092 - f1: 0.7646 - val_loss: 0.9149 - val_f1: 0.7578\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.8764 - f1: 0.7758 - val_loss: 0.8948 - val_f1: 0.7685\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.8542 - f1: 0.7856 - val_loss: 0.8627 - val_f1: 0.7821\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.8251 - f1: 0.8013 - val_loss: 0.8441 - val_f1: 0.7848\n",
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.8011 - f1: 0.8114 - val_loss: 0.8264 - val_f1: 0.7938\n",
      "Epoch 25/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.7789 - f1: 0.8205 - val_loss: 0.8195 - val_f1: 0.7908\n",
      "Epoch 26/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.7593 - f1: 0.8285 - val_loss: 0.7873 - val_f1: 0.8103\n",
      "Epoch 27/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.7366 - f1: 0.8345 - val_loss: 0.7817 - val_f1: 0.8188\n",
      "Epoch 28/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.7179 - f1: 0.8449 - val_loss: 0.7567 - val_f1: 0.8264\n",
      "Epoch 29/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.7006 - f1: 0.8482 - val_loss: 0.7451 - val_f1: 0.8301\n",
      "Epoch 30/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.6823 - f1: 0.8546 - val_loss: 0.7157 - val_f1: 0.8418\n",
      "Epoch 31/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.6626 - f1: 0.8636 - val_loss: 0.7074 - val_f1: 0.8477\n",
      "Epoch 32/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.6500 - f1: 0.8681 - val_loss: 0.7045 - val_f1: 0.8434\n",
      "Epoch 33/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.6394 - f1: 0.8696 - val_loss: 0.6687 - val_f1: 0.8602\n",
      "Epoch 34/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.6191 - f1: 0.8790 - val_loss: 0.6783 - val_f1: 0.8545\n",
      "Epoch 35/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.6081 - f1: 0.8837 - val_loss: 0.6534 - val_f1: 0.8614\n",
      "Epoch 36/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.5918 - f1: 0.8862 - val_loss: 0.6485 - val_f1: 0.8685\n",
      "Epoch 37/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.5792 - f1: 0.8924 - val_loss: 0.6449 - val_f1: 0.8672\n",
      "Epoch 38/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.5698 - f1: 0.8931 - val_loss: 0.6326 - val_f1: 0.8683\n",
      "Epoch 39/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.5576 - f1: 0.8983 - val_loss: 0.6104 - val_f1: 0.8795\n",
      "Epoch 40/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.5486 - f1: 0.9023 - val_loss: 0.6150 - val_f1: 0.8766\n",
      "Epoch 41/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.5335 - f1: 0.9084 - val_loss: 0.5984 - val_f1: 0.8801\n",
      "Epoch 42/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.5239 - f1: 0.9109 - val_loss: 0.5925 - val_f1: 0.8786\n",
      "Epoch 43/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.5120 - f1: 0.9114 - val_loss: 0.5991 - val_f1: 0.8760\n",
      "Epoch 44/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.5010 - f1: 0.9181 - val_loss: 0.5722 - val_f1: 0.8869\n",
      "Epoch 45/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.4899 - f1: 0.9215 - val_loss: 0.5680 - val_f1: 0.8880\n",
      "Epoch 46/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.4858 - f1: 0.9197 - val_loss: 0.5709 - val_f1: 0.8877\n",
      "Epoch 47/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.4791 - f1: 0.9216 - val_loss: 0.5529 - val_f1: 0.8901\n",
      "Epoch 48/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.4711 - f1: 0.9237 - val_loss: 0.5499 - val_f1: 0.8919\n",
      "Epoch 49/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.4634 - f1: 0.9211 - val_loss: 0.5501 - val_f1: 0.8913\n",
      "Epoch 50/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.4647 - f1: 0.9237 - val_loss: 0.5505 - val_f1: 0.8897\n",
      "Epoch 51/2000\n",
      "5000/5000 [==============================] - 2s 308us/sample - loss: 0.4468 - f1: 0.9312 - val_loss: 0.5361 - val_f1: 0.8928\n",
      "Epoch 52/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.4386 - f1: 0.9326 - val_loss: 0.5292 - val_f1: 0.8945\n",
      "Epoch 53/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.4366 - f1: 0.9323 - val_loss: 0.5157 - val_f1: 0.8995\n",
      "Epoch 54/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.4260 - f1: 0.9349 - val_loss: 0.5263 - val_f1: 0.8935\n",
      "Epoch 55/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.4235 - f1: 0.9347 - val_loss: 0.5203 - val_f1: 0.8911\n",
      "Epoch 56/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.4137 - f1: 0.9402 - val_loss: 0.5048 - val_f1: 0.8984\n",
      "Epoch 57/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.4080 - f1: 0.9391 - val_loss: 0.5003 - val_f1: 0.9016\n",
      "Epoch 58/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.4011 - f1: 0.9425 - val_loss: 0.5058 - val_f1: 0.8961\n",
      "Epoch 59/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3898 - f1: 0.9443 - val_loss: 0.4915 - val_f1: 0.9005\n",
      "Epoch 60/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3883 - f1: 0.9420 - val_loss: 0.4884 - val_f1: 0.9030\n",
      "Epoch 61/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.3820 - f1: 0.9454 - val_loss: 0.4928 - val_f1: 0.9007\n",
      "Epoch 62/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3767 - f1: 0.9472 - val_loss: 0.4876 - val_f1: 0.9008\n",
      "Epoch 63/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3695 - f1: 0.9482 - val_loss: 0.4769 - val_f1: 0.9014\n",
      "Epoch 64/2000\n",
      "5000/5000 [==============================] - 2s 310us/sample - loss: 0.3694 - f1: 0.9479 - val_loss: 0.4762 - val_f1: 0.9038\n",
      "Epoch 65/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.3693 - f1: 0.9456 - val_loss: 0.4775 - val_f1: 0.9069\n",
      "Epoch 66/2000\n",
      "5000/5000 [==============================] - 2s 309us/sample - loss: 0.3593 - f1: 0.9521 - val_loss: 0.4648 - val_f1: 0.9061\n",
      "Epoch 67/2000\n",
      "5000/5000 [==============================] - 4s 771us/sample - loss: 0.3579 - f1: 0.9460 - val_loss: 0.4566 - val_f1: 0.9056\n",
      "Running through fold 4\n",
      "Train on 5000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "5000/5000 [==============================] - 4s 810us/sample - loss: 3.5899 - f1: 0.0000e+00 - val_loss: 3.2084 - val_f1: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 2.8813 - f1: 0.0473 - val_loss: 2.5536 - val_f1: 0.1277\n",
      "Epoch 3/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 2.3394 - f1: 0.1383 - val_loss: 2.1256 - val_f1: 0.1944\n",
      "Epoch 4/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 2.0120 - f1: 0.2274 - val_loss: 1.8617 - val_f1: 0.2765\n",
      "Epoch 5/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 1.7931 - f1: 0.3013 - val_loss: 1.7005 - val_f1: 0.3159\n",
      "Epoch 6/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 1.6386 - f1: 0.3633 - val_loss: 1.5534 - val_f1: 0.4061\n",
      "Epoch 7/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 1.5106 - f1: 0.4295 - val_loss: 1.4380 - val_f1: 0.4702\n",
      "Epoch 8/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 1.4103 - f1: 0.4887 - val_loss: 1.3463 - val_f1: 0.5314\n",
      "Epoch 9/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 1.3300 - f1: 0.5431 - val_loss: 1.2685 - val_f1: 0.5800\n",
      "Epoch 10/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 1.2481 - f1: 0.5885 - val_loss: 1.2090 - val_f1: 0.6102\n",
      "Epoch 11/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 1.1822 - f1: 0.6283 - val_loss: 1.1528 - val_f1: 0.6386\n",
      "Epoch 12/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 1.1260 - f1: 0.6542 - val_loss: 1.1051 - val_f1: 0.6853\n",
      "Epoch 13/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 1.0735 - f1: 0.6838 - val_loss: 1.0552 - val_f1: 0.6976\n",
      "Epoch 14/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 1.0272 - f1: 0.7173 - val_loss: 1.0273 - val_f1: 0.7145\n",
      "Epoch 15/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 0.9832 - f1: 0.7376 - val_loss: 0.9786 - val_f1: 0.7347\n",
      "Epoch 16/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.9494 - f1: 0.7563 - val_loss: 0.9466 - val_f1: 0.7493\n",
      "Epoch 17/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.9123 - f1: 0.7777 - val_loss: 0.9193 - val_f1: 0.7597\n",
      "Epoch 18/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.8851 - f1: 0.7839 - val_loss: 0.8953 - val_f1: 0.7722\n",
      "Epoch 19/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.8509 - f1: 0.7966 - val_loss: 0.8710 - val_f1: 0.7881\n",
      "Epoch 20/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.8273 - f1: 0.8088 - val_loss: 0.8440 - val_f1: 0.7927\n",
      "Epoch 21/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.8007 - f1: 0.8203 - val_loss: 0.8306 - val_f1: 0.8016\n",
      "Epoch 22/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.7755 - f1: 0.8228 - val_loss: 0.7993 - val_f1: 0.8103\n",
      "Epoch 23/2000\n",
      "5000/5000 [==============================] - 2s 315us/sample - loss: 0.7624 - f1: 0.8319 - val_loss: 0.7835 - val_f1: 0.8194\n",
      "Epoch 24/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.7364 - f1: 0.8400 - val_loss: 0.7801 - val_f1: 0.8140\n",
      "Epoch 25/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.7178 - f1: 0.8456 - val_loss: 0.7653 - val_f1: 0.8251\n",
      "Epoch 26/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.7023 - f1: 0.8521 - val_loss: 0.7391 - val_f1: 0.8346\n",
      "Epoch 27/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.6835 - f1: 0.8630 - val_loss: 0.7329 - val_f1: 0.8301\n",
      "Epoch 28/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.6647 - f1: 0.8662 - val_loss: 0.7142 - val_f1: 0.8424\n",
      "Epoch 29/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.6515 - f1: 0.8656 - val_loss: 0.7038 - val_f1: 0.8451\n",
      "Epoch 30/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.6410 - f1: 0.8756 - val_loss: 0.6924 - val_f1: 0.8523\n",
      "Epoch 31/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.6212 - f1: 0.8846 - val_loss: 0.6737 - val_f1: 0.8547\n",
      "Epoch 32/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.6068 - f1: 0.8884 - val_loss: 0.6767 - val_f1: 0.8519\n",
      "Epoch 33/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.5967 - f1: 0.8854 - val_loss: 0.6577 - val_f1: 0.8620\n",
      "Epoch 34/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 0.5891 - f1: 0.8900 - val_loss: 0.6596 - val_f1: 0.8590\n",
      "Epoch 35/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.5720 - f1: 0.8923 - val_loss: 0.6459 - val_f1: 0.8644\n",
      "Epoch 36/2000\n",
      "5000/5000 [==============================] - 2s 315us/sample - loss: 0.5595 - f1: 0.8990 - val_loss: 0.6438 - val_f1: 0.8652\n",
      "Epoch 37/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.5547 - f1: 0.9018 - val_loss: 0.6189 - val_f1: 0.8712\n",
      "Epoch 38/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.5417 - f1: 0.9052 - val_loss: 0.6229 - val_f1: 0.8681\n",
      "Epoch 39/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.5327 - f1: 0.9112 - val_loss: 0.6110 - val_f1: 0.8782\n",
      "Epoch 40/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 0.5207 - f1: 0.9103 - val_loss: 0.5969 - val_f1: 0.8786\n",
      "Epoch 41/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.5105 - f1: 0.9161 - val_loss: 0.6000 - val_f1: 0.8739\n",
      "Epoch 42/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 0.5042 - f1: 0.9146 - val_loss: 0.5863 - val_f1: 0.8813\n",
      "Epoch 43/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 0.4958 - f1: 0.9191 - val_loss: 0.5808 - val_f1: 0.8797\n",
      "Epoch 44/2000\n",
      "5000/5000 [==============================] - 2s 314us/sample - loss: 0.4873 - f1: 0.9208 - val_loss: 0.5688 - val_f1: 0.8871\n",
      "Epoch 45/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.4840 - f1: 0.9217 - val_loss: 0.5781 - val_f1: 0.8836\n",
      "Epoch 46/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.4742 - f1: 0.9232 - val_loss: 0.5611 - val_f1: 0.8839\n",
      "Epoch 47/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.4572 - f1: 0.9309 - val_loss: 0.5613 - val_f1: 0.8893\n",
      "Epoch 48/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.4553 - f1: 0.9309 - val_loss: 0.5461 - val_f1: 0.8902\n",
      "Epoch 49/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.4448 - f1: 0.9342 - val_loss: 0.5441 - val_f1: 0.8933\n",
      "Epoch 50/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.4402 - f1: 0.9347 - val_loss: 0.5329 - val_f1: 0.8941\n",
      "Epoch 51/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.4347 - f1: 0.9368 - val_loss: 0.5414 - val_f1: 0.8906\n",
      "Epoch 52/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.4288 - f1: 0.9379 - val_loss: 0.5532 - val_f1: 0.8784\n",
      "Epoch 53/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.4234 - f1: 0.9380 - val_loss: 0.5237 - val_f1: 0.8985\n",
      "Epoch 54/2000\n",
      "5000/5000 [==============================] - 2s 313us/sample - loss: 0.4173 - f1: 0.9419 - val_loss: 0.5256 - val_f1: 0.8976\n",
      "Epoch 55/2000\n",
      "5000/5000 [==============================] - 2s 312us/sample - loss: 0.4062 - f1: 0.9433 - val_loss: 0.5189 - val_f1: 0.8966\n",
      "Epoch 56/2000\n",
      "5000/5000 [==============================] - 2s 311us/sample - loss: 0.4041 - f1: 0.9417 - val_loss: 0.5204 - val_f1: 0.8980\n",
      "Epoch 57/2000\n",
      "5000/5000 [==============================] - 4s 830us/sample - loss: 0.3947 - f1: 0.9456 - val_loss: 0.5071 - val_f1: 0.8988\n",
      "\n",
      "\n",
      "Running through training size 15000\n",
      "Running through fold 0\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 454us/sample - loss: 2.8347 - f1: 0.0631 - val_loss: 1.9809 - val_f1: 0.1928\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 1.7056 - f1: 0.3359 - val_loss: 1.4467 - val_f1: 0.4561\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 272us/sample - loss: 1.3383 - f1: 0.5356 - val_loss: 1.1924 - val_f1: 0.6347\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 271us/sample - loss: 1.1403 - f1: 0.6606 - val_loss: 1.0627 - val_f1: 0.7085\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 271us/sample - loss: 0.9979 - f1: 0.7316 - val_loss: 0.9244 - val_f1: 0.7595\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 272us/sample - loss: 0.8943 - f1: 0.7753 - val_loss: 0.8330 - val_f1: 0.7953\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 271us/sample - loss: 0.8115 - f1: 0.8082 - val_loss: 0.7710 - val_f1: 0.8175\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 272us/sample - loss: 0.7418 - f1: 0.8334 - val_loss: 0.7092 - val_f1: 0.8426\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.6929 - f1: 0.8510 - val_loss: 0.6634 - val_f1: 0.8565\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 271us/sample - loss: 0.6425 - f1: 0.8657 - val_loss: 0.6286 - val_f1: 0.8789\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 271us/sample - loss: 0.6041 - f1: 0.8795 - val_loss: 0.5928 - val_f1: 0.8833\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 272us/sample - loss: 0.5685 - f1: 0.8888 - val_loss: 0.5570 - val_f1: 0.8913\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 271us/sample - loss: 0.5406 - f1: 0.8962 - val_loss: 0.5398 - val_f1: 0.8958\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 272us/sample - loss: 0.5150 - f1: 0.9058 - val_loss: 0.5213 - val_f1: 0.9017\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 271us/sample - loss: 0.4933 - f1: 0.9088 - val_loss: 0.5033 - val_f1: 0.9031\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 271us/sample - loss: 0.4715 - f1: 0.9149 - val_loss: 0.4761 - val_f1: 0.9116\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 271us/sample - loss: 0.4530 - f1: 0.9187 - val_loss: 0.4622 - val_f1: 0.9106\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 4s 271us/sample - loss: 0.4356 - f1: 0.9256 - val_loss: 0.4578 - val_f1: 0.9164\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 271us/sample - loss: 0.4199 - f1: 0.9289 - val_loss: 0.4312 - val_f1: 0.9204\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 4s 273us/sample - loss: 0.4033 - f1: 0.9336 - val_loss: 0.4187 - val_f1: 0.9225\n",
      "Epoch 21/2000\n",
      "15000/15000 [==============================] - 4s 273us/sample - loss: 0.3918 - f1: 0.9338 - val_loss: 0.4116 - val_f1: 0.9202\n",
      "Epoch 22/2000\n",
      "15000/15000 [==============================] - 4s 271us/sample - loss: 0.3800 - f1: 0.9373 - val_loss: 0.4240 - val_f1: 0.9210\n",
      "Epoch 23/2000\n",
      "15000/15000 [==============================] - 4s 272us/sample - loss: 0.3695 - f1: 0.9405 - val_loss: 0.3971 - val_f1: 0.9281\n",
      "Epoch 24/2000\n",
      "15000/15000 [==============================] - 4s 272us/sample - loss: 0.3569 - f1: 0.9432 - val_loss: 0.3874 - val_f1: 0.9260\n",
      "Epoch 25/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.3498 - f1: 0.9428 - val_loss: 0.3794 - val_f1: 0.9297\n",
      "Epoch 26/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.3375 - f1: 0.9475 - val_loss: 0.3735 - val_f1: 0.9341\n",
      "Epoch 27/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.3287 - f1: 0.9474 - val_loss: 0.3663 - val_f1: 0.9343\n",
      "Epoch 28/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.3232 - f1: 0.9484 - val_loss: 0.3524 - val_f1: 0.9351\n",
      "Epoch 29/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.3134 - f1: 0.9503 - val_loss: 0.3588 - val_f1: 0.9343\n",
      "Epoch 30/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.3045 - f1: 0.9538 - val_loss: 0.3596 - val_f1: 0.9321\n",
      "Epoch 31/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.2990 - f1: 0.9559 - val_loss: 0.3538 - val_f1: 0.9354\n",
      "Epoch 32/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.2949 - f1: 0.9563 - val_loss: 0.3401 - val_f1: 0.9355\n",
      "Epoch 33/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.2847 - f1: 0.9593 - val_loss: 0.3294 - val_f1: 0.9392\n",
      "Epoch 34/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.2795 - f1: 0.9592 - val_loss: 0.3271 - val_f1: 0.9415\n",
      "Epoch 35/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.2742 - f1: 0.9602 - val_loss: 0.3263 - val_f1: 0.9350\n",
      "Epoch 36/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.2673 - f1: 0.9626 - val_loss: 0.3218 - val_f1: 0.9359\n",
      "Epoch 37/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.2638 - f1: 0.9622 - val_loss: 0.3097 - val_f1: 0.9426\n",
      "Epoch 38/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.2571 - f1: 0.9651 - val_loss: 0.3171 - val_f1: 0.9372\n",
      "Epoch 39/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.2536 - f1: 0.9647 - val_loss: 0.3133 - val_f1: 0.9446\n",
      "Epoch 40/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.2477 - f1: 0.9662 - val_loss: 0.3073 - val_f1: 0.9415\n",
      "Epoch 41/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.2415 - f1: 0.9681 - val_loss: 0.3119 - val_f1: 0.9355\n",
      "Epoch 42/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.2387 - f1: 0.9688 - val_loss: 0.2982 - val_f1: 0.9409\n",
      "Epoch 43/2000\n",
      "15000/15000 [==============================] - 7s 453us/sample - loss: 0.2356 - f1: 0.9699 - val_loss: 0.3031 - val_f1: 0.9460\n",
      "Running through fold 1\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 464us/sample - loss: 2.9596 - f1: 0.0595 - val_loss: 2.2180 - val_f1: 0.1646\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 1.8922 - f1: 0.2608 - val_loss: 1.6225 - val_f1: 0.3622\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 1.4779 - f1: 0.4491 - val_loss: 1.3345 - val_f1: 0.5493\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 279us/sample - loss: 1.2575 - f1: 0.5868 - val_loss: 1.1635 - val_f1: 0.6656\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 279us/sample - loss: 1.1011 - f1: 0.6825 - val_loss: 1.0247 - val_f1: 0.7175\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.9866 - f1: 0.7383 - val_loss: 0.9269 - val_f1: 0.7653\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.9006 - f1: 0.7757 - val_loss: 0.8644 - val_f1: 0.7889\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.8306 - f1: 0.8036 - val_loss: 0.8131 - val_f1: 0.8080\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 279us/sample - loss: 0.7738 - f1: 0.8252 - val_loss: 0.7575 - val_f1: 0.8267\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.7257 - f1: 0.8399 - val_loss: 0.7035 - val_f1: 0.8481\n",
      "Epoch 11/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 4s 279us/sample - loss: 0.6863 - f1: 0.8540 - val_loss: 0.6794 - val_f1: 0.8493\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 279us/sample - loss: 0.6550 - f1: 0.8631 - val_loss: 0.6387 - val_f1: 0.8675\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.6211 - f1: 0.8723 - val_loss: 0.6227 - val_f1: 0.8692\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 279us/sample - loss: 0.5917 - f1: 0.8811 - val_loss: 0.5966 - val_f1: 0.8778\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.5679 - f1: 0.8869 - val_loss: 0.5737 - val_f1: 0.8828\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 279us/sample - loss: 0.5441 - f1: 0.8925 - val_loss: 0.5455 - val_f1: 0.8952\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.5257 - f1: 0.8996 - val_loss: 0.5328 - val_f1: 0.8957\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.5042 - f1: 0.9048 - val_loss: 0.5226 - val_f1: 0.8949\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.4872 - f1: 0.9070 - val_loss: 0.5066 - val_f1: 0.8983\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.4674 - f1: 0.9134 - val_loss: 0.4899 - val_f1: 0.9039\n",
      "Epoch 21/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.4533 - f1: 0.9180 - val_loss: 0.4790 - val_f1: 0.9030\n",
      "Epoch 22/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.4387 - f1: 0.9195 - val_loss: 0.4739 - val_f1: 0.9025\n",
      "Epoch 23/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.4280 - f1: 0.9218 - val_loss: 0.4538 - val_f1: 0.9085\n",
      "Epoch 24/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.4128 - f1: 0.9261 - val_loss: 0.4529 - val_f1: 0.9091\n",
      "Epoch 25/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.4047 - f1: 0.9278 - val_loss: 0.4422 - val_f1: 0.9124\n",
      "Epoch 26/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.3924 - f1: 0.9291 - val_loss: 0.4457 - val_f1: 0.9067\n",
      "Epoch 27/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.3822 - f1: 0.9326 - val_loss: 0.4180 - val_f1: 0.9150\n",
      "Epoch 28/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.3709 - f1: 0.9357 - val_loss: 0.4189 - val_f1: 0.9154\n",
      "Epoch 29/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.3629 - f1: 0.9355 - val_loss: 0.4523 - val_f1: 0.9032\n",
      "Epoch 30/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.3566 - f1: 0.9381 - val_loss: 0.4057 - val_f1: 0.9179\n",
      "Epoch 31/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.3472 - f1: 0.9403 - val_loss: 0.4003 - val_f1: 0.9223\n",
      "Epoch 32/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.3378 - f1: 0.9425 - val_loss: 0.3867 - val_f1: 0.9188\n",
      "Epoch 33/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.3325 - f1: 0.9422 - val_loss: 0.3837 - val_f1: 0.9225\n",
      "Epoch 34/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.3257 - f1: 0.9424 - val_loss: 0.3724 - val_f1: 0.9261\n",
      "Epoch 35/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.3185 - f1: 0.9451 - val_loss: 0.3705 - val_f1: 0.9235\n",
      "Epoch 36/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.3141 - f1: 0.9454 - val_loss: 0.3797 - val_f1: 0.9193\n",
      "Epoch 37/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.3072 - f1: 0.9470 - val_loss: 0.3624 - val_f1: 0.9259\n",
      "Epoch 38/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.3004 - f1: 0.9485 - val_loss: 0.3565 - val_f1: 0.9236\n",
      "Epoch 39/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.2913 - f1: 0.9525 - val_loss: 0.3547 - val_f1: 0.9248\n",
      "Epoch 40/2000\n",
      "15000/15000 [==============================] - 4s 275us/sample - loss: 0.2905 - f1: 0.9500 - val_loss: 0.3491 - val_f1: 0.9235\n",
      "Epoch 41/2000\n",
      "15000/15000 [==============================] - 7s 458us/sample - loss: 0.2865 - f1: 0.9526 - val_loss: 0.3530 - val_f1: 0.9256\n",
      "Running through fold 2\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 483us/sample - loss: 3.0062 - f1: 0.0608 - val_loss: 2.2665 - val_f1: 0.1719\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 1.9448 - f1: 0.2562 - val_loss: 1.6499 - val_f1: 0.3578\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 1.5133 - f1: 0.4403 - val_loss: 1.3515 - val_f1: 0.5458\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 1.2683 - f1: 0.5868 - val_loss: 1.1554 - val_f1: 0.6489\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 1.1015 - f1: 0.6781 - val_loss: 1.0163 - val_f1: 0.7159\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.9765 - f1: 0.7405 - val_loss: 0.9116 - val_f1: 0.7615\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.8843 - f1: 0.7805 - val_loss: 0.8326 - val_f1: 0.7907\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.8088 - f1: 0.8108 - val_loss: 0.7674 - val_f1: 0.8193\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.7467 - f1: 0.8331 - val_loss: 0.7171 - val_f1: 0.8358\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.7011 - f1: 0.8445 - val_loss: 0.6722 - val_f1: 0.8542\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 288us/sample - loss: 0.6606 - f1: 0.8600 - val_loss: 0.6440 - val_f1: 0.8596\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 283us/sample - loss: 0.6280 - f1: 0.8690 - val_loss: 0.6194 - val_f1: 0.8792\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.5941 - f1: 0.8803 - val_loss: 0.5953 - val_f1: 0.8815\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.5670 - f1: 0.8878 - val_loss: 0.5547 - val_f1: 0.8920\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.5415 - f1: 0.8961 - val_loss: 0.5389 - val_f1: 0.8948\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.5212 - f1: 0.9006 - val_loss: 0.5219 - val_f1: 0.9002\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.5010 - f1: 0.9073 - val_loss: 0.4973 - val_f1: 0.9084\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.4853 - f1: 0.9098 - val_loss: 0.4973 - val_f1: 0.9077\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.4670 - f1: 0.9140 - val_loss: 0.4948 - val_f1: 0.9101\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.4465 - f1: 0.9213 - val_loss: 0.4620 - val_f1: 0.9130\n",
      "Epoch 21/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.4366 - f1: 0.9223 - val_loss: 0.4646 - val_f1: 0.9147\n",
      "Epoch 22/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.4228 - f1: 0.9251 - val_loss: 0.4500 - val_f1: 0.9157\n",
      "Epoch 23/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.4134 - f1: 0.9273 - val_loss: 0.4388 - val_f1: 0.9229\n",
      "Epoch 24/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.3973 - f1: 0.9304 - val_loss: 0.4357 - val_f1: 0.9185\n",
      "Epoch 25/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.3888 - f1: 0.9352 - val_loss: 0.4154 - val_f1: 0.9223\n",
      "Epoch 26/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.3767 - f1: 0.9373 - val_loss: 0.4164 - val_f1: 0.9200\n",
      "Epoch 27/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.3664 - f1: 0.9390 - val_loss: 0.3997 - val_f1: 0.9288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.3590 - f1: 0.9388 - val_loss: 0.3935 - val_f1: 0.9284\n",
      "Epoch 29/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.3490 - f1: 0.9422 - val_loss: 0.3858 - val_f1: 0.9279\n",
      "Epoch 30/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.3454 - f1: 0.9433 - val_loss: 0.3880 - val_f1: 0.9244\n",
      "Epoch 31/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.3356 - f1: 0.9440 - val_loss: 0.3695 - val_f1: 0.9361\n",
      "Epoch 32/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.3288 - f1: 0.9475 - val_loss: 0.3742 - val_f1: 0.9301\n",
      "Epoch 33/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.3226 - f1: 0.9469 - val_loss: 0.3632 - val_f1: 0.9341\n",
      "Epoch 34/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.3142 - f1: 0.9491 - val_loss: 0.3589 - val_f1: 0.9304\n",
      "Epoch 35/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.3082 - f1: 0.9515 - val_loss: 0.3585 - val_f1: 0.9331\n",
      "Epoch 36/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.3015 - f1: 0.9524 - val_loss: 0.3504 - val_f1: 0.9350\n",
      "Epoch 37/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.2960 - f1: 0.9533 - val_loss: 0.3354 - val_f1: 0.9366\n",
      "Epoch 38/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.2933 - f1: 0.9529 - val_loss: 0.3407 - val_f1: 0.9342\n",
      "Epoch 39/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.2878 - f1: 0.9545 - val_loss: 0.3306 - val_f1: 0.9404\n",
      "Epoch 40/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.2837 - f1: 0.9548 - val_loss: 0.3285 - val_f1: 0.9399\n",
      "Epoch 41/2000\n",
      "15000/15000 [==============================] - 7s 493us/sample - loss: 0.2788 - f1: 0.9560 - val_loss: 0.3403 - val_f1: 0.9379\n",
      "Running through fold 3\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 483us/sample - loss: 2.9830 - f1: 0.0517 - val_loss: 2.1934 - val_f1: 0.1613\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 1.8742 - f1: 0.2735 - val_loss: 1.6027 - val_f1: 0.3876\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 1.4727 - f1: 0.4697 - val_loss: 1.3189 - val_f1: 0.5758\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 1.2545 - f1: 0.5955 - val_loss: 1.1506 - val_f1: 0.6611\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 1.1033 - f1: 0.6758 - val_loss: 1.0405 - val_f1: 0.7131\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.9878 - f1: 0.7305 - val_loss: 0.9328 - val_f1: 0.7493\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.9013 - f1: 0.7697 - val_loss: 0.8616 - val_f1: 0.7926\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 288us/sample - loss: 0.8291 - f1: 0.8002 - val_loss: 0.7944 - val_f1: 0.8108\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 280us/sample - loss: 0.7641 - f1: 0.8232 - val_loss: 0.7477 - val_f1: 0.8324\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 283us/sample - loss: 0.7141 - f1: 0.8434 - val_loss: 0.6939 - val_f1: 0.8503\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.6708 - f1: 0.8565 - val_loss: 0.6528 - val_f1: 0.8634\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.6321 - f1: 0.8694 - val_loss: 0.6313 - val_f1: 0.8684\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.5980 - f1: 0.8831 - val_loss: 0.6166 - val_f1: 0.8733\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.5675 - f1: 0.8901 - val_loss: 0.5792 - val_f1: 0.8824\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.5430 - f1: 0.8975 - val_loss: 0.5535 - val_f1: 0.8912\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.5175 - f1: 0.9031 - val_loss: 0.5287 - val_f1: 0.9019\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.4979 - f1: 0.9083 - val_loss: 0.5050 - val_f1: 0.9046\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.4772 - f1: 0.9150 - val_loss: 0.5081 - val_f1: 0.9034\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.4590 - f1: 0.9175 - val_loss: 0.4789 - val_f1: 0.9121\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.4446 - f1: 0.9227 - val_loss: 0.4767 - val_f1: 0.9088\n",
      "Epoch 21/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.4258 - f1: 0.9260 - val_loss: 0.4571 - val_f1: 0.9146\n",
      "Epoch 22/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.4167 - f1: 0.9258 - val_loss: 0.4396 - val_f1: 0.9199\n",
      "Epoch 23/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.4001 - f1: 0.9333 - val_loss: 0.4439 - val_f1: 0.9163\n",
      "Epoch 24/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.3906 - f1: 0.9340 - val_loss: 0.4258 - val_f1: 0.9227\n",
      "Epoch 25/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.3768 - f1: 0.9378 - val_loss: 0.4199 - val_f1: 0.9183\n",
      "Epoch 26/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.3707 - f1: 0.9389 - val_loss: 0.4060 - val_f1: 0.9243\n",
      "Epoch 27/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.3601 - f1: 0.9399 - val_loss: 0.4004 - val_f1: 0.9255\n",
      "Epoch 28/2000\n",
      "15000/15000 [==============================] - 4s 279us/sample - loss: 0.3468 - f1: 0.9454 - val_loss: 0.3892 - val_f1: 0.9257\n",
      "Epoch 29/2000\n",
      "15000/15000 [==============================] - 4s 284us/sample - loss: 0.3400 - f1: 0.9460 - val_loss: 0.3908 - val_f1: 0.9243\n",
      "Epoch 30/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.3314 - f1: 0.9466 - val_loss: 0.3799 - val_f1: 0.9316\n",
      "Epoch 31/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.3230 - f1: 0.9492 - val_loss: 0.3697 - val_f1: 0.9294\n",
      "Epoch 32/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.3175 - f1: 0.9496 - val_loss: 0.3700 - val_f1: 0.9294\n",
      "Epoch 33/2000\n",
      "15000/15000 [==============================] - 4s 283us/sample - loss: 0.3119 - f1: 0.9512 - val_loss: 0.3529 - val_f1: 0.9355\n",
      "Epoch 34/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.2981 - f1: 0.9546 - val_loss: 0.3583 - val_f1: 0.9321\n",
      "Epoch 35/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.2977 - f1: 0.9526 - val_loss: 0.3750 - val_f1: 0.9252\n",
      "Epoch 36/2000\n",
      "15000/15000 [==============================] - 4s 283us/sample - loss: 0.2913 - f1: 0.9555 - val_loss: 0.3395 - val_f1: 0.9395\n",
      "Epoch 37/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.2846 - f1: 0.9573 - val_loss: 0.3335 - val_f1: 0.9388\n",
      "Epoch 38/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.2809 - f1: 0.9582 - val_loss: 0.3386 - val_f1: 0.9320\n",
      "Epoch 39/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.2732 - f1: 0.9605 - val_loss: 0.3389 - val_f1: 0.9339\n",
      "Epoch 40/2000\n",
      "15000/15000 [==============================] - 4s 282us/sample - loss: 0.2691 - f1: 0.9603 - val_loss: 0.3192 - val_f1: 0.9368\n",
      "Epoch 41/2000\n",
      "15000/15000 [==============================] - 4s 283us/sample - loss: 0.2614 - f1: 0.9634 - val_loss: 0.3297 - val_f1: 0.9403\n",
      "Epoch 42/2000\n",
      "15000/15000 [==============================] - 4s 279us/sample - loss: 0.2545 - f1: 0.9655 - val_loss: 0.3200 - val_f1: 0.9370\n",
      "Epoch 43/2000\n",
      "15000/15000 [==============================] - 4s 278us/sample - loss: 0.2518 - f1: 0.9664 - val_loss: 0.3183 - val_f1: 0.9457\n",
      "Epoch 44/2000\n",
      "15000/15000 [==============================] - 4s 278us/sample - loss: 0.2473 - f1: 0.9664 - val_loss: 0.3172 - val_f1: 0.9387\n",
      "Epoch 45/2000\n",
      "15000/15000 [==============================] - 4s 277us/sample - loss: 0.2437 - f1: 0.9684 - val_loss: 0.3190 - val_f1: 0.9443\n",
      "Epoch 46/2000\n",
      "15000/15000 [==============================] - 4s 277us/sample - loss: 0.2404 - f1: 0.9690 - val_loss: 0.3090 - val_f1: 0.9410\n",
      "Epoch 47/2000\n",
      "15000/15000 [==============================] - 4s 277us/sample - loss: 0.2330 - f1: 0.9713 - val_loss: 0.2980 - val_f1: 0.9497\n",
      "Epoch 48/2000\n",
      "15000/15000 [==============================] - 4s 276us/sample - loss: 0.2304 - f1: 0.9722 - val_loss: 0.2944 - val_f1: 0.9480\n",
      "Epoch 49/2000\n",
      "15000/15000 [==============================] - 4s 278us/sample - loss: 0.2272 - f1: 0.9717 - val_loss: 0.2890 - val_f1: 0.9514\n",
      "Epoch 50/2000\n",
      "15000/15000 [==============================] - 4s 281us/sample - loss: 0.2226 - f1: 0.9735 - val_loss: 0.2906 - val_f1: 0.9483\n",
      "Epoch 51/2000\n",
      "15000/15000 [==============================] - 4s 277us/sample - loss: 0.2209 - f1: 0.9739 - val_loss: 0.2878 - val_f1: 0.9504\n",
      "Epoch 52/2000\n",
      "15000/15000 [==============================] - 4s 279us/sample - loss: 0.2122 - f1: 0.9756 - val_loss: 0.2737 - val_f1: 0.9519\n",
      "Epoch 53/2000\n",
      "15000/15000 [==============================] - 7s 489us/sample - loss: 0.2102 - f1: 0.9774 - val_loss: 0.2794 - val_f1: 0.9501\n",
      "Running through fold 4\n",
      "Train on 15000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 7s 492us/sample - loss: 3.0989 - f1: 0.0386 - val_loss: 2.4561 - val_f1: 0.1010\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 2.0888 - f1: 0.1998 - val_loss: 1.7789 - val_f1: 0.3106\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 1.6093 - f1: 0.3854 - val_loss: 1.4391 - val_f1: 0.4659\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 1.3348 - f1: 0.5341 - val_loss: 1.2242 - val_f1: 0.6065\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 1.1484 - f1: 0.6494 - val_loss: 1.0575 - val_f1: 0.7043\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 1.0087 - f1: 0.7286 - val_loss: 0.9496 - val_f1: 0.7479\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.9043 - f1: 0.7738 - val_loss: 0.8644 - val_f1: 0.7820\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.8240 - f1: 0.8054 - val_loss: 0.7923 - val_f1: 0.8183\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.7591 - f1: 0.8289 - val_loss: 0.7347 - val_f1: 0.8360\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.7108 - f1: 0.8470 - val_loss: 0.6974 - val_f1: 0.8439\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.6689 - f1: 0.8581 - val_loss: 0.6517 - val_f1: 0.8646\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 4s 292us/sample - loss: 0.6266 - f1: 0.8723 - val_loss: 0.6205 - val_f1: 0.8721\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 4s 285us/sample - loss: 0.5980 - f1: 0.8805 - val_loss: 0.5891 - val_f1: 0.8818\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.5696 - f1: 0.8881 - val_loss: 0.5853 - val_f1: 0.8788\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 4s 290us/sample - loss: 0.5385 - f1: 0.8986 - val_loss: 0.5444 - val_f1: 0.8948\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.5175 - f1: 0.9023 - val_loss: 0.5281 - val_f1: 0.8981\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.4966 - f1: 0.9097 - val_loss: 0.5103 - val_f1: 0.8994\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.4773 - f1: 0.9148 - val_loss: 0.4988 - val_f1: 0.9047\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.4588 - f1: 0.9177 - val_loss: 0.4795 - val_f1: 0.9053\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.4414 - f1: 0.9227 - val_loss: 0.4470 - val_f1: 0.9180\n",
      "Epoch 21/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.4257 - f1: 0.9266 - val_loss: 0.4672 - val_f1: 0.9077\n",
      "Epoch 22/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.4124 - f1: 0.9288 - val_loss: 0.4385 - val_f1: 0.9144\n",
      "Epoch 23/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.4012 - f1: 0.9324 - val_loss: 0.4171 - val_f1: 0.9249\n",
      "Epoch 24/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.3871 - f1: 0.9374 - val_loss: 0.4206 - val_f1: 0.9203\n",
      "Epoch 25/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.3765 - f1: 0.9368 - val_loss: 0.4005 - val_f1: 0.9259\n",
      "Epoch 26/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.3627 - f1: 0.9434 - val_loss: 0.3973 - val_f1: 0.9276\n",
      "Epoch 27/2000\n",
      "15000/15000 [==============================] - 4s 288us/sample - loss: 0.3534 - f1: 0.9451 - val_loss: 0.3952 - val_f1: 0.9270\n",
      "Epoch 28/2000\n",
      "15000/15000 [==============================] - 4s 289us/sample - loss: 0.3469 - f1: 0.9453 - val_loss: 0.3718 - val_f1: 0.9361\n",
      "Epoch 29/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.3362 - f1: 0.9474 - val_loss: 0.3813 - val_f1: 0.9291\n",
      "Epoch 30/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.3274 - f1: 0.9501 - val_loss: 0.3539 - val_f1: 0.9388\n",
      "Epoch 31/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.3171 - f1: 0.9534 - val_loss: 0.3600 - val_f1: 0.9338\n",
      "Epoch 32/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.3070 - f1: 0.9557 - val_loss: 0.3478 - val_f1: 0.9423\n",
      "Epoch 33/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.3015 - f1: 0.9578 - val_loss: 0.3459 - val_f1: 0.9374\n",
      "Epoch 34/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.2923 - f1: 0.9599 - val_loss: 0.3322 - val_f1: 0.9454\n",
      "Epoch 35/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.2896 - f1: 0.9605 - val_loss: 0.3264 - val_f1: 0.9434\n",
      "Epoch 36/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.2802 - f1: 0.9626 - val_loss: 0.3335 - val_f1: 0.9450\n",
      "Epoch 37/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.2754 - f1: 0.9640 - val_loss: 0.3208 - val_f1: 0.9484\n",
      "Epoch 38/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.2666 - f1: 0.9668 - val_loss: 0.3082 - val_f1: 0.9515\n",
      "Epoch 39/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.2573 - f1: 0.9691 - val_loss: 0.3022 - val_f1: 0.9538\n",
      "Epoch 40/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.2503 - f1: 0.9719 - val_loss: 0.3028 - val_f1: 0.9528\n",
      "Epoch 41/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.2502 - f1: 0.9694 - val_loss: 0.3022 - val_f1: 0.9509\n",
      "Epoch 42/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.2386 - f1: 0.9740 - val_loss: 0.2864 - val_f1: 0.9589\n",
      "Epoch 43/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.2343 - f1: 0.9748 - val_loss: 0.2921 - val_f1: 0.9587\n",
      "Epoch 44/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.2299 - f1: 0.9752 - val_loss: 0.2833 - val_f1: 0.9570\n",
      "Epoch 45/2000\n",
      "15000/15000 [==============================] - 4s 291us/sample - loss: 0.2240 - f1: 0.9770 - val_loss: 0.2860 - val_f1: 0.9562\n",
      "Epoch 46/2000\n",
      "15000/15000 [==============================] - 4s 288us/sample - loss: 0.2208 - f1: 0.9775 - val_loss: 0.2720 - val_f1: 0.9612\n",
      "Epoch 47/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.2128 - f1: 0.9803 - val_loss: 0.2794 - val_f1: 0.9572\n",
      "Epoch 48/2000\n",
      "15000/15000 [==============================] - 4s 287us/sample - loss: 0.2091 - f1: 0.9798 - val_loss: 0.2722 - val_f1: 0.9552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.2046 - f1: 0.9808 - val_loss: 0.2597 - val_f1: 0.9626\n",
      "Epoch 50/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.2050 - f1: 0.9792 - val_loss: 0.2534 - val_f1: 0.9616\n",
      "Epoch 51/2000\n",
      "15000/15000 [==============================] - 4s 286us/sample - loss: 0.2018 - f1: 0.9810 - val_loss: 0.2706 - val_f1: 0.9576\n",
      "Epoch 52/2000\n",
      "15000/15000 [==============================] - 7s 497us/sample - loss: 0.1947 - f1: 0.9824 - val_loss: 0.2552 - val_f1: 0.9615\n",
      "\n",
      "\n",
      "Running through training size 20000\n",
      "Running through fold 0\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 9s 444us/sample - loss: 2.7135 - f1: 0.0929 - val_loss: 1.8689 - val_f1: 0.2483\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 285us/sample - loss: 1.5650 - f1: 0.4164 - val_loss: 1.3159 - val_f1: 0.5753\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 283us/sample - loss: 1.2029 - f1: 0.6310 - val_loss: 1.0784 - val_f1: 0.6870\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 285us/sample - loss: 1.0068 - f1: 0.7279 - val_loss: 0.9372 - val_f1: 0.7598\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 283us/sample - loss: 0.8797 - f1: 0.7792 - val_loss: 0.8271 - val_f1: 0.8047\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 283us/sample - loss: 0.7855 - f1: 0.8171 - val_loss: 0.7463 - val_f1: 0.8321\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.7135 - f1: 0.8421 - val_loss: 0.7006 - val_f1: 0.8536\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 281us/sample - loss: 0.6575 - f1: 0.8606 - val_loss: 0.6474 - val_f1: 0.8634\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.6077 - f1: 0.8788 - val_loss: 0.6110 - val_f1: 0.8739\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.5709 - f1: 0.8887 - val_loss: 0.5662 - val_f1: 0.8907\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.5335 - f1: 0.9005 - val_loss: 0.5347 - val_f1: 0.8988\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.5069 - f1: 0.9059 - val_loss: 0.5177 - val_f1: 0.8991\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 281us/sample - loss: 0.4810 - f1: 0.9120 - val_loss: 0.5245 - val_f1: 0.8949\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.4589 - f1: 0.9167 - val_loss: 0.4763 - val_f1: 0.9099\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 283us/sample - loss: 0.4384 - f1: 0.9225 - val_loss: 0.4591 - val_f1: 0.9149\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 285us/sample - loss: 0.4165 - f1: 0.9287 - val_loss: 0.4605 - val_f1: 0.9102\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.4018 - f1: 0.9304 - val_loss: 0.4319 - val_f1: 0.9209\n",
      "Epoch 18/2000\n",
      "20000/20000 [==============================] - 6s 285us/sample - loss: 0.3877 - f1: 0.9326 - val_loss: 0.4218 - val_f1: 0.9216\n",
      "Epoch 19/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.3740 - f1: 0.9355 - val_loss: 0.4134 - val_f1: 0.9215\n",
      "Epoch 20/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.3614 - f1: 0.9385 - val_loss: 0.4054 - val_f1: 0.9229\n",
      "Epoch 21/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.3505 - f1: 0.9416 - val_loss: 0.3954 - val_f1: 0.9252\n",
      "Epoch 22/2000\n",
      "20000/20000 [==============================] - 6s 281us/sample - loss: 0.3388 - f1: 0.9440 - val_loss: 0.3784 - val_f1: 0.9286\n",
      "Epoch 23/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.3308 - f1: 0.9457 - val_loss: 0.3670 - val_f1: 0.9324\n",
      "Epoch 24/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.3186 - f1: 0.9481 - val_loss: 0.3632 - val_f1: 0.9320\n",
      "Epoch 25/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.3098 - f1: 0.9506 - val_loss: 0.3714 - val_f1: 0.9296\n",
      "Epoch 26/2000\n",
      "20000/20000 [==============================] - 6s 282us/sample - loss: 0.3055 - f1: 0.9505 - val_loss: 0.3587 - val_f1: 0.9315\n",
      "Epoch 27/2000\n",
      "20000/20000 [==============================] - 6s 283us/sample - loss: 0.2949 - f1: 0.9537 - val_loss: 0.3580 - val_f1: 0.9315\n",
      "Epoch 28/2000\n",
      "20000/20000 [==============================] - 6s 289us/sample - loss: 0.2891 - f1: 0.9538 - val_loss: 0.3477 - val_f1: 0.9332\n",
      "Epoch 29/2000\n",
      "20000/20000 [==============================] - 6s 283us/sample - loss: 0.2811 - f1: 0.9556 - val_loss: 0.3499 - val_f1: 0.9280\n",
      "Epoch 30/2000\n",
      "20000/20000 [==============================] - 6s 285us/sample - loss: 0.2750 - f1: 0.9560 - val_loss: 0.3471 - val_f1: 0.9344\n",
      "Epoch 31/2000\n",
      "20000/20000 [==============================] - 6s 285us/sample - loss: 0.2705 - f1: 0.9569 - val_loss: 0.3423 - val_f1: 0.9340\n",
      "Epoch 32/2000\n",
      "20000/20000 [==============================] - 6s 287us/sample - loss: 0.2616 - f1: 0.9605 - val_loss: 0.3256 - val_f1: 0.9392\n",
      "Epoch 33/2000\n",
      "20000/20000 [==============================] - 9s 454us/sample - loss: 0.2556 - f1: 0.9617 - val_loss: 0.3263 - val_f1: 0.9373\n",
      "Running through fold 1\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 9s 472us/sample - loss: 2.6026 - f1: 0.1063 - val_loss: 1.7538 - val_f1: 0.3094\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 1.4777 - f1: 0.4607 - val_loss: 1.2312 - val_f1: 0.6014\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 1.1268 - f1: 0.6695 - val_loss: 1.0035 - val_f1: 0.7253\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.9359 - f1: 0.7629 - val_loss: 0.8628 - val_f1: 0.7890\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.8118 - f1: 0.8123 - val_loss: 0.7629 - val_f1: 0.8292\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 300us/sample - loss: 0.7234 - f1: 0.8448 - val_loss: 0.6977 - val_f1: 0.8546\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 306us/sample - loss: 0.6584 - f1: 0.8640 - val_loss: 0.6395 - val_f1: 0.8694\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.6067 - f1: 0.8815 - val_loss: 0.6138 - val_f1: 0.8826\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 295us/sample - loss: 0.5655 - f1: 0.8937 - val_loss: 0.5561 - val_f1: 0.8956\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 294us/sample - loss: 0.5294 - f1: 0.9033 - val_loss: 0.5381 - val_f1: 0.8962\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 293us/sample - loss: 0.5010 - f1: 0.9104 - val_loss: 0.5051 - val_f1: 0.9045\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 293us/sample - loss: 0.4745 - f1: 0.9148 - val_loss: 0.4835 - val_f1: 0.9081\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 293us/sample - loss: 0.4525 - f1: 0.9200 - val_loss: 0.4605 - val_f1: 0.9144\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 294us/sample - loss: 0.4296 - f1: 0.9259 - val_loss: 0.4456 - val_f1: 0.9204\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 294us/sample - loss: 0.4146 - f1: 0.9267 - val_loss: 0.4487 - val_f1: 0.9117\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 292us/sample - loss: 0.3976 - f1: 0.9325 - val_loss: 0.4292 - val_f1: 0.9193\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 6s 293us/sample - loss: 0.3833 - f1: 0.9332 - val_loss: 0.4215 - val_f1: 0.9197\n",
      "Epoch 18/2000\n",
      "20000/20000 [==============================] - 6s 292us/sample - loss: 0.3699 - f1: 0.9361 - val_loss: 0.3951 - val_f1: 0.9219\n",
      "Epoch 19/2000\n",
      "20000/20000 [==============================] - 6s 293us/sample - loss: 0.3584 - f1: 0.9396 - val_loss: 0.3908 - val_f1: 0.9227\n",
      "Epoch 20/2000\n",
      "20000/20000 [==============================] - 6s 293us/sample - loss: 0.3463 - f1: 0.9419 - val_loss: 0.3785 - val_f1: 0.9253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/2000\n",
      "20000/20000 [==============================] - 6s 292us/sample - loss: 0.3354 - f1: 0.9433 - val_loss: 0.3795 - val_f1: 0.9238\n",
      "Epoch 22/2000\n",
      "20000/20000 [==============================] - 6s 293us/sample - loss: 0.3256 - f1: 0.9454 - val_loss: 0.3875 - val_f1: 0.9174\n",
      "Epoch 23/2000\n",
      "20000/20000 [==============================] - 6s 293us/sample - loss: 0.3180 - f1: 0.9468 - val_loss: 0.3676 - val_f1: 0.9246\n",
      "Epoch 24/2000\n",
      "20000/20000 [==============================] - 9s 473us/sample - loss: 0.3088 - f1: 0.9478 - val_loss: 0.3551 - val_f1: 0.9277\n",
      "Running through fold 2\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 10s 476us/sample - loss: 2.7329 - f1: 0.0757 - val_loss: 1.8817 - val_f1: 0.2458\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 1.6454 - f1: 0.3520 - val_loss: 1.3844 - val_f1: 0.5140\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 295us/sample - loss: 1.2924 - f1: 0.5664 - val_loss: 1.1356 - val_f1: 0.6574\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 1.0904 - f1: 0.6824 - val_loss: 0.9821 - val_f1: 0.7298\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 295us/sample - loss: 0.9466 - f1: 0.7503 - val_loss: 0.8686 - val_f1: 0.7744\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.8437 - f1: 0.7917 - val_loss: 0.7730 - val_f1: 0.8161\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.7662 - f1: 0.8223 - val_loss: 0.7174 - val_f1: 0.8375\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.6991 - f1: 0.8447 - val_loss: 0.6785 - val_f1: 0.8454\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.6475 - f1: 0.8608 - val_loss: 0.6244 - val_f1: 0.8710\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.6021 - f1: 0.8775 - val_loss: 0.5765 - val_f1: 0.8841\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.5647 - f1: 0.8880 - val_loss: 0.5481 - val_f1: 0.8926\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.5299 - f1: 0.8998 - val_loss: 0.5262 - val_f1: 0.8972\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.5016 - f1: 0.9074 - val_loss: 0.4874 - val_f1: 0.9087\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 295us/sample - loss: 0.4752 - f1: 0.9155 - val_loss: 0.4794 - val_f1: 0.9103\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.4560 - f1: 0.9195 - val_loss: 0.4530 - val_f1: 0.9200\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.4329 - f1: 0.9264 - val_loss: 0.4337 - val_f1: 0.9180\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 6s 295us/sample - loss: 0.4168 - f1: 0.9285 - val_loss: 0.4317 - val_f1: 0.9169\n",
      "Epoch 18/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.3977 - f1: 0.9352 - val_loss: 0.4075 - val_f1: 0.9257\n",
      "Epoch 19/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.3841 - f1: 0.9375 - val_loss: 0.3975 - val_f1: 0.9304\n",
      "Epoch 20/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.3691 - f1: 0.9427 - val_loss: 0.3983 - val_f1: 0.9231\n",
      "Epoch 21/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.3562 - f1: 0.9451 - val_loss: 0.3771 - val_f1: 0.9322\n",
      "Epoch 22/2000\n",
      "20000/20000 [==============================] - 6s 306us/sample - loss: 0.3456 - f1: 0.9460 - val_loss: 0.3614 - val_f1: 0.9373\n",
      "Epoch 23/2000\n",
      "20000/20000 [==============================] - 6s 318us/sample - loss: 0.3350 - f1: 0.9497 - val_loss: 0.3562 - val_f1: 0.9383\n",
      "Epoch 24/2000\n",
      "20000/20000 [==============================] - 6s 305us/sample - loss: 0.3228 - f1: 0.9529 - val_loss: 0.3458 - val_f1: 0.9409\n",
      "Epoch 25/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.3116 - f1: 0.9557 - val_loss: 0.3450 - val_f1: 0.9437\n",
      "Epoch 26/2000\n",
      "20000/20000 [==============================] - 6s 305us/sample - loss: 0.3031 - f1: 0.9564 - val_loss: 0.3192 - val_f1: 0.9510\n",
      "Epoch 27/2000\n",
      "20000/20000 [==============================] - 6s 304us/sample - loss: 0.2920 - f1: 0.9606 - val_loss: 0.3203 - val_f1: 0.9475\n",
      "Epoch 28/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.2872 - f1: 0.9612 - val_loss: 0.3203 - val_f1: 0.9477\n",
      "Epoch 29/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.2741 - f1: 0.9652 - val_loss: 0.3165 - val_f1: 0.9526\n",
      "Epoch 30/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.2703 - f1: 0.9650 - val_loss: 0.3048 - val_f1: 0.9550\n",
      "Epoch 31/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.2593 - f1: 0.9693 - val_loss: 0.3056 - val_f1: 0.9454\n",
      "Epoch 32/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.2497 - f1: 0.9711 - val_loss: 0.2894 - val_f1: 0.9532\n",
      "Epoch 33/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.2456 - f1: 0.9731 - val_loss: 0.2753 - val_f1: 0.9636\n",
      "Epoch 34/2000\n",
      "20000/20000 [==============================] - 6s 301us/sample - loss: 0.2348 - f1: 0.9760 - val_loss: 0.2777 - val_f1: 0.9613\n",
      "Epoch 35/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.2290 - f1: 0.9763 - val_loss: 0.2634 - val_f1: 0.9642\n",
      "Epoch 36/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.2230 - f1: 0.9780 - val_loss: 0.2623 - val_f1: 0.9631\n",
      "Epoch 37/2000\n",
      "20000/20000 [==============================] - 6s 304us/sample - loss: 0.2174 - f1: 0.9789 - val_loss: 0.2421 - val_f1: 0.9698\n",
      "Epoch 38/2000\n",
      "20000/20000 [==============================] - 6s 306us/sample - loss: 0.2103 - f1: 0.9805 - val_loss: 0.2508 - val_f1: 0.9661\n",
      "Epoch 39/2000\n",
      "20000/20000 [==============================] - 6s 303us/sample - loss: 0.2035 - f1: 0.9816 - val_loss: 0.2498 - val_f1: 0.9668\n",
      "Epoch 40/2000\n",
      "20000/20000 [==============================] - 6s 303us/sample - loss: 0.1995 - f1: 0.9829 - val_loss: 0.2472 - val_f1: 0.9635\n",
      "Epoch 41/2000\n",
      "20000/20000 [==============================] - 6s 303us/sample - loss: 0.1963 - f1: 0.9817 - val_loss: 0.2319 - val_f1: 0.9674\n",
      "Epoch 42/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.1909 - f1: 0.9830 - val_loss: 0.2343 - val_f1: 0.9680\n",
      "Epoch 43/2000\n",
      "20000/20000 [==============================] - 10s 498us/sample - loss: 0.1857 - f1: 0.9850 - val_loss: 0.2180 - val_f1: 0.9725\n",
      "Running through fold 3\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 10s 483us/sample - loss: 2.6802 - f1: 0.0969 - val_loss: 1.8548 - val_f1: 0.2781\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 305us/sample - loss: 1.5970 - f1: 0.3968 - val_loss: 1.3545 - val_f1: 0.5273\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 306us/sample - loss: 1.2289 - f1: 0.6108 - val_loss: 1.0800 - val_f1: 0.6954\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 306us/sample - loss: 1.0238 - f1: 0.7166 - val_loss: 0.9206 - val_f1: 0.7562\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 305us/sample - loss: 0.8874 - f1: 0.7810 - val_loss: 0.8272 - val_f1: 0.7966\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 302us/sample - loss: 0.7961 - f1: 0.8144 - val_loss: 0.7378 - val_f1: 0.8291\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 301us/sample - loss: 0.7192 - f1: 0.8425 - val_loss: 0.6909 - val_f1: 0.8507\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.6671 - f1: 0.8596 - val_loss: 0.6330 - val_f1: 0.8679\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.6194 - f1: 0.8743 - val_loss: 0.5916 - val_f1: 0.8829\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.5802 - f1: 0.8864 - val_loss: 0.5628 - val_f1: 0.8876\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.5481 - f1: 0.8946 - val_loss: 0.5421 - val_f1: 0.8922\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.5170 - f1: 0.9031 - val_loss: 0.5036 - val_f1: 0.9057\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 301us/sample - loss: 0.4925 - f1: 0.9094 - val_loss: 0.5177 - val_f1: 0.8954\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 306us/sample - loss: 0.4723 - f1: 0.9119 - val_loss: 0.4710 - val_f1: 0.9079\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.4514 - f1: 0.9182 - val_loss: 0.4618 - val_f1: 0.9136\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.4339 - f1: 0.9213 - val_loss: 0.4508 - val_f1: 0.9105\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.4183 - f1: 0.9247 - val_loss: 0.4344 - val_f1: 0.9178\n",
      "Epoch 18/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.4028 - f1: 0.9280 - val_loss: 0.4128 - val_f1: 0.9235\n",
      "Epoch 19/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.3918 - f1: 0.9310 - val_loss: 0.4177 - val_f1: 0.9191\n",
      "Epoch 20/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.3750 - f1: 0.9343 - val_loss: 0.3985 - val_f1: 0.9237\n",
      "Epoch 21/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.3640 - f1: 0.9368 - val_loss: 0.4016 - val_f1: 0.9248\n",
      "Epoch 22/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.3555 - f1: 0.9382 - val_loss: 0.4000 - val_f1: 0.9203\n",
      "Epoch 23/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.3443 - f1: 0.9400 - val_loss: 0.3893 - val_f1: 0.9221\n",
      "Epoch 24/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.3340 - f1: 0.9413 - val_loss: 0.3685 - val_f1: 0.9350\n",
      "Epoch 25/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.3267 - f1: 0.9437 - val_loss: 0.3696 - val_f1: 0.9245\n",
      "Epoch 26/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.3205 - f1: 0.9443 - val_loss: 0.3595 - val_f1: 0.9306\n",
      "Epoch 27/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.3127 - f1: 0.9455 - val_loss: 0.3461 - val_f1: 0.9322\n",
      "Epoch 28/2000\n",
      "20000/20000 [==============================] - 6s 301us/sample - loss: 0.3055 - f1: 0.9487 - val_loss: 0.3601 - val_f1: 0.9249\n",
      "Epoch 29/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.2989 - f1: 0.9485 - val_loss: 0.3440 - val_f1: 0.9326\n",
      "Epoch 30/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.2910 - f1: 0.9511 - val_loss: 0.3397 - val_f1: 0.9312\n",
      "Epoch 31/2000\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.2868 - f1: 0.9512 - val_loss: 0.3360 - val_f1: 0.9375\n",
      "Epoch 32/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.2784 - f1: 0.9531 - val_loss: 0.3427 - val_f1: 0.9328\n",
      "Epoch 33/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.2753 - f1: 0.9537 - val_loss: 0.3306 - val_f1: 0.9335\n",
      "Epoch 34/2000\n",
      "20000/20000 [==============================] - 10s 514us/sample - loss: 0.2702 - f1: 0.9547 - val_loss: 0.3252 - val_f1: 0.9330\n",
      "Running through fold 4\n",
      "Train on 20000 samples, validate on 3000 samples\n",
      "Epoch 1/2000\n",
      "20000/20000 [==============================] - 10s 488us/sample - loss: 2.7361 - f1: 0.0824 - val_loss: 1.9523 - val_f1: 0.2152\n",
      "Epoch 2/2000\n",
      "20000/20000 [==============================] - 6s 301us/sample - loss: 1.6520 - f1: 0.3599 - val_loss: 1.3894 - val_f1: 0.4738\n",
      "Epoch 3/2000\n",
      "20000/20000 [==============================] - 6s 300us/sample - loss: 1.2680 - f1: 0.5747 - val_loss: 1.1247 - val_f1: 0.6613\n",
      "Epoch 4/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 1.0580 - f1: 0.6954 - val_loss: 0.9731 - val_f1: 0.7387\n",
      "Epoch 5/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.9227 - f1: 0.7615 - val_loss: 0.8549 - val_f1: 0.7909\n",
      "Epoch 6/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.8220 - f1: 0.8023 - val_loss: 0.7658 - val_f1: 0.8214\n",
      "Epoch 7/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.7459 - f1: 0.8309 - val_loss: 0.6977 - val_f1: 0.8482\n",
      "Epoch 8/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.6838 - f1: 0.8539 - val_loss: 0.6491 - val_f1: 0.8643\n",
      "Epoch 9/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.6348 - f1: 0.8693 - val_loss: 0.5994 - val_f1: 0.8812\n",
      "Epoch 10/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.5945 - f1: 0.8819 - val_loss: 0.5775 - val_f1: 0.8866\n",
      "Epoch 11/2000\n",
      "20000/20000 [==============================] - 6s 297us/sample - loss: 0.5587 - f1: 0.8903 - val_loss: 0.5400 - val_f1: 0.8968\n",
      "Epoch 12/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.5287 - f1: 0.9000 - val_loss: 0.5369 - val_f1: 0.8941\n",
      "Epoch 13/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.5006 - f1: 0.9068 - val_loss: 0.5108 - val_f1: 0.9023\n",
      "Epoch 14/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.4801 - f1: 0.9112 - val_loss: 0.5006 - val_f1: 0.9039\n",
      "Epoch 15/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.4616 - f1: 0.9147 - val_loss: 0.4614 - val_f1: 0.9133\n",
      "Epoch 16/2000\n",
      "20000/20000 [==============================] - 6s 302us/sample - loss: 0.4423 - f1: 0.9182 - val_loss: 0.4573 - val_f1: 0.9120\n",
      "Epoch 17/2000\n",
      "20000/20000 [==============================] - 6s 307us/sample - loss: 0.4283 - f1: 0.9220 - val_loss: 0.4353 - val_f1: 0.9154\n",
      "Epoch 18/2000\n",
      "20000/20000 [==============================] - 6s 300us/sample - loss: 0.4125 - f1: 0.9241 - val_loss: 0.4280 - val_f1: 0.9189\n",
      "Epoch 19/2000\n",
      "20000/20000 [==============================] - 6s 302us/sample - loss: 0.4004 - f1: 0.9274 - val_loss: 0.4032 - val_f1: 0.9223\n",
      "Epoch 20/2000\n",
      "20000/20000 [==============================] - 6s 301us/sample - loss: 0.3848 - f1: 0.9309 - val_loss: 0.4063 - val_f1: 0.9224\n",
      "Epoch 21/2000\n",
      "20000/20000 [==============================] - 6s 300us/sample - loss: 0.3740 - f1: 0.9327 - val_loss: 0.3974 - val_f1: 0.9249\n",
      "Epoch 22/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.3627 - f1: 0.9358 - val_loss: 0.3762 - val_f1: 0.9258\n",
      "Epoch 23/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.3527 - f1: 0.9355 - val_loss: 0.3712 - val_f1: 0.9311\n",
      "Epoch 24/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.3436 - f1: 0.9393 - val_loss: 0.3622 - val_f1: 0.9293\n",
      "Epoch 25/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.3373 - f1: 0.9379 - val_loss: 0.3574 - val_f1: 0.9280\n",
      "Epoch 26/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.3259 - f1: 0.9426 - val_loss: 0.3503 - val_f1: 0.9303\n",
      "Epoch 27/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.3210 - f1: 0.9435 - val_loss: 0.3561 - val_f1: 0.9288\n",
      "Epoch 28/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.3137 - f1: 0.9424 - val_loss: 0.3366 - val_f1: 0.9346\n",
      "Epoch 29/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.3061 - f1: 0.9446 - val_loss: 0.3491 - val_f1: 0.9278\n",
      "Epoch 30/2000\n",
      "20000/20000 [==============================] - 6s 300us/sample - loss: 0.3005 - f1: 0.9463 - val_loss: 0.3396 - val_f1: 0.9299\n",
      "Epoch 31/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.2920 - f1: 0.9484 - val_loss: 0.3207 - val_f1: 0.9365\n",
      "Epoch 32/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.2863 - f1: 0.9496 - val_loss: 0.3289 - val_f1: 0.9281\n",
      "Epoch 33/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.2820 - f1: 0.9500 - val_loss: 0.3188 - val_f1: 0.9345\n",
      "Epoch 34/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.2781 - f1: 0.9510 - val_loss: 0.3208 - val_f1: 0.9334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/2000\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.2728 - f1: 0.9512 - val_loss: 0.3126 - val_f1: 0.9389\n",
      "Epoch 36/2000\n",
      "20000/20000 [==============================] - 6s 298us/sample - loss: 0.2689 - f1: 0.9526 - val_loss: 0.3068 - val_f1: 0.9382\n",
      "Epoch 37/2000\n",
      "20000/20000 [==============================] - 6s 305us/sample - loss: 0.2637 - f1: 0.9532 - val_loss: 0.3192 - val_f1: 0.9348\n",
      "Epoch 38/2000\n",
      "20000/20000 [==============================] - 6s 304us/sample - loss: 0.2596 - f1: 0.9533 - val_loss: 0.2921 - val_f1: 0.9423\n",
      "Epoch 39/2000\n",
      "20000/20000 [==============================] - 6s 300us/sample - loss: 0.2564 - f1: 0.9548 - val_loss: 0.3021 - val_f1: 0.9387\n",
      "Epoch 40/2000\n",
      "20000/20000 [==============================] - 6s 301us/sample - loss: 0.2511 - f1: 0.9543 - val_loss: 0.3032 - val_f1: 0.9398\n",
      "Epoch 41/2000\n",
      "20000/20000 [==============================] - 10s 505us/sample - loss: 0.2467 - f1: 0.9566 - val_loss: 0.2966 - val_f1: 0.9379\n"
     ]
    }
   ],
   "source": [
    "mlb=LabelBinarizer()\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    print('\\n\\nRunning through training size '+str(train_size))\n",
    "    k_folds_errors = []\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=5, train_size=train_size)\n",
    "    k = 0\n",
    "    for train_index, _ in sss.split(training_spectra, training_keys):\n",
    "        print('Running through fold '+str(k))\n",
    "        training_keys_binarized = mlb.fit_transform(training_keys.reshape([training_keys.shape[0],1]))\n",
    "        testing_keys_binarized = mlb.transform(testing_keys)\n",
    "        model = compile_model(\n",
    "            build_cnn_model,\n",
    "            model_features)\n",
    "\n",
    "        csv_logger = tf.keras.callbacks.CSVLogger('./final-models-keras/'+model_id_save_as+'_trainsize'+str(train_size)+'_fold'+str(k)+'.log')\n",
    "\n",
    "        output = model.fit(\n",
    "            x=training_spectra_scaled[train_index],\n",
    "            y=training_keys_binarized[train_index],\n",
    "            epochs=num_epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(testing_spectra_scaled,\n",
    "                             testing_keys_binarized),\n",
    "            shuffle=True,\n",
    "            callbacks=[earlystop_callback, csv_logger],\n",
    "        )\n",
    "        model.save('./final-models-keras/'+model_id_save_as+'_trainsize'+str(train_size)+'_fold'+str(k)+'.hdf5')\n",
    "        k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36_update)",
   "language": "python",
   "name": "conda_tensorflow_p36_update"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
