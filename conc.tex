\chapter{Conclusions and Future Work}

\section{General Conclusions}


\section{Suggested Future Works}

% 80%+ Wish list 

Treating dataset expansion methods [calibration, signal-to-total ratio] as random data augmentation instead of sampling them discreetly. Compare asymptotic performance of this 'extreme data augmentation model' on template dataset to performance of 'dataset expansion models' at expansion levels sufficient for learning curve asymptote. 

Create training datasets composed of isotope mixtures. How to sample these mixtures? Exhaustive? Latin hypercube (this is my preference)? Uniform random? See how this works on single- and multi-isotope identification.

% True future work

Much of the gamma-ray spectrum has no information in it, there are no peaks in certain regions. You can apply different preprocessing techniques to shrink these sections (similar to what RSL has done). What is the effect of these re-calibrations on performance?

See how well kernel SVM, boosted trees, random forests work on features extracted by DAE, CAE, PCA. Do these methods perform better on the datasets I've provided compared to the neural networks I've demonstrated? Compare speed, accuracy on simulated and collected data.

Autoencoder that takes spectrum as input, output is peak positions. Use this as a feature extractor. 

Can you address background identification errors by adding a higher penalizing term to the cost of mislabeling background? How does this play with precision/recall/F1 score as you change the decision threshold?
